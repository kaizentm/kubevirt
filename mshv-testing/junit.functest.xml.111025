<testsuite name="KubeVirt Tests Suite" tests="647" failures="39" errors="0" time="14418.137">
      <testcase name="[sig-network] Subdomain with a headless service given VMI should have the expected FQDN with Masquerade binding and subdomain and hostname" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Subdomain with a headless service given VMI should have the expected FQDN with Bridge binding and subdomain" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Subdomain with a headless service given VMI should have the expected FQDN with Masquerade binding without subdomain" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Subdomain with a headless service given VMI should have the expected FQDN with Bridge binding without subdomain" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Subdomain with a headless service given VMI with custom DNSPolicy should have the expected FQDN" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Subdomain VMI with custom DNSPolicy, a subdomain and no service entry, should not include the subdomain in the searchlist" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MediatedDevices with externally provided mediated devices Should make sure that mdevs listed with ExternalResourceProvider are not removed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MediatedDevices with externally provided mediated devices Should make sure that no mdev is removed if the feature is gated" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MediatedDevices with mediated devices configuration Should successfully passthrough a mediated device" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MediatedDevices with mediated devices configuration Should override default mdev configuration on a specific node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MediatedDevices with generic mediated devices should create mdevs on devices that appear after CR configuration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Monitoring Kubevirt alert rules [test_id:8821]should have all the required annotations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Monitoring Kubevirt alert rules [test_id:8822]should have all the required labels" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Monitoring Migration Alerts KubeVirtVMIExcessiveMigrations should be triggered when a VMI has been migrated more than 12 times during the last 24 hours" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Monitoring System Alerts KubeVirtNoAvailableNodesToRunVMs should be triggered when there are no available nodes in the cluster to run VMs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Monitoring Deprecation Alerts KubeVirtDeprecatedAPIRequested should be triggered when a deprecated API is requested" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:8499]Should be able to get and remove memory dump calling endpoint directly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:8502]Run multiple memory dumps" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:8503]Run memory dump to a pvc, remove and run memory dump to different pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:8506]Run memory dump, stop vm and remove memory dump" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:8515]Run memory dump, stop vm start vm" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:8501]Run memory dump with pvc too small should fail" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Memory dump Memory dump with existing PVC [test_id:9341]Should be able to remove memory dump while memory dump is stuck" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Guest console log [level:component] Guest console log container set LogSerialConsole it should exit cleanly when the shutdown is initiated by the guest" classname="KubeVirt Tests Suite" time="42.812221618" />
      <testcase name="[sig-compute]Guest console log [level:component] Guest console log container fetch logs [QUARANTINE] it should fetch logs for a running VM with logs API" classname="KubeVirt Tests Suite" time="33.515183677" />
      <testcase name="[sig-compute]Guest console log [level:component] Guest console log container fetch logs it should rotate the internal log files" classname="KubeVirt Tests Suite" time="708.921685996" />
      <testcase name="[sig-compute]Guest console log [level:component] Guest console log container fetch logs [QUARANTINE] it should not skip any log line even trying to flood the serial console for QOSGuaranteed VMs" classname="KubeVirt Tests Suite" time="105.812616925" />
      <testcase name="[sig-compute]PortForward should successfully open connection to guest" classname="KubeVirt Tests Suite" time="70.238314139" />
      <testcase name="[virtctl] [crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] usbredir Should fail when limit is reached" classname="KubeVirt Tests Suite" time="16.298061425" />
      <testcase name="[virtctl] [crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] usbredir Should work several times" classname="KubeVirt Tests Suite" time="14.781754923" />
      <testcase name="[sig-compute] usbredir support should fail to connect to VMI's usbredir socket" classname="KubeVirt Tests Suite" time="11.919708303" />
      <testcase name="[sig-compute] Infrastructure tls configuration [test_id:9306]should result only connections with the correct client-side tls configurations are accepted by the components" classname="KubeVirt Tests Suite" time="82.183694417" />
      <testcase name="[sig-compute]NUMA [test_id:7299] topology should be mapped to the guest and hugepages should be allocated" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:4126][crit:medium][vendor:cnv-qe@redhat.com][level:component]Taints and toleration CriticalAddonsOnly taint set on a node [test_id:4134] kubevirt components on that node should not evict" classname="KubeVirt Tests Suite" time="15.306413102">
          <failure type="Failure">tests/infrastructure/taints-and-tolerations.go:59
Could not determine a node to safely taint
tests/infrastructure/taints-and-tolerations.go:73</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/1_*
Skipping volume snapshot log collection
Global test cleanup started.
Forwarding from 127.0.0.1:7103 -&gt; 8443
Forwarding from [::1]:7103 -&gt; 8443
Handling connection for 7103
Forwarding from 127.0.0.1:9512 -&gt; 8443
Forwarding from [::1]:9512 -&gt; 8443
Handling connection for 9512
Forwarding from 127.0.0.1:10038 -&gt; 8443
Forwarding from [::1]:10038 -&gt; 8443
Handling connection for 10038
Forwarding from 127.0.0.1:7205 -&gt; 8443
Forwarding from [::1]:7205 -&gt; 8443
Handling connection for 7205
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute] Infrastructure downwardMetrics should start a vmi and get the metrics [test_id:6535]using a disk" classname="KubeVirt Tests Suite" time="44.285282887" />
      <testcase name="[sig-compute] Infrastructure downwardMetrics should start a vmi and get the metrics using a virtio serial device" classname="KubeVirt Tests Suite" time="42.227875144" />
      <testcase name="[sig-compute] Infrastructure downwardMetrics metric ResourceProcessorLimit should be present" classname="KubeVirt Tests Suite" time="40.218654715" />
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled [test_id:10823]should successfully hotplug memory with a common VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled [test_id:10823]should successfully hotplug memory with 2Mi pagesize hugepages VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled [test_id:10824]after a hotplug memory and a restart the new memory value should be the base for the VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled [test_id:10825]should successfully hotplug Memory and CPU in parallel" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled should successfully hotplug memory when adding guest.memory to a VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled should successfully hotplug memory twice" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Memory Hotplug A VM with memory liveUpdate enabled should detect a failed memory hotplug" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests With simple VM [test_id:4609]should successfully create a snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests With simple VM [test_id:4610]create a snapshot when VM is running should succeed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests With simple VM should create a snapshot when VM runStrategy is Manual" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests With simple VM VM should contain snapshot status for all volumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot [test_id:6767]with volumes and guest agent available" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot [test_id:6768]with volumes and no guest agent available" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot [test_id:6769]without volumes with guest agent available" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot [test_id:6837]delete snapshot after freeze, expect vm unfreeze" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot [test_id:6949]should unfreeze vm if snapshot fails when deadline exceeded" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot [test_id:12182] should succeed snapshot when VM is paused with Paused indication" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot should succeed online snapshot with hot plug disk [test_id:7472] with ephemeral hotplug disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot should succeed online snapshot with hot plug disk without ephemeral hotplug disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot should report appropriate event when freeze fails" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With online vm snapshot with memory dump [test_id:8922]should include memory dump in vm snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With more complicated VM [test_id:4611] should successfully create a snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With more complicated VM should successfully recreate status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With more complicated VM VM should contain snapshot status for all volumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With more complicated VM should error if VolumeSnapshot deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With more complicated VM should not error if VolumeSnapshot has error" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With more complicated VM [test_id:6838]snapshot should fail when deadline exceeded due to volume snapshots failure" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] vmsnapshot should update error if vmsnapshotcontent is unready to use and error" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] snapshot create before source wait for volume bound, then continues and succeeds" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] with independent DataVolume should accurately report DataVolume provisioning with DataVolume volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] with independent DataVolume should accurately report DataVolume provisioning with PVC volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] with independent DataVolume [test_id:9705]Should show included and excluded volumes in the snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] with independent DataVolume Should also include backend PVC in the snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With VM using instancetype and preferences Bug #8435 - should create a snapshot successfully with running source VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineSnapshot Tests [storage-req] With VM using instancetype and preferences Bug #8435 - should create a snapshot successfully with stopped source VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition set sidecar resources [test_id:3155]should successfully start with hook sidecar annotation" classname="KubeVirt Tests Suite" time="97.373303131" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with SM BIOS hook sidecar [test_id:3156]should successfully start with hook sidecar annotation for v1alpha2" classname="KubeVirt Tests Suite" time="18.038070526" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with SM BIOS hook sidecar [test_id:3157]should call Collect and OnDefineDomain on the hook sidecar" classname="KubeVirt Tests Suite" time="18.30982793" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with SM BIOS hook sidecar should not start with hook sidecar annotation when the version is not provided" classname="KubeVirt Tests Suite" time="15.205847434" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with sidecar-shim should receive Terminal signal on VMI deletion" classname="KubeVirt Tests Suite" time="18.191244692" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with sidecar-shim migrate VMI with sidecar Fails to terminate on migration with &lt; v1alpha3" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with sidecar-shim migrate VMI with sidecar Terminates properly on migration with &gt;= v1alpha3" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with ConfigMap in sidecar hook annotation should update domain XML with SM BIOS properties when sidecar image is specified" classname="KubeVirt Tests Suite" time="19.57242071" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with ConfigMap in sidecar hook annotation should update domain XML with SM BIOS properties when sidecar image is not specified" classname="KubeVirt Tests Suite" time="18.487150989" />
      <testcase name="[sig-compute]HookSidecars [rfe_id:2667][crit:medium][vendor:cnv-qe@redhat.com][level:component] VMI definition with sidecar feature gate disabled [test_id:2666]should not start with hook sidecar annotation" classname="KubeVirt Tests Suite" time="78.020017311" />
      <testcase name="[sig-compute] Eviction should not shutdown VM" classname="KubeVirt Tests Suite" time="43.684532973" />
      <testcase name="[sig-network]  SRIOV nic-hotplug a running VM can hotplug a network interface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component]should scale [test_id:1405]to three, to two and then to zero replicas" classname="KubeVirt Tests Suite" time="9.25052283" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component]should scale [test_id:1406]to five, to six and then to zero replicas" classname="KubeVirt Tests Suite" time="10.537804956" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component]should scale with scale subresource [test_id:1407]to three, to two and then to zero replicas" classname="KubeVirt Tests Suite" time="11.403653244000001" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component]should scale with scale subresource [test_id:1408]to five, to six and then to zero replicas" classname="KubeVirt Tests Suite" time="12.153793426" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component]should scale with the horizontal pod autoscaler [test_id:1409]to three, to two and then to one replicas" classname="KubeVirt Tests Suite" time="53.975813311" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component]should scale with the horizontal pod autoscaler [test_id:1410]to five, to six and then to one replicas" classname="KubeVirt Tests Suite" time="54.978605552" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1411]should be rejected on POST if spec is invalid" classname="KubeVirt Tests Suite" time="7.462423974" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1412]should reject POST if validation webhoook deems the spec is invalid" classname="KubeVirt Tests Suite" time="7.463706534" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1413]should update readyReplicas once VMIs are up" classname="KubeVirt Tests Suite" time="16.309989623" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1414]should return the correct data when using server-side printing" classname="KubeVirt Tests Suite" time="17.457148565" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1415]should remove VMIs once they are marked for deletion" classname="KubeVirt Tests Suite" time="9.798794307" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1416]should remove owner references on the VirtualMachineInstance if it is orphan deleted" classname="KubeVirt Tests Suite" time="9.203579804" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1417]should not scale when paused and scale when resume" classname="KubeVirt Tests Suite" time="11.104429988" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet [test_id:1418] should replace finished VMIs" classname="KubeVirt Tests Suite" time="12.437445489" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet should replace a VMI immediately when a virt-launcher pod gets deleted" classname="KubeVirt Tests Suite" time="16.780208344000002" />
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachineInstanceReplicaSet replicaset with topology spread constraints Replicas should be spread across nodes" classname="KubeVirt Tests Suite" time="7.392970592">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking Multiple virtual machines connectivity using bridge binding interface with a test outbound VMI should be able to reach [test_id:1539]the Inbound VirtualMachineInstance with default (implicit) binding" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking Multiple virtual machines connectivity using bridge binding interface with a test outbound VMI should be able to reach [test_id:1541]the Inbound VirtualMachineInstance with custom MAC address" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking Multiple virtual machines connectivity using bridge binding interface with a test outbound VMI should be able to reach [test_id:1542]the Inbound VirtualMachineInstance with muti-queue and a single CPU" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking Multiple virtual machines connectivity using bridge binding interface clients should be able to reach VM workload, with propagated IP from a pod" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with custom and default interface models [test_id:1770]should expose the right device type to the guest" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking [test_id:1774]should not configure any external interfaces when a VMI has no networks and auto attachment is disabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VMI with an interface that has ACPI Index set" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with learning disabled on pod interface [test_id:1777]should disable learning on pod iface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with dhcp options [test_id:1778]should offer extra dhcp options to pod iface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with custom dns [test_id:1779]should have custom resolv.conf" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection ipv4 with a specific port number [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection ipv4 with a specific port used by live migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection ipv4 without a specific port number [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection ipv4 with custom CIDR [IPv4] containing leading zeros" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection should be able to reach the outside world [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection [QUARANTINE] IPv6 with a specific port number [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection [QUARANTINE] IPv6 with a specific port used by live migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection [QUARANTINE] IPv6 without a specific port number [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection [QUARANTINE] IPv6 with custom CIDR [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism [test_id:1780][label:masquerade_binding_connectivity]should allow regular network connection should be able to reach the outside world" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism when performing migration preserves connectivity - IPv4 without a specific port number" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism when performing migration preserves connectivity - IPv4 with explicit ports used by live migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism when performing migration should preserve connectivity - IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism MTU verification should have the correct MTU IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with masquerade binding mechanism MTU verification should have the correct MTU IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]Networking VirtualMachineInstance with TX offload disabled [test_id:1781]should have tx checksumming disabled on interface serving dhcp" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Services bridge interface binding with a service matching the vmi exposed [test_id:1547] should be able to reach the vmi based on labels specified on the vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Services bridge interface binding with a service matching the vmi exposed [test_id:1548] should fail to reach the vmi if an invalid servicename is used" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Services bridge interface binding with a subdomain and a headless service given [test_id:1549]should be able to reach the vmi via its unique fully qualified domain name" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Services Masquerade interface binding with a service matching the vmi exposed should be able to reach the vmi based on labels specified on the vmi when the service is exposed by an IPv4 address." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Services Masquerade interface binding with a service matching the vmi exposed should be able to reach the vmi based on labels specified on the vmi when the service is exposed by an IPv6 address." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Services Masquerade interface binding *without* a service matching the vmi exposed should fail to reach the vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Migration recovery should successfully defer a migration failure" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Migration recovery should successfully defer a migration success" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Migration recovery should successfully defer a migration failure [Serial]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Migration recovery should successfully defer a migration success [Serial]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VMI with external kernel boot with external alpine-based kernel &amp; initrd images [test_id:7748]ensure successful boot" classname="KubeVirt Tests Suite" time="20.129932592" />
      <testcase name="[sig-compute]VMI with external kernel boot with external alpine-based kernel &amp; initrd images ensure successful boot and deletion when VMI has a disk defined" classname="KubeVirt Tests Suite" time="116.285055895" />
      <testcase name="[sig-compute]VMI with external kernel boot with illegal definition ensure rejection of [test_id:7750]VMI defined without an image" classname="KubeVirt Tests Suite" time="7.427965782" />
      <testcase name="[sig-compute]VMI with external kernel boot with illegal definition ensure rejection of [test_id:7751]VMI defined with image but without initrd &amp; kernel paths" classname="KubeVirt Tests Suite" time="7.430344406" />
      <testcase name="[sig-compute]VMI with external kernel boot with external alpine-based kernel only (without initrd) ensure successful boot" classname="KubeVirt Tests Suite" time="15.974755093" />
      <testcase name="[sig-compute]VMI with external kernel boot with external alpine-based kernel only (without initrd) ensure successful boot and deletion when VMI has a disk defined" classname="KubeVirt Tests Suite" time="31.213196349" />
      <testcase name="[sig-storage] Storage configuration volumes and disks validation (with volumes, disks and filesystem defined) [test_id:6960]should reject disk with missing volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration driver cache and io settings and PVC [test_id:1681]should set appropriate cache modes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration driver cache and io settings and PVC [test_id:5360]should set appropriate IO modes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration Block size configuration set [test_id:6965]Should set BlockIO when using custom block sizes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration Block size configuration set [test_id:6966]Should set BlockIO when set to match volume block sizes on block devices" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration Block size configuration set [test_id:6967]Should set BlockIO when set to match volume block sizes on files" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration virtio queues [test_id:1664]should map cores to virtio block queues" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage configuration virtio queues [test_id:1667]should not enforce explicitly rejected virtio block queues without cores" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle when virt-handler is deleted [test_id:4716]should label the node with kubevirt.io/schedulable=false" classname="KubeVirt Tests Suite" time="29.645333071" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance [test_id:6095]should start in paused state if start strategy set to paused" classname="KubeVirt Tests Suite" time="16.109571134" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance [test_id:1621]should attach virt-launcher to it" classname="KubeVirt Tests Suite" time="16.70610401" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance [test_id:3196]should carry kubernetes and kubevirt annotations to pod" classname="KubeVirt Tests Suite" time="16.034381455" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance Should prevent eviction when EvictionStratgy: External" classname="KubeVirt Tests Suite" time="26.134872454" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance [test_id:1622]should log libvirtd logs" classname="KubeVirt Tests Suite" time="16.193240589" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance log libvirtd debug logs should be [test_id:3197]enabled when debugLogs label defined" classname="KubeVirt Tests Suite" time="13.012211236" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance log libvirtd debug logs should be [test_id:8530]enabled when customLogFilters defined" classname="KubeVirt Tests Suite" time="12.916500888" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance log libvirtd debug logs should be [test_id:8531]enabled when log verbosity is high" classname="KubeVirt Tests Suite" time="12.869823778" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance log libvirtd debug logs should be [test_id:8532]disabled when log verbosity is low" classname="KubeVirt Tests Suite" time="13.808019746" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance log libvirtd debug logs should be [test_id:8533]disabled when log verbosity, debug logs and customLogFilters are not defined" classname="KubeVirt Tests Suite" time="13.811399467" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance [test_id:1623]should reject POST if validation webhook deems the spec invalid" classname="KubeVirt Tests Suite" time="7.433684448" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance [test_id:1624]should reject PATCH if schema is invalid" classname="KubeVirt Tests Suite" time="7.708385324" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when name is longer than 63 characters [test_id:1625]should start it" classname="KubeVirt Tests Suite" time="25.431259086" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with boot order [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]should be able to boot from selected disk [test_id:1627]Alpine as first boot" classname="KubeVirt Tests Suite" time="25.145015539" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with boot order [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]should be able to boot from selected disk [test_id:1628]Cirros as first boot" classname="KubeVirt Tests Suite" time="19.984196974" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with user-data without k8s secret [test_id:1630]should log warning and proceed once the secret is there" classname="KubeVirt Tests Suite" time="16.568710253" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with nodeselector [test_id:5760]should check if vm's with non existing nodeselector is not running and node selector is not updated" classname="KubeVirt Tests Suite" time="7.503442028" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with nodeselector [test_id:5761]should check if vm with valid node selector is scheduled and running and node selector is not updated" classname="KubeVirt Tests Suite" time="16.034174566" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with nodeselector for Machine Type should prevent scheduling of a pod for a VMI with an unsupported machine type amd64" classname="KubeVirt Tests Suite" time="7.601607076" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with nodeselector for Machine Type should prevent scheduling of a pod for a VMI with an unsupported machine type arm64" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with nodeselector for Machine Type should prevent scheduling of a pod for a VMI with an unsupported machine type s390x" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when guest crashes should be stopped and have Failed phase when a PanicDevice is provided amd64" classname="KubeVirt Tests Suite" time="145.450986633" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when guest crashes should be stopped and have Failed phase when a PanicDevice is provided arm64" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-launcher crashes [test_id:1631]should be stopped and have Failed phase" classname="KubeVirt Tests Suite" time="74.141300664" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler crashes [test_id:1632]should recover and continue management" classname="KubeVirt Tests Suite" time="336.832897011" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler is responsive [test_id:1633]should indicate that a node is ready for vmis" classname="KubeVirt Tests Suite" time="13.133417867" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler is responsive [test_id:3198]device plugins should re-register if the kubelet restarts" classname="KubeVirt Tests Suite" time="116.944124899">
          <failure type="Failure">tests/vmi_lifecycle_test.go:590
Timed out after 60.001s.
Should log device plugin restart
Expected
    &lt;string&gt;: 
to contain substring
    &lt;string&gt;: device socket file for device kvm was removed, kubelet probably restarted.
tests/vmi_lifecycle_test.go:627</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/2_*
Skipping volume snapshot log collection
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "(localhost|testvmi-662jp) login: " found: ["localhost login: " "localhost"] Buffer: 
Welcome to Alpine Linux 3.20
Kernel 6.6.34-1-virt on an x86_64 (/dev/ttyS0)

localhost login: 
&#65533;[34mSent:&#65533;[39m "root\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["# " "# "] Buffer: root
Welcome to Alpine!

The Alpine Wiki contains a large amount of how-to guides and general
information about administrating Alpine systems.
See &lt;https://wiki.alpinelinux.org/&gt;.

You can setup the system with the command: setup-alpine

You may change this message by editing /etc/motd.

localhost:~# 
&#65533;[34mSent:&#65533;[39m "stty cols 500 rows 500\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["# " "# "] Buffer: &#65533;[6nstty cols 500 rows 500
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "\n0\r\n.*(\\$ |\\# )" found: ["\n0\r\nlocalhost:~# " "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "dmesg -n 1\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["# " "# "] Buffer: &#65533;[6ndmesg -n 1
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "\n0\r\n.*(\\$ |\\# )" found: ["\n0\r\nlocalhost:~# " "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "ip address\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip address((?s).*)((?s).*)(\\$ |\\# )" found: ["ip address\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 66:21:74:19:e9:0e brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~# " "\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 66:21:74:19:e9:0e brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~" "" "# "] Buffer: ip address
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000
    link/ether 66:21:74:19:e9:0e brd ff:ff:ff:ff:ff:ff
localhost:~# &#65533;[
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: 6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "ip link\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip link((?s).*)((?s).*)(\\$ |\\# )" found: ["ip link\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 66:21:74:19:e9:0e brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~# " "\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 66:21:74:19:e9:0e brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~" "" "# "] Buffer: ip link
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000
    link/ether 66:21:74:19:e9:0e brd ff:ff:ff:ff:ff:ff
localhost:~# &#65533;[6n
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: echo $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "ip route show table all\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip route show table all((?s).*)((?s).*)(\\$ |\\# )" found: ["ip route show table all\r\nlocalhost:~# " "\r\nlocalhost:~" "" "# "] Buffer: ip route show table all
localhost:~# &#65533;
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: [6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "dmesg\n"
&#65533;[32mMatch for RE:&#65533;[39m "dmesg((?s).*)((?s).*)(\\$ |\\# )" found: ["dmesg\r\n[    0.000000] Linux version 6.6.34-1-virt (buildozer@build-3-20-x86_64) (gcc (Alpine 13.2.1_git20240309) 13.2.1 20240309, GNU ld (GNU Binutils) 2.42) #2-Alpine SMP PREEMPT_DYNAMIC Tue, 18 Jun 2024 10:38:37 +0000\r\n[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.000000] BIOS-provided physical RAM map:\r\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable\r\n[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable\r\n[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved\r\n[    0.000000] NX (Execute Disable) protection: active\r\n[    0.000000] APIC: Static calls initialized\r\n[    0.000000] SMBIOS 2.8 present.\r\n[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014\r\n[    0.000000] Hypervisor detected: Microsoft Hyper-V\r\n[    0.000000] Hyper-V: privilege flags low 0xe7e, high 0x0, hints 0x60624, misc 0xe0130\r\n[    0.000000] Hyper-V: Host Build 10.0.26100.1381-1-0\r\n[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480\r\n[    0.000000] Hyper-V: Using hypercall for remote TLB flush\r\n[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000000] clocksource: hyperv_clocksource_msr: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000001] tsc: Marking TSC unstable due to running on Hyper-V\r\n[    0.000003] tsc: Detected 2299.999 MHz processor\r\n[    0.000193] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved\r\n[    0.000195] e820: remove [mem 0x000a0000-0x000fffff] usable\r\n[    0.000198] last_pfn = 0x7fdd max_arch_pfn = 0x400000000\r\n[    0.000218] MTRR map: 4 entries (3 fixed + 1 variable; max 19), built from 8 variable MTRRs\r\n[    0.000220] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \r\n[    0.000252] Using GB pages for direct mapping\r\n[    0.000326] RAMDISK: [mem 0x0774b000-0x07fdcfff]\r\n[    0.000327] ACPI: Early table checksum verification disabled\r\n[    0.000329] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )\r\n[    0.000331] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000334] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000337] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000339] ACPI: FACS 0x0000000007FE0000 000040\r\n[    0.000341] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000342] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000344] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000345] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000347] ACPI: Reserving FACP table memory at [mem 0x7fe2947-0x7fe2a3a]\r\n[    0.000347] ACPI: Reserving DSDT table memory at [mem 0x7fe0040-0x7fe2946]\r\n[    0.000348] ACPI: Reserving FACS table memory at [mem 0x7fe0000-0x7fe003f]\r\n[    0.000348] ACPI: Reserving APIC table memory at [mem 0x7fe2a3b-0x7fe2aca]\r\n[    0.000349] ACPI: Reserving HPET table memory at [mem 0x7fe2acb-0x7fe2b02]\r\n[    0.000349] ACPI: Reserving MCFG table memory at [mem 0x7fe2b03-0x7fe2b3e]\r\n[    0.000350] ACPI: Reserving WAET table memory at [mem 0x7fe2b3f-0x7fe2b66]\r\n[    0.000571] Zone ranges:\r\n[    0.000571]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]\r\n[    0.000572]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]\r\n[    0.000573]   Normal   empty\r\n[    0.000574] Movable zone start for each node\r\n[    0.000574] Early memory node ranges\r\n[    0.000574]   node   0: [mem 0x0000000000001000-0x000000000009efff]\r\n[    0.000575]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]\r\n[    0.000576] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]\r\n[    0.000578] On node 0, zone DMA: 1 pages in unavailable ranges\r\n[    0.000589] On node 0, zone DMA: 97 pages in unavailable ranges\r\n[    0.001184] On node 0, zone DMA32: 35 pages in unavailable ranges\r\n[    0.024444] ACPI: PM-Timer IO Port: 0x608\r\n[    0.024450] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\r\n[    0.026262] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23\r\n[    0.026265] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)\r\n[    0.026266] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\r\n[    0.026267] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\r\n[    0.026268] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\r\n[    0.026268] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\r\n[    0.026271] ACPI: Using ACPI (MADT) for SMP configuration information\r\n[    0.026272] ACPI: HPET id: 0x8086a201 base: 0xfed00000\r\n[    0.026274] smpboot: Allowing 4 CPUs, 3 hotplug CPUs\r\n[    0.026280] [mem 0x08000000-0xafffffff] available for PCI devices\r\n[    0.026281] Booting paravirtualized kernel on Hyper-V\r\n[    0.026282] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.030521] setup_percpu: NR_CPUS:256 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1\r\n[    0.031707] percpu: Embedded 57 pages/cpu s195560 r8192 d29720 u524288\r\n[    0.031711] pcpu-alloc: s195560 r8192 d29720 u524288 alloc=1*2097152\r\n[    0.031713] pcpu-alloc: [0] 0 1 2 3 \r\n[    0.031723] Hyper-V: PV spinlocks enabled\r\n[    0.031725] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    0.031727] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.031764] Unknown kernel command line parameters \"BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage\", will be passed to user space.\r\n[    0.031772] random: crng init done\r\n[    0.031789] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r\n[    0.031797] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r\n[    0.031850] Built 1 zonelists, mobility grouping on.  Total pages: 31965\r\n[    0.032825] mem auto-init: stack:all(zero), heap alloc:on, heap free:off\r\n[    0.033046] Memory: 80436K/130540K available (14336K kernel code, 1799K rwdata, 8232K rodata, 2696K init, 2032K bss, 49844K reserved, 0K cma-reserved)\r\n[    0.033178] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1\r\n[    0.033724] Dynamic Preempt: none\r\n[    0.033753] rcu: Preemptible hierarchical RCU implementation.\r\n[    0.033753] rcu: \tRCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=4.\r\n[    0.033754] \tTrampoline variant of Tasks RCU enabled.\r\n[    0.033754] \tTracing variant of Tasks RCU enabled.\r\n[    0.033755] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.\r\n[    0.033755] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4\r\n[    0.035340] NR_IRQS: 16640, nr_irqs: 456, preallocated irqs: 16\r\n[    0.036616] rcu: srcu_init: Setting srcu_struct sizes based on contention.\r\n[    0.039007] kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)\r\n[    0.041386] Console: colour *CGA 80x25\r\n[    0.041387] printk: console [tty0] enabled\r\n[    0.041398] ACPI: Core revision 20230628\r\n[    0.045779] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns\r\n[    0.048956] APIC: Switch to symmetric I/O mode setup\r\n[    0.070947] x2apic enabled\r\n[    0.071225] APIC: Switched APIC routing to: physical x2apic\r\n[    0.071239] Hyper-V: Disabling IBT because of Hyper-V bug\r\n[    0.071240] Hyper-V: Using IPI hypercalls\r\n[    0.071241] APIC: send_IPI() replaced with hv_send_ipi()\r\n[    0.071245] APIC: send_IPI_mask() replaced with hv_send_ipi_mask()\r\n[    0.071247] APIC: send_IPI_mask_allbutself() replaced with hv_send_ipi_mask_allbutself()\r\n[    0.071249] APIC: send_IPI_allbutself() replaced with hv_send_ipi_allbutself()\r\n[    0.071250] APIC: send_IPI_all() replaced with hv_send_ipi_all()\r\n[    0.071252] APIC: send_IPI_self() replaced with hv_send_ipi_self()\r\n[    0.156820] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1\r\n[    0.158698] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=22999990)\r\n[    0.158771] x86/cpu: User Mode Instruction Prevention (UMIP) activated\r\n[    0.158779] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0\r\n[    0.158780] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0\r\n[    0.158784] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization\r\n[    0.158786] Spectre V2 : Mitigation: Retpolines\r\n[    0.158786] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch\r\n[    0.158787] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT\r\n[    0.158787] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!\r\n[    0.158788] RETBleed: Vulnerable\r\n[    0.158789] Speculative Store Bypass: Vulnerable\r\n[    0.158789] MMIO Stale Data: Unknown: No mitigations\r\n[    0.158804] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'\r\n[    0.158805] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'\r\n[    0.158806] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'\r\n[    0.158807] x86/fpu: Supporting XSAVE feature 0x800: 'Control-flow User registers'\r\n[    0.158808] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256\r\n[    0.158809] x86/fpu: xstate_offset[11]:  832, xstate_sizes[11]:   16\r\n[    0.158810] x86/fpu: Enabled xstate features 0x807, context size is 848 bytes, using 'compacted' format.\r\n[    0.180638] pid_max: default: 32768 minimum: 301\r\n[    0.180663] LSM: initializing lsm=lockdown,capability,landlock,integrity\r\n[    0.180681] landlock: Up and running.\r\n[    0.180694] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.180696] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.182091] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)\r\n[    0.182208] RCU Tasks: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.182216] RCU Tasks Trace: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.182224] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.\r\n[    0.182237] signal: max sigframe size: 1776\r\n[    0.182255] rcu: Hierarchical SRCU implementation.\r\n[    0.182255] rcu: \tMax phase no-delay instances is 1000.\r\n[    0.182378] NMI watchdog: Perf NMI watchdog permanently disabled\r\n[    0.182410] smp: Bringing up secondary CPUs ...\r\n[    0.182414] smp: Brought up 1 node, 1 CPU\r\n[    0.182415] smpboot: Max logical packages: 4\r\n[    0.182415] ----------------\r\n[    0.182416] | NMI testsuite:\r\n[    0.182416] --------------------\r\n[    0.182416]   remote IPI:  ok  |\r\n[    0.182417]    local IPI:  ok  |\r\n[    0.182425] --------------------\r\n[    0.182425] Good, all   2 testcases passed! |\r\n[    0.182426] ---------------------------------\r\n[    0.182426] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)\r\n[    0.182511] devtmpfs: initialized\r\n[    0.182535] x86/mm: Memory block size: 128MB\r\n[    0.182611] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.182620] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)\r\n[    0.183891] NET: Registered PF_NETLINK/PF_ROUTE protocol family\r\n[    0.183933] audit: initializing netlink subsys (disabled)\r\n[    0.183981] thermal_sys: Registered thermal governor 'step_wise'\r\n[    0.183986] audit: type=2000 audit(1762556618.020:1): state=initialized audit_enabled=0 res=1\r\n[    0.183988] cpuidle: using governor ladder\r\n[    0.183990] cpuidle: using governor menu\r\n[    0.184006] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5\r\n[    0.185606] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)\r\n[    0.185608] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved as E820 entry\r\n[    0.185613] PCI: Using configuration type 1 for base access\r\n[    0.185675] kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.\r\n[    0.187938] HugeTLB: registered 1.00 GiB page size, pre-allocated 0 pages\r\n[    0.187939] HugeTLB: 16380 KiB vmemmap can be freed for a 1.00 GiB page\r\n[    0.187940] HugeTLB: registered 2.00 MiB page size, pre-allocated 0 pages\r\n[    0.187941] HugeTLB: 28 KiB vmemmap can be freed for a 2.00 MiB page\r\n[    0.188040] ACPI: Added _OSI(Module Device)\r\n[    0.188041] ACPI: Added _OSI(Processor Device)\r\n[    0.188041] ACPI: Added _OSI(3.0 _SCP Extensions)\r\n[    0.188042] ACPI: Added _OSI(Processor Aggregator Device)\r\n[    0.188695] ACPI: 1 ACPI AML tables successfully acquired and loaded\r\n[    0.192890] ACPI: _OSC evaluation for CPUs failed, trying _PDC\r\n[    0.192964] ACPI: Interpreter enabled\r\n[    0.192970] ACPI: PM: (supports S0 S3 S5)\r\n[    0.192971] ACPI: Using IOAPIC for interrupt routing\r\n[    0.192981] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\r\n[    0.192982] PCI: Using E820 reservations for host bridge windows\r\n[    0.193432] ACPI: Enabled 2 GPEs in block 00 to 3F\r\n[    0.200531] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\r\n[    0.200534] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]\r\n[    0.200557] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]\r\n[    0.200586] acpi PNP0A08:00: _OSC: OS now controls [PME PCIeCapability]\r\n[    0.204006] PCI host bridge to bus 0000:00\r\n[    0.204007] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]\r\n[    0.204009] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]\r\n[    0.204010] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]\r\n[    0.204011] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]\r\n[    0.204012] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]\r\n[    0.204013] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]\r\n[    0.204015] pci_bus 0000:00: root bus resource [bus 00-ff]\r\n[    0.205105] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000\r\n[    0.213209] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400\r\n[    0.216536] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]\r\n[    0.224539] pci 0000:00:01.0: enabling Extended Tags\r\n[    0.244251] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400\r\n[    0.248077] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]\r\n[    0.256220] pci 0000:00:01.1: enabling Extended Tags\r\n[    0.275826] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400\r\n[    0.279570] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]\r\n[    0.287280] pci 0000:00:01.2: enabling Extended Tags\r\n[    0.306758] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400\r\n[    0.309854] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]\r\n[    0.317838] pci 0000:00:01.3: enabling Extended Tags\r\n[    0.338513] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400\r\n[    0.342125] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]\r\n[    0.349364] pci 0000:00:01.4: enabling Extended Tags\r\n[    0.368667] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400\r\n[    0.372347] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]\r\n[    0.380276] pci 0000:00:01.5: enabling Extended Tags\r\n[    0.399897] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400\r\n[    0.410065] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]\r\n[    0.441437] pci 0000:00:01.6: enabling Extended Tags\r\n[    0.459354] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400\r\n[    0.463104] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]\r\n[    0.471947] pci 0000:00:01.7: enabling Extended Tags\r\n[    0.492185] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400\r\n[    0.495754] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]\r\n[    0.504041] pci 0000:00:02.0: enabling Extended Tags\r\n[    0.523026] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400\r\n[    0.526800] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]\r\n[    0.533865] pci 0000:00:02.1: enabling Extended Tags\r\n[    0.559610] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100\r\n[    0.566125] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO\r\n[    0.568506] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601\r\n[    0.576395] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]\r\n[    0.578450] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]\r\n[    0.588419] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500\r\n[    0.595372] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]\r\n[    0.601665] acpiphp: Slot [0] registered\r\n[    0.603776] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000\r\n[    0.606822] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]\r\n[    0.611110] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]\r\n[    0.612889] pci 0000:01:00.0: enabling Extended Tags\r\n[    0.627421] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    0.627802] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    0.628182] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    0.630741] acpiphp: Slot [0-2] registered\r\n[    0.630927] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    0.631308] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    0.631706] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    0.634297] acpiphp: Slot [0-3] registered\r\n[    0.634482] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    0.634864] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    0.635241] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    0.637765] acpiphp: Slot [0-4] registered\r\n[    0.637952] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    0.638333] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    0.638697] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    0.641281] acpiphp: Slot [0-5] registered\r\n[    0.643357] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000\r\n[    0.646418] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]\r\n[    0.650846] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]\r\n[    0.652648] pci 0000:05:00.0: enabling Extended Tags\r\n[    0.667035] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    0.667439] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    0.667820] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    0.670447] acpiphp: Slot [0-6] registered\r\n[    0.672516] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000\r\n[    0.675663] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]\r\n[    0.679651] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]\r\n[    0.682376] pci 0000:06:00.0: enabling Extended Tags\r\n[    0.696453] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    0.696829] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    0.697202] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    0.699732] acpiphp: Slot [0-7] registered\r\n[    0.701828] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000\r\n[    0.720081] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]\r\n[    0.750952] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]\r\n[    0.761124] pci 0000:07:00.0: enabling Extended Tags\r\n[    0.779076] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    0.779452] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    0.779831] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    0.782409] acpiphp: Slot [0-8] registered\r\n[    0.784301] pci 0000:08:00.0: [1af4:1045] type 00 class 0x00ff00\r\n[    0.787162] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]\r\n[    0.791275] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]\r\n[    0.793034] pci 0000:08:00.0: enabling Extended Tags\r\n[    0.807534] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    0.807916] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    0.808283] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    0.810924] acpiphp: Slot [0-9] registered\r\n[    0.812987] pci 0000:09:00.0: [1af4:1044] type 00 class 0x00ff00\r\n[    0.816075] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]\r\n[    0.820364] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]\r\n[    0.822209] pci 0000:09:00.0: enabling Extended Tags\r\n[    0.836340] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    0.836718] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    0.837099] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    0.839572] acpiphp: Slot [0-10] registered\r\n[    0.839755] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    0.840119] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    0.840590] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    0.848697] pci_bus 0000:00: on NUMA node 0\r\n[    0.849536] ACPI: PCI: Interrupt link LNKA configured for IRQ 10\r\n[    0.849915] ACPI: PCI: Interrupt link LNKB configured for IRQ 10\r\n[    0.850293] ACPI: PCI: Interrupt link LNKC configured for IRQ 11\r\n[    0.850952] ACPI: PCI: Interrupt link LNKD configured for IRQ 11\r\n[    0.851334] ACPI: PCI: Interrupt link LNKE configured for IRQ 10\r\n[    0.851712] ACPI: PCI: Interrupt link LNKF configured for IRQ 10\r\n[    0.852114] ACPI: PCI: Interrupt link LNKG configured for IRQ 11\r\n[    0.852494] ACPI: PCI: Interrupt link LNKH configured for IRQ 11\r\n[    0.852675] ACPI: PCI: Interrupt link GSIA configured for IRQ 16\r\n[    0.852679] ACPI: PCI: Interrupt link GSIB configured for IRQ 17\r\n[    0.852683] ACPI: PCI: Interrupt link GSIC configured for IRQ 18\r\n[    0.852687] ACPI: PCI: Interrupt link GSID configured for IRQ 19\r\n[    0.852691] ACPI: PCI: Interrupt link GSIE configured for IRQ 20\r\n[    0.852694] ACPI: PCI: Interrupt link GSIF configured for IRQ 21\r\n[    0.852698] ACPI: PCI: Interrupt link GSIG configured for IRQ 22\r\n[    0.852702] ACPI: PCI: Interrupt link GSIH configured for IRQ 23\r\n[    0.853469] iommu: Default domain type: Translated\r\n[    0.853469] iommu: DMA domain TLB invalidation policy: lazy mode\r\n[    0.853528] SCSI subsystem initialized\r\n[    0.853571] libata version 3.00 loaded.\r\n[    0.853581] pps_core: LinuxPPS API ver. 1 registered\r\n[    0.853581] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;\r\n[    0.853585] PTP clock support registered\r\n[    0.853759] PCI: Using ACPI for IRQ routing\r\n[    1.593744] PCI: pci_cache_line_size set to 64 bytes\r\n[    1.597575] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]\r\n[    1.597578] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]\r\n[    1.597654] clocksource: Switched to clocksource hyperv_clocksource_tsc_page\r\n[    1.597736] VFS: Disk quotas dquot_6.6.0\r\n[    1.597743] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\r\n[    1.597772] pnp: PnP ACPI init\r\n[    1.597862] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved\r\n[    1.598695] pnp: PnP ACPI: found 5 devices\r\n[    1.598695] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns\r\n[    1.598695] NET: Registered PF_INET protocol family\r\n[    1.598695] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)\r\n[    1.598695] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    1.598695] Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)\r\n[    1.598695] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r\n[    1.598695] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)\r\n[    1.598695] TCP: Hash tables configured (established 1024 bind 1024)\r\n[    1.598695] MPTCP token hash table entries: 256 (order: 0, 6144 bytes, linear)\r\n[    1.598695] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.598695] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.598695] NET: Registered PF_UNIX/PF_LOCAL protocol family\r\n[    1.598695] NET: Registered PF_XDP protocol family\r\n[    1.598695] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000\r\n[    1.598695] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000\r\n[    1.598695] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000\r\n[    1.598695] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000\r\n[    1.598695] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000\r\n[    1.598695] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000\r\n[    1.598695] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000\r\n[    1.598695] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000\r\n[    1.598695] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000\r\n[    1.598695] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000\r\n[    1.598695] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]\r\n[    1.598695] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]\r\n[    1.598695] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]\r\n[    1.598695] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]\r\n[    1.598695] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]\r\n[    1.598695] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]\r\n[    1.598695] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]\r\n[    1.598695] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]\r\n[    1.598695] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]\r\n[    1.598695] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]\r\n[    1.598695] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    1.598695] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]\r\n[    1.599540] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    1.600471] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.602227] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    1.602427] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]\r\n[    1.603864] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    1.604792] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.606602] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    1.606804] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]\r\n[    1.608215] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    1.609509] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.610859] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    1.611077] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]\r\n[    1.612291] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    1.613222] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.615071] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    1.615288] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]\r\n[    1.616724] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    1.617546] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.620443] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    1.620768] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]\r\n[    1.621897] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    1.622618] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.623900] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    1.624105] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]\r\n[    1.625223] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    1.625865] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.627549] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    1.627769] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]\r\n[    1.628838] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    1.629586] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.631392] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    1.631657] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]\r\n[    1.632598] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    1.633328] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.634957] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    1.635159] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]\r\n[    1.636263] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    1.637149] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.638770] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]\r\n[    1.638771] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]\r\n[    1.638772] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]\r\n[    1.638773] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]\r\n[    1.638774] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]\r\n[    1.638775] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]\r\n[    1.638776] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]\r\n[    1.638776] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]\r\n[    1.638777] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.638778] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]\r\n[    1.638779] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]\r\n[    1.638779] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.638780] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]\r\n[    1.638781] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]\r\n[    1.638781] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.638782] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]\r\n[    1.638783] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]\r\n[    1.638784] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.638784] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]\r\n[    1.638785] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]\r\n[    1.638786] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.638786] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]\r\n[    1.638787] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]\r\n[    1.638788] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.638788] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]\r\n[    1.638789] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]\r\n[    1.638790] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.638791] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]\r\n[    1.638791] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]\r\n[    1.638792] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.638793] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]\r\n[    1.638793] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]\r\n[    1.638794] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.638795] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]\r\n[    1.638795] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]\r\n[    1.638796] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.643736] PCI: CLS 0 bytes, default 64\r\n[    1.643917] Initialise system trusted keyrings\r\n[    1.643960] Unpacking initramfs...\r\n[    1.669864] workingset: timestamp_bits=46 max_order=15 bucket_order=0\r\n[    1.669870] zbud: loaded\r\n[    1.669922] Key type asymmetric registered\r\n[    1.669923] Asymmetric key parser 'x509' registered\r\n[    1.669938] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 247)\r\n[    1.670730] io scheduler mq-deadline registered\r\n[    1.670731] io scheduler kyber registered\r\n[    1.670736] io scheduler bfq registered\r\n[    1.671108] ACPI: \\_SB_.GSIF: Enabled at IRQ 21\r\n[    1.679406] pcieport 0000:00:01.0: PME: Signaling with IRQ 24\r\n[    1.698068] pcieport 0000:00:01.1: PME: Signaling with IRQ 25\r\n[    1.716977] pcieport 0000:00:01.2: PME: Signaling with IRQ 26\r\n[    1.734597] pcieport 0000:00:01.3: PME: Signaling with IRQ 27\r\n[    1.752266] pcieport 0000:00:01.4: PME: Signaling with IRQ 28\r\n[    1.770416] pcieport 0000:00:01.5: PME: Signaling with IRQ 29\r\n[    1.783416] pcieport 0000:00:01.6: PME: Signaling with IRQ 30\r\n[    1.795094] pcieport 0000:00:01.7: PME: Signaling with IRQ 31\r\n[    1.799546] ACPI: \\_SB_.GSIG: Enabled at IRQ 22\r\n[    1.805930] pcieport 0000:00:02.0: PME: Signaling with IRQ 32\r\n[    1.816013] pcieport 0000:00:02.1: PME: Signaling with IRQ 33\r\n[    1.820353] ERST DBG: ERST support is disabled.\r\n[    1.959824] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled\r\n[    1.961908] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\r\n[    2.320412] Freeing initrd memory: 8776K\r\n[    2.321737] VMware PVSCSI driver - version 1.0.7.0-k\r\n[    2.321759] ahci 0000:00:1f.2: version 3.0\r\n[    2.322069] ACPI: \\_SB_.GSIA: Enabled at IRQ 16\r\n[    2.345989] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode\r\n[    2.345991] ahci 0000:00:1f.2: flags: 64bit ncq only \r\n[    2.368354] scsi host0: ahci\r\n[    2.368457] scsi host1: ahci\r\n[    2.368539] scsi host2: ahci\r\n[    2.368608] scsi host3: ahci\r\n[    2.368678] scsi host4: ahci\r\n[    2.368757] scsi host5: ahci\r\n[    2.369080] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 36\r\n[    2.369249] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 36\r\n[    2.369424] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 36\r\n[    2.369577] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 36\r\n[    2.369854] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 36\r\n[    2.370016] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 36\r\n[    2.370070] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\r\n[    2.389138] serio: i8042 KBD port at 0x60,0x64 irq 1\r\n[    2.389141] serio: i8042 AUX port at 0x60,0x64 irq 12\r\n[    2.389155] rtc_cmos 00:03: RTC can wake from S4\r\n[    2.406705] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input0\r\n[    2.427862] rtc_cmos 00:03: registered as rtc0\r\n[    2.429445] rtc_cmos 00:03: setting system clock to 2025-11-07T23:03:40 UTC (1762556620)\r\n[    2.430410] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs\r\n[    2.430419] intel_pstate: CPU model not supported\r\n[    2.430494] gre: GRE over IPv4 demultiplexor driver\r\n[    2.439377] NET: Registered PF_INET6 protocol family\r\n[    2.439495] Segment Routing with IPv6\r\n[    2.439498] In-situ OAM (IOAM) with IPv6\r\n[    2.439524] Key type dns_resolver registered\r\n[    2.439546] IPI shorthand broadcast: enabled\r\n[    2.440203] sched_clock: Marking stable (2320005200, 119769000)-&gt;(2723708600, -283934400)\r\n[    2.445586] registered taskstats version 1\r\n[    2.445630] Loading compiled-in X.509 certificates\r\n[    2.447468] Loaded X.509 cert 'alpinelinux.org: Alpine Linux kernel key: d76a695f66ad9cd28f5c22a8508f36e91f521f7a'\r\n[    2.448777] Key type .fscrypt registered\r\n[    2.448778] Key type fscrypt-provisioning registered\r\n[    2.745373] ata1: SATA link down (SStatus 0 SControl 300)\r\n[    2.750672] ata2: SATA link down (SStatus 0 SControl 300)\r\n[    2.756588] ata3: SATA link down (SStatus 0 SControl 300)\r\n[    2.762147] ata5: SATA link down (SStatus 0 SControl 300)\r\n[    2.767322] ata4: SATA link down (SStatus 0 SControl 300)\r\n[    2.772557] ata6: SATA link down (SStatus 0 SControl 300)\r\n[    2.774515] Freeing unused kernel image (initmem) memory: 2696K\r\n[    2.774517] Write protecting the kernel read-only data: 24576k\r\n[    2.774996] Freeing unused kernel image (rodata/data gap) memory: 2008K\r\n[    2.775000] rodata_test: all tests were successful\r\n[    2.775003] Run /init as init process\r\n[    2.775004]   with arguments:\r\n[    2.775004]     /init\r\n[    2.775005]   with environment:\r\n[    2.775005]     HOME=/\r\n[    2.775006]     TERM=linux\r\n[    2.775006]     BOOT_IMAGE=/boot/vmlinuz-virt\r\n[    2.775007]     modules=loop,squashfs,sd-mod,usb-storage\r\n[    2.778480] Alpine Init 3.10.1-r0\r\n[    2.778766] Loading boot drivers...\r\n[    2.781251] loop: module loaded\r\n[    2.782556] squashfs: version 4.0 (2009/01/31) Phillip Lougher\r\n[    2.792347] ACPI: bus type USB registered\r\n[    2.792364] usbcore: registered new interface driver usbfs\r\n[    2.792369] usbcore: registered new interface driver hub\r\n[    2.792373] usbcore: registered new device driver usb\r\n[    2.793760] usbcore: registered new interface driver usb-storage\r\n[    2.808123] ACPI: bus type drm_connector registered\r\n[    2.814777] Loading boot drivers: ok.\r\n[    2.815352] Mounting boot media...\r\n[    2.865466] scsi host6: Virtio SCSI HBA\r\n[    2.911631] Free page reporting enabled\r\n[    2.952211] virtio_blk virtio3: 1/0/0 default/read/poll queues\r\n[    2.969975] virtio_blk virtio3: [vda] 124928 512-byte logical blocks (64.0 MB/61.0 MiB)\r\n[    2.971147]  vda: vda1 vda2\r\n[    3.050539] ISO 9660 Extensions: Microsoft Joliet Level 3\r\n[    3.051031] ISO 9660 Extensions: RRIP_1991A\r\n[    3.326398] Mounting boot media: ok.\r\n[    3.342968] Installing packages to root filesystem...\r\n[    3.555677] Installing packages to root filesystem: ok.\r\n[    3.783441] loop0: detected capacity change from 0 to 39312\r\n[    3.979083] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input3\r\n[    4.009882] ACPI: button: Power Button [PWRF]\r\n[    4.052457] cryptd: max_cpu_qlen set to 1000\r\n[    4.096362] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input4\r\n[    4.130028] mousedev: PS/2 mouse device common for all mice\r\n[    4.219456] NET: Registered PF_PACKET protocol family\r\nlocalhost:~# " "\r\n[    0.000000] Linux version 6.6.34-1-virt (buildozer@build-3-20-x86_64) (gcc (Alpine 13.2.1_git20240309) 13.2.1 20240309, GNU ld (GNU Binutils) 2.42) #2-Alpine SMP PREEMPT_DYNAMIC Tue, 18 Jun 2024 10:38:37 +0000\r\n[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.000000] BIOS-provided physical RAM map:\r\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable\r\n[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable\r\n[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved\r\n[    0.000000] NX (Execute Disable) protection: active\r\n[    0.000000] APIC: Static calls initialized\r\n[    0.000000] SMBIOS 2.8 present.\r\n[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014\r\n[    0.000000] Hypervisor detected: Microsoft Hyper-V\r\n[    0.000000] Hyper-V: privilege flags low 0xe7e, high 0x0, hints 0x60624, misc 0xe0130\r\n[    0.000000] Hyper-V: Host Build 10.0.26100.1381-1-0\r\n[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480\r\n[    0.000000] Hyper-V: Using hypercall for remote TLB flush\r\n[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000000] clocksource: hyperv_clocksource_msr: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000001] tsc: Marking TSC unstable due to running on Hyper-V\r\n[    0.000003] tsc: Detected 2299.999 MHz processor\r\n[    0.000193] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved\r\n[    0.000195] e820: remove [mem 0x000a0000-0x000fffff] usable\r\n[    0.000198] last_pfn = 0x7fdd max_arch_pfn = 0x400000000\r\n[    0.000218] MTRR map: 4 entries (3 fixed + 1 variable; max 19), built from 8 variable MTRRs\r\n[    0.000220] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \r\n[    0.000252] Using GB pages for direct mapping\r\n[    0.000326] RAMDISK: [mem 0x0774b000-0x07fdcfff]\r\n[    0.000327] ACPI: Early table checksum verification disabled\r\n[    0.000329] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )\r\n[    0.000331] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000334] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000337] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000339] ACPI: FACS 0x0000000007FE0000 000040\r\n[    0.000341] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000342] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000344] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000345] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000347] ACPI: Reserving FACP table memory at [mem 0x7fe2947-0x7fe2a3a]\r\n[    0.000347] ACPI: Reserving DSDT table memory at [mem 0x7fe0040-0x7fe2946]\r\n[    0.000348] ACPI: Reserving FACS table memory at [mem 0x7fe0000-0x7fe003f]\r\n[    0.000348] ACPI: Reserving APIC table memory at [mem 0x7fe2a3b-0x7fe2aca]\r\n[    0.000349] ACPI: Reserving HPET table memory at [mem 0x7fe2acb-0x7fe2b02]\r\n[    0.000349] ACPI: Reserving MCFG table memory at [mem 0x7fe2b03-0x7fe2b3e]\r\n[    0.000350] ACPI: Reserving WAET table memory at [mem 0x7fe2b3f-0x7fe2b66]\r\n[    0.000571] Zone ranges:\r\n[    0.000571]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]\r\n[    0.000572]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]\r\n[    0.000573]   Normal   empty\r\n[    0.000574] Movable zone start for each node\r\n[    0.000574] Early memory node ranges\r\n[    0.000574]   node   0: [mem 0x0000000000001000-0x000000000009efff]\r\n[    0.000575]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]\r\n[    0.000576] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]\r\n[    0.000578] On node 0, zone DMA: 1 pages in unavailable ranges\r\n[    0.000589] On node 0, zone DMA: 97 pages in unavailable ranges\r\n[    0.001184] On node 0, zone DMA32: 35 pages in unavailable ranges\r\n[    0.024444] ACPI: PM-Timer IO Port: 0x608\r\n[    0.024450] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\r\n[    0.026262] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23\r\n[    0.026265] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)\r\n[    0.026266] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\r\n[    0.026267] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\r\n[    0.026268] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\r\n[    0.026268] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\r\n[    0.026271] ACPI: Using ACPI (MADT) for SMP configuration information\r\n[    0.026272] ACPI: HPET id: 0x8086a201 base: 0xfed00000\r\n[    0.026274] smpboot: Allowing 4 CPUs, 3 hotplug CPUs\r\n[    0.026280] [mem 0x08000000-0xafffffff] available for PCI devices\r\n[    0.026281] Booting paravirtualized kernel on Hyper-V\r\n[    0.026282] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.030521] setup_percpu: NR_CPUS:256 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1\r\n[    0.031707] percpu: Embedded 57 pages/cpu s195560 r8192 d29720 u524288\r\n[    0.031711] pcpu-alloc: s195560 r8192 d29720 u524288 alloc=1*2097152\r\n[    0.031713] pcpu-alloc: [0] 0 1 2 3 \r\n[    0.031723] Hyper-V: PV spinlocks enabled\r\n[    0.031725] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    0.031727] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.031764] Unknown kernel command line parameters \"BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage\", will be passed to user space.\r\n[    0.031772] random: crng init done\r\n[    0.031789] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r\n[    0.031797] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r\n[    0.031850] Built 1 zonelists, mobility grouping on.  Total pages: 31965\r\n[    0.032825] mem auto-init: stack:all(zero), heap alloc:on, heap free:off\r\n[    0.033046] Memory: 80436K/130540K available (14336K kernel code, 1799K rwdata, 8232K rodata, 2696K init, 2032K bss, 49844K reserved, 0K cma-reserved)\r\n[    0.033178] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1\r\n[    0.033724] Dynamic Preempt: none\r\n[    0.033753] rcu: Preemptible hierarchical RCU implementation.\r\n[    0.033753] rcu: \tRCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=4.\r\n[    0.033754] \tTrampoline variant of Tasks RCU enabled.\r\n[    0.033754] \tTracing variant of Tasks RCU enabled.\r\n[    0.033755] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.\r\n[    0.033755] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4\r\n[    0.035340] NR_IRQS: 16640, nr_irqs: 456, preallocated irqs: 16\r\n[    0.036616] rcu: srcu_init: Setting srcu_struct sizes based on contention.\r\n[    0.039007] kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)\r\n[    0.041386] Console: colour *CGA 80x25\r\n[    0.041387] printk: console [tty0] enabled\r\n[    0.041398] ACPI: Core revision 20230628\r\n[    0.045779] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns\r\n[    0.048956] APIC: Switch to symmetric I/O mode setup\r\n[    0.070947] x2apic enabled\r\n[    0.071225] APIC: Switched APIC routing to: physical x2apic\r\n[    0.071239] Hyper-V: Disabling IBT because of Hyper-V bug\r\n[    0.071240] Hyper-V: Using IPI hypercalls\r\n[    0.071241] APIC: send_IPI() replaced with hv_send_ipi()\r\n[    0.071245] APIC: send_IPI_mask() replaced with hv_send_ipi_mask()\r\n[    0.071247] APIC: send_IPI_mask_allbutself() replaced with hv_send_ipi_mask_allbutself()\r\n[    0.071249] APIC: send_IPI_allbutself() replaced with hv_send_ipi_allbutself()\r\n[    0.071250] APIC: send_IPI_all() replaced with hv_send_ipi_all()\r\n[    0.071252] APIC: send_IPI_self() replaced with hv_send_ipi_self()\r\n[    0.156820] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1\r\n[    0.158698] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=22999990)\r\n[    0.158771] x86/cpu: User Mode Instruction Prevention (UMIP) activated\r\n[    0.158779] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0\r\n[    0.158780] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0\r\n[    0.158784] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization\r\n[    0.158786] Spectre V2 : Mitigation: Retpolines\r\n[    0.158786] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch\r\n[    0.158787] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT\r\n[    0.158787] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!\r\n[    0.158788] RETBleed: Vulnerable\r\n[    0.158789] Speculative Store Bypass: Vulnerable\r\n[    0.158789] MMIO Stale Data: Unknown: No mitigations\r\n[    0.158804] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'\r\n[    0.158805] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'\r\n[    0.158806] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'\r\n[    0.158807] x86/fpu: Supporting XSAVE feature 0x800: 'Control-flow User registers'\r\n[    0.158808] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256\r\n[    0.158809] x86/fpu: xstate_offset[11]:  832, xstate_sizes[11]:   16\r\n[    0.158810] x86/fpu: Enabled xstate features 0x807, context size is 848 bytes, using 'compacted' format.\r\n[    0.180638] pid_max: default: 32768 minimum: 301\r\n[    0.180663] LSM: initializing lsm=lockdown,capability,landlock,integrity\r\n[    0.180681] landlock: Up and running.\r\n[    0.180694] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.180696] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.182091] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)\r\n[    0.182208] RCU Tasks: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.182216] RCU Tasks Trace: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.182224] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.\r\n[    0.182237] signal: max sigframe size: 1776\r\n[    0.182255] rcu: Hierarchical SRCU implementation.\r\n[    0.182255] rcu: \tMax phase no-delay instances is 1000.\r\n[    0.182378] NMI watchdog: Perf NMI watchdog permanently disabled\r\n[    0.182410] smp: Bringing up secondary CPUs ...\r\n[    0.182414] smp: Brought up 1 node, 1 CPU\r\n[    0.182415] smpboot: Max logical packages: 4\r\n[    0.182415] ----------------\r\n[    0.182416] | NMI testsuite:\r\n[    0.182416] --------------------\r\n[    0.182416]   remote IPI:  ok  |\r\n[    0.182417]    local IPI:  ok  |\r\n[    0.182425] --------------------\r\n[    0.182425] Good, all   2 testcases passed! |\r\n[    0.182426] ---------------------------------\r\n[    0.182426] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)\r\n[    0.182511] devtmpfs: initialized\r\n[    0.182535] x86/mm: Memory block size: 128MB\r\n[    0.182611] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.182620] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)\r\n[    0.183891] NET: Registered PF_NETLINK/PF_ROUTE protocol family\r\n[    0.183933] audit: initializing netlink subsys (disabled)\r\n[    0.183981] thermal_sys: Registered thermal governor 'step_wise'\r\n[    0.183986] audit: type=2000 audit(1762556618.020:1): state=initialized audit_enabled=0 res=1\r\n[    0.183988] cpuidle: using governor ladder\r\n[    0.183990] cpuidle: using governor menu\r\n[    0.184006] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5\r\n[    0.185606] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)\r\n[    0.185608] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved as E820 entry\r\n[    0.185613] PCI: Using configuration type 1 for base access\r\n[    0.185675] kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.\r\n[    0.187938] HugeTLB: registered 1.00 GiB page size, pre-allocated 0 pages\r\n[    0.187939] HugeTLB: 16380 KiB vmemmap can be freed for a 1.00 GiB page\r\n[    0.187940] HugeTLB: registered 2.00 MiB page size, pre-allocated 0 pages\r\n[    0.187941] HugeTLB: 28 KiB vmemmap can be freed for a 2.00 MiB page\r\n[    0.188040] ACPI: Added _OSI(Module Device)\r\n[    0.188041] ACPI: Added _OSI(Processor Device)\r\n[    0.188041] ACPI: Added _OSI(3.0 _SCP Extensions)\r\n[    0.188042] ACPI: Added _OSI(Processor Aggregator Device)\r\n[    0.188695] ACPI: 1 ACPI AML tables successfully acquired and loaded\r\n[    0.192890] ACPI: _OSC evaluation for CPUs failed, trying _PDC\r\n[    0.192964] ACPI: Interpreter enabled\r\n[    0.192970] ACPI: PM: (supports S0 S3 S5)\r\n[    0.192971] ACPI: Using IOAPIC for interrupt routing\r\n[    0.192981] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\r\n[    0.192982] PCI: Using E820 reservations for host bridge windows\r\n[    0.193432] ACPI: Enabled 2 GPEs in block 00 to 3F\r\n[    0.200531] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\r\n[    0.200534] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]\r\n[    0.200557] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]\r\n[    0.200586] acpi PNP0A08:00: _OSC: OS now controls [PME PCIeCapability]\r\n[    0.204006] PCI host bridge to bus 0000:00\r\n[    0.204007] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]\r\n[    0.204009] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]\r\n[    0.204010] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]\r\n[    0.204011] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]\r\n[    0.204012] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]\r\n[    0.204013] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]\r\n[    0.204015] pci_bus 0000:00: root bus resource [bus 00-ff]\r\n[    0.205105] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000\r\n[    0.213209] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400\r\n[    0.216536] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]\r\n[    0.224539] pci 0000:00:01.0: enabling Extended Tags\r\n[    0.244251] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400\r\n[    0.248077] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]\r\n[    0.256220] pci 0000:00:01.1: enabling Extended Tags\r\n[    0.275826] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400\r\n[    0.279570] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]\r\n[    0.287280] pci 0000:00:01.2: enabling Extended Tags\r\n[    0.306758] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400\r\n[    0.309854] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]\r\n[    0.317838] pci 0000:00:01.3: enabling Extended Tags\r\n[    0.338513] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400\r\n[    0.342125] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]\r\n[    0.349364] pci 0000:00:01.4: enabling Extended Tags\r\n[    0.368667] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400\r\n[    0.372347] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]\r\n[    0.380276] pci 0000:00:01.5: enabling Extended Tags\r\n[    0.399897] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400\r\n[    0.410065] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]\r\n[    0.441437] pci 0000:00:01.6: enabling Extended Tags\r\n[    0.459354] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400\r\n[    0.463104] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]\r\n[    0.471947] pci 0000:00:01.7: enabling Extended Tags\r\n[    0.492185] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400\r\n[    0.495754] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]\r\n[    0.504041] pci 0000:00:02.0: enabling Extended Tags\r\n[    0.523026] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400\r\n[    0.526800] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]\r\n[    0.533865] pci 0000:00:02.1: enabling Extended Tags\r\n[    0.559610] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100\r\n[    0.566125] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO\r\n[    0.568506] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601\r\n[    0.576395] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]\r\n[    0.578450] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]\r\n[    0.588419] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500\r\n[    0.595372] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]\r\n[    0.601665] acpiphp: Slot [0] registered\r\n[    0.603776] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000\r\n[    0.606822] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]\r\n[    0.611110] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]\r\n[    0.612889] pci 0000:01:00.0: enabling Extended Tags\r\n[    0.627421] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    0.627802] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    0.628182] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    0.630741] acpiphp: Slot [0-2] registered\r\n[    0.630927] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    0.631308] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    0.631706] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    0.634297] acpiphp: Slot [0-3] registered\r\n[    0.634482] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    0.634864] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    0.635241] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    0.637765] acpiphp: Slot [0-4] registered\r\n[    0.637952] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    0.638333] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    0.638697] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    0.641281] acpiphp: Slot [0-5] registered\r\n[    0.643357] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000\r\n[    0.646418] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]\r\n[    0.650846] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]\r\n[    0.652648] pci 0000:05:00.0: enabling Extended Tags\r\n[    0.667035] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    0.667439] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    0.667820] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    0.670447] acpiphp: Slot [0-6] registered\r\n[    0.672516] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000\r\n[    0.675663] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]\r\n[    0.679651] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]\r\n[    0.682376] pci 0000:06:00.0: enabling Extended Tags\r\n[    0.696453] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    0.696829] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    0.697202] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    0.699732] acpiphp: Slot [0-7] registered\r\n[    0.701828] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000\r\n[    0.720081] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]\r\n[    0.750952] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]\r\n[    0.761124] pci 0000:07:00.0: enabling Extended Tags\r\n[    0.779076] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    0.779452] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    0.779831] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    0.782409] acpiphp: Slot [0-8] registered\r\n[    0.784301] pci 0000:08:00.0: [1af4:1045] type 00 class 0x00ff00\r\n[    0.787162] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]\r\n[    0.791275] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]\r\n[    0.793034] pci 0000:08:00.0: enabling Extended Tags\r\n[    0.807534] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    0.807916] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    0.808283] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    0.810924] acpiphp: Slot [0-9] registered\r\n[    0.812987] pci 0000:09:00.0: [1af4:1044] type 00 class 0x00ff00\r\n[    0.816075] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]\r\n[    0.820364] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]\r\n[    0.822209] pci 0000:09:00.0: enabling Extended Tags\r\n[    0.836340] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    0.836718] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    0.837099] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    0.839572] acpiphp: Slot [0-10] registered\r\n[    0.839755] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    0.840119] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    0.840590] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    0.848697] pci_bus 0000:00: on NUMA node 0\r\n[    0.849536] ACPI: PCI: Interrupt link LNKA configured for IRQ 10\r\n[    0.849915] ACPI: PCI: Interrupt link LNKB configured for IRQ 10\r\n[    0.850293] ACPI: PCI: Interrupt link LNKC configured for IRQ 11\r\n[    0.850952] ACPI: PCI: Interrupt link LNKD configured for IRQ 11\r\n[    0.851334] ACPI: PCI: Interrupt link LNKE configured for IRQ 10\r\n[    0.851712] ACPI: PCI: Interrupt link LNKF configured for IRQ 10\r\n[    0.852114] ACPI: PCI: Interrupt link LNKG configured for IRQ 11\r\n[    0.852494] ACPI: PCI: Interrupt link LNKH configured for IRQ 11\r\n[    0.852675] ACPI: PCI: Interrupt link GSIA configured for IRQ 16\r\n[    0.852679] ACPI: PCI: Interrupt link GSIB configured for IRQ 17\r\n[    0.852683] ACPI: PCI: Interrupt link GSIC configured for IRQ 18\r\n[    0.852687] ACPI: PCI: Interrupt link GSID configured for IRQ 19\r\n[    0.852691] ACPI: PCI: Interrupt link GSIE configured for IRQ 20\r\n[    0.852694] ACPI: PCI: Interrupt link GSIF configured for IRQ 21\r\n[    0.852698] ACPI: PCI: Interrupt link GSIG configured for IRQ 22\r\n[    0.852702] ACPI: PCI: Interrupt link GSIH configured for IRQ 23\r\n[    0.853469] iommu: Default domain type: Translated\r\n[    0.853469] iommu: DMA domain TLB invalidation policy: lazy mode\r\n[    0.853528] SCSI subsystem initialized\r\n[    0.853571] libata version 3.00 loaded.\r\n[    0.853581] pps_core: LinuxPPS API ver. 1 registered\r\n[    0.853581] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;\r\n[    0.853585] PTP clock support registered\r\n[    0.853759] PCI: Using ACPI for IRQ routing\r\n[    1.593744] PCI: pci_cache_line_size set to 64 bytes\r\n[    1.597575] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]\r\n[    1.597578] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]\r\n[    1.597654] clocksource: Switched to clocksource hyperv_clocksource_tsc_page\r\n[    1.597736] VFS: Disk quotas dquot_6.6.0\r\n[    1.597743] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\r\n[    1.597772] pnp: PnP ACPI init\r\n[    1.597862] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved\r\n[    1.598695] pnp: PnP ACPI: found 5 devices\r\n[    1.598695] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns\r\n[    1.598695] NET: Registered PF_INET protocol family\r\n[    1.598695] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)\r\n[    1.598695] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    1.598695] Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)\r\n[    1.598695] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r\n[    1.598695] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)\r\n[    1.598695] TCP: Hash tables configured (established 1024 bind 1024)\r\n[    1.598695] MPTCP token hash table entries: 256 (order: 0, 6144 bytes, linear)\r\n[    1.598695] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.598695] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.598695] NET: Registered PF_UNIX/PF_LOCAL protocol family\r\n[    1.598695] NET: Registered PF_XDP protocol family\r\n[    1.598695] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000\r\n[    1.598695] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000\r\n[    1.598695] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000\r\n[    1.598695] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000\r\n[    1.598695] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000\r\n[    1.598695] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000\r\n[    1.598695] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000\r\n[    1.598695] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000\r\n[    1.598695] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000\r\n[    1.598695] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000\r\n[    1.598695] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]\r\n[    1.598695] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]\r\n[    1.598695] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]\r\n[    1.598695] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]\r\n[    1.598695] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]\r\n[    1.598695] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]\r\n[    1.598695] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]\r\n[    1.598695] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]\r\n[    1.598695] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]\r\n[    1.598695] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]\r\n[    1.598695] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    1.598695] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]\r\n[    1.599540] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    1.600471] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.602227] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    1.602427] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]\r\n[    1.603864] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    1.604792] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.606602] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    1.606804] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]\r\n[    1.608215] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    1.609509] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.610859] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    1.611077] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]\r\n[    1.612291] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    1.613222] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.615071] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    1.615288] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]\r\n[    1.616724] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    1.617546] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.620443] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    1.620768] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]\r\n[    1.621897] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    1.622618] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.623900] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    1.624105] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]\r\n[    1.625223] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    1.625865] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.627549] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    1.627769] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]\r\n[    1.628838] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    1.629586] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.631392] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    1.631657] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]\r\n[    1.632598] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    1.633328] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.634957] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    1.635159] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]\r\n[    1.636263] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    1.637149] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.638770] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]\r\n[    1.638771] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]\r\n[    1.638772] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]\r\n[    1.638773] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]\r\n[    1.638774] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]\r\n[    1.638775] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]\r\n[    1.638776] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]\r\n[    1.638776] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]\r\n[    1.638777] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.638778] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]\r\n[    1.638779] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]\r\n[    1.638779] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.638780] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]\r\n[    1.638781] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]\r\n[    1.638781] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.638782] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]\r\n[    1.638783] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]\r\n[    1.638784] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.638784] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]\r\n[    1.638785] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]\r\n[    1.638786] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.638786] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]\r\n[    1.638787] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]\r\n[    1.638788] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.638788] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]\r\n[    1.638789] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]\r\n[    1.638790] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.638791] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]\r\n[    1.638791] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]\r\n[    1.638792] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.638793] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]\r\n[    1.638793] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]\r\n[    1.638794] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.638795] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]\r\n[    1.638795] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]\r\n[    1.638796] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.643736] PCI: CLS 0 bytes, default 64\r\n[    1.643917] Initialise system trusted keyrings\r\n[    1.643960] Unpacking initramfs...\r\n[    1.669864] workingset: timestamp_bits=46 max_order=15 bucket_order=0\r\n[    1.669870] zbud: loaded\r\n[    1.669922] Key type asymmetric registered\r\n[    1.669923] Asymmetric key parser 'x509' registered\r\n[    1.669938] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 247)\r\n[    1.670730] io scheduler mq-deadline registered\r\n[    1.670731] io scheduler kyber registered\r\n[    1.670736] io scheduler bfq registered\r\n[    1.671108] ACPI: \\_SB_.GSIF: Enabled at IRQ 21\r\n[    1.679406] pcieport 0000:00:01.0: PME: Signaling with IRQ 24\r\n[    1.698068] pcieport 0000:00:01.1: PME: Signaling with IRQ 25\r\n[    1.716977] pcieport 0000:00:01.2: PME: Signaling with IRQ 26\r\n[    1.734597] pcieport 0000:00:01.3: PME: Signaling with IRQ 27\r\n[    1.752266] pcieport 0000:00:01.4: PME: Signaling with IRQ 28\r\n[    1.770416] pcieport 0000:00:01.5: PME: Signaling with IRQ 29\r\n[    1.783416] pcieport 0000:00:01.6: PME: Signaling with IRQ 30\r\n[    1.795094] pcieport 0000:00:01.7: PME: Signaling with IRQ 31\r\n[    1.799546] ACPI: \\_SB_.GSIG: Enabled at IRQ 22\r\n[    1.805930] pcieport 0000:00:02.0: PME: Signaling with IRQ 32\r\n[    1.816013] pcieport 0000:00:02.1: PME: Signaling with IRQ 33\r\n[    1.820353] ERST DBG: ERST support is disabled.\r\n[    1.959824] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled\r\n[    1.961908] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\r\n[    2.320412] Freeing initrd memory: 8776K\r\n[    2.321737] VMware PVSCSI driver - version 1.0.7.0-k\r\n[    2.321759] ahci 0000:00:1f.2: version 3.0\r\n[    2.322069] ACPI: \\_SB_.GSIA: Enabled at IRQ 16\r\n[    2.345989] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode\r\n[    2.345991] ahci 0000:00:1f.2: flags: 64bit ncq only \r\n[    2.368354] scsi host0: ahci\r\n[    2.368457] scsi host1: ahci\r\n[    2.368539] scsi host2: ahci\r\n[    2.368608] scsi host3: ahci\r\n[    2.368678] scsi host4: ahci\r\n[    2.368757] scsi host5: ahci\r\n[    2.369080] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 36\r\n[    2.369249] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 36\r\n[    2.369424] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 36\r\n[    2.369577] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 36\r\n[    2.369854] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 36\r\n[    2.370016] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 36\r\n[    2.370070] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\r\n[    2.389138] serio: i8042 KBD port at 0x60,0x64 irq 1\r\n[    2.389141] serio: i8042 AUX port at 0x60,0x64 irq 12\r\n[    2.389155] rtc_cmos 00:03: RTC can wake from S4\r\n[    2.406705] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input0\r\n[    2.427862] rtc_cmos 00:03: registered as rtc0\r\n[    2.429445] rtc_cmos 00:03: setting system clock to 2025-11-07T23:03:40 UTC (1762556620)\r\n[    2.430410] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs\r\n[    2.430419] intel_pstate: CPU model not supported\r\n[    2.430494] gre: GRE over IPv4 demultiplexor driver\r\n[    2.439377] NET: Registered PF_INET6 protocol family\r\n[    2.439495] Segment Routing with IPv6\r\n[    2.439498] In-situ OAM (IOAM) with IPv6\r\n[    2.439524] Key type dns_resolver registered\r\n[    2.439546] IPI shorthand broadcast: enabled\r\n[    2.440203] sched_clock: Marking stable (2320005200, 119769000)-&gt;(2723708600, -283934400)\r\n[    2.445586] registered taskstats version 1\r\n[    2.445630] Loading compiled-in X.509 certificates\r\n[    2.447468] Loaded X.509 cert 'alpinelinux.org: Alpine Linux kernel key: d76a695f66ad9cd28f5c22a8508f36e91f521f7a'\r\n[    2.448777] Key type .fscrypt registered\r\n[    2.448778] Key type fscrypt-provisioning registered\r\n[    2.745373] ata1: SATA link down (SStatus 0 SControl 300)\r\n[    2.750672] ata2: SATA link down (SStatus 0 SControl 300)\r\n[    2.756588] ata3: SATA link down (SStatus 0 SControl 300)\r\n[    2.762147] ata5: SATA link down (SStatus 0 SControl 300)\r\n[    2.767322] ata4: SATA link down (SStatus 0 SControl 300)\r\n[    2.772557] ata6: SATA link down (SStatus 0 SControl 300)\r\n[    2.774515] Freeing unused kernel image (initmem) memory: 2696K\r\n[    2.774517] Write protecting the kernel read-only data: 24576k\r\n[    2.774996] Freeing unused kernel image (rodata/data gap) memory: 2008K\r\n[    2.775000] rodata_test: all tests were successful\r\n[    2.775003] Run /init as init process\r\n[    2.775004]   with arguments:\r\n[    2.775004]     /init\r\n[    2.775005]   with environment:\r\n[    2.775005]     HOME=/\r\n[    2.775006]     TERM=linux\r\n[    2.775006]     BOOT_IMAGE=/boot/vmlinuz-virt\r\n[    2.775007]     modules=loop,squashfs,sd-mod,usb-storage\r\n[    2.778480] Alpine Init 3.10.1-r0\r\n[    2.778766] Loading boot drivers...\r\n[    2.781251] loop: module loaded\r\n[    2.782556] squashfs: version 4.0 (2009/01/31) Phillip Lougher\r\n[    2.792347] ACPI: bus type USB registered\r\n[    2.792364] usbcore: registered new interface driver usbfs\r\n[    2.792369] usbcore: registered new interface driver hub\r\n[    2.792373] usbcore: registered new device driver usb\r\n[    2.793760] usbcore: registered new interface driver usb-storage\r\n[    2.808123] ACPI: bus type drm_connector registered\r\n[    2.814777] Loading boot drivers: ok.\r\n[    2.815352] Mounting boot media...\r\n[    2.865466] scsi host6: Virtio SCSI HBA\r\n[    2.911631] Free page reporting enabled\r\n[    2.952211] virtio_blk virtio3: 1/0/0 default/read/poll queues\r\n[    2.969975] virtio_blk virtio3: [vda] 124928 512-byte logical blocks (64.0 MB/61.0 MiB)\r\n[    2.971147]  vda: vda1 vda2\r\n[    3.050539] ISO 9660 Extensions: Microsoft Joliet Level 3\r\n[    3.051031] ISO 9660 Extensions: RRIP_1991A\r\n[    3.326398] Mounting boot media: ok.\r\n[    3.342968] Installing packages to root filesystem...\r\n[    3.555677] Installing packages to root filesystem: ok.\r\n[    3.783441] loop0: detected capacity change from 0 to 39312\r\n[    3.979083] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input3\r\n[    4.009882] ACPI: button: Power Button [PWRF]\r\n[    4.052457] cryptd: max_cpu_qlen set to 1000\r\n[    4.096362] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input4\r\n[    4.130028] mousedev: PS/2 mouse device common for all mice\r\n[    4.219456] NET: Registered PF_PACKET protocol family\r\nlocalhost:~" "" "# "] Buffer: dmesg
[    0.000000] Linux version 6.6.34-1-virt (buildozer@build-3-20-x86_64) (gcc (Alpine 13.2.1_git20240309) 13.2.1 20240309, GNU ld (GNU Binutils) 2.42) #2-Alpine SMP PREEMPT_DYNAMIC Tue, 18 Jun 2024 10:38:37 +0000
[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable
[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved
[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] APIC: Static calls initialized
[    0.000000] SMBIOS 2.8 present.
[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014
[    0.000000] Hypervisor detected: Microsoft Hyper-V
[    0.000000] Hyper-V: privilege flags low 0xe7e, high 0x0, hints 0x60624, misc 0xe0130
[    0.000000] Hyper-V: Host Build 10.0.26100.1381-1-0
[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480
[    0.000000] Hyper-V: Using hypercall for remote TLB flush
[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000000] clocksource: hyperv_clocksource_msr: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000001] tsc: Marking TSC unstable due to running on Hyper-V
[    0.000003] tsc: Detected 2299.999 MHz processor
[    0.000193] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved
[    0.000195] e820: remove [mem 0x000a0000-0x000fffff] usable
[    0.000198] last_pfn = 0x7fdd max_arch_pfn = 0x400000000
[    0.000218] MTRR map: 4 entries (3 fixed + 1 variable; max 19), built from 8 variable MTRRs
[    0.000220] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  
[    0.000252] Using GB pages for direct mapping
[    0.000326] RAMDISK: [mem 0x0774b000-0x07fdcfff]
[    0.000327] ACPI: Early table checksum verification disabled
[    0.000329] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )
[    0.000331] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000334] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000337] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000339] ACPI: FACS 0x0000000007FE0000 000040
[    0.000341] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000342] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000344] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000345] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000347] ACPI: Reserving FACP table memory at [mem 0x7fe2947-0x7fe2a3a]
[    0.000347] ACPI: Reserving DSDT table memory at [mem 0x7fe0040-0x7fe2946]
[    0.000348] ACPI: Reserving FACS table memory at [mem 0x7fe0000-0x7fe003f]
[    0.000348] ACPI: Reserving APIC table memory at [mem 0x7fe2a3b-0x7fe2aca]
[    0.000349] ACPI: Reserving HPET table memory at [mem 0x7fe2acb-0x7fe2b02]
[    0.000349] ACPI: Reserving MCFG table memory at [mem 0x7fe2b03-0x7fe2b3e]
[    0.000350] ACPI: Reserving WAET table memory at [mem 0x7fe2b3f-0x7fe2b66]
[    0.000571] Zone ranges:
[    0.000571]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.000572]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]
[    0.000573]   Normal   empty
[    0.000574] Movable zone start for each node
[    0.000574] Early memory node ranges
[    0.000574]   node   0: [mem 0x0000000000001000-0x000000000009efff]
[    0.000575]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]
[    0.000576] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]
[    0.000578] On node 0, zone DMA: 1 pages in unavailable ranges
[    0.000589] On node 0, zone DMA: 97 pages in unavailable ranges
[    0.001184] On node 0, zone DMA32: 35 pages in unavailable ranges
[    0.024444] ACPI: PM-Timer IO Port: 0x608
[    0.024450] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])
[    0.026262] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23
[    0.026265] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
[    0.026266] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)
[    0.026267] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.026268] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)
[    0.026268] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)
[    0.026271] ACPI: Using ACPI (MADT) for SMP configuration information
[    0.026272] ACPI: HPET id: 0x8086a201 base: 0xfed00000
[    0.026274] smpboot: Allowing 4 CPUs, 3 hotplug CPUs
[    0.026280] [mem 0x08000000-0xafffffff] available for PCI devices
[    0.026281] Booting paravirtualized kernel on Hyper-V
[    0.026282] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.030521] setup_percpu: NR_CPUS:256 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1
[    0.031707] percpu: Embedded 57 pages/cpu s195560 r8192 d29720 u524288
[    0.031711] pcpu-alloc: s195560 r8192 d29720 u524288 alloc=1*2097152
[    0.031713] pcpu-alloc: [0] 0 1 2 3 
[    0.031723] Hyper-V: PV spinlocks enabled
[    0.031725] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)
[    0.031727] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt
[    0.031764] Unknown kernel command line parameters "BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage", will be passed to user space.
[    0.031772] random: crng init done
[    0.031789] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)
[    0.031797] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)
[    0.031850] Built 1 zonelists, mobility grouping on.  Total pages: 31965
[    0.032825] mem auto-init: stack:all(zero), heap alloc:on, heap free:off
[    0.033046] Memory: 80436K/130540K available (14336K kernel code, 1799K rwdata, 8232K rodata, 2696K init, 2032K bss, 49844K reserved, 0K cma-reserved)
[    0.033178] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1
[    0.033724] Dynamic Preempt: none
[    0.033753] rcu: Preemptible hierarchical RCU implementation.
[    0.033753] rcu: 	RCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=4.
[    0.033754] 	Trampoline variant of Tasks RCU enabled.
[    0.033754] 	Tracing variant of Tasks RCU enabled.
[    0.033755] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.
[    0.033755] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4
[    0.035340] NR_IRQS: 16640, nr_irqs: 456, preallocated irqs: 16
[    0.036616] rcu: srcu_init: Setting srcu_struct sizes based on contention.
[    0.039007] kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)
[    0.041386] Console: colour *CGA 80x25
[    0.041387] printk: console [tty0] enabled
[    0.041398] ACPI: Core revision 20230628
[    0.045779] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns
[    0.048956] APIC: Switch to symmetric I/O mode setup
[    0.070947] x2apic enabled
[    0.071225] APIC: Switched APIC routing to: physical x2apic
[    0.071239] Hyper-V: Disabling IBT because of Hyper-V bug
[    0.071240] Hyper-V: Using IPI hypercalls
[    0.071241] APIC: send_IPI() replaced with hv_send_ipi()
[    0.071245] APIC: send_IPI_mask() replaced with hv_send_ipi_mask()
[    0.071247] APIC: send_IPI_mask_allbutself() replaced with hv_send_ipi_mask_allbutself()
[    0.071249] APIC: send_IPI_allbutself() replaced with hv_send_ipi_allbutself()
[    0.071250] APIC: send_IPI_all() replaced with hv_send_ipi_all()
[    0.071252] APIC: send_IPI_self() replaced with hv_send_ipi_self()
[    0.156820] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
[    0.158698] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=22999990)
[    0.158771] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    0.158779] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
[    0.158780] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
[    0.158784] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
[    0.158786] Spectre V2 : Mitigation: Retpolines
[    0.158786] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
[    0.158787] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT
[    0.158787] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!
[    0.158788] RETBleed: Vulnerable
[    0.158789] Speculative Store Bypass: Vulnerable
[    0.158789] MMIO Stale Data: Unknown: No mitigations
[    0.158804] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.158805] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.158806] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.158807] x86/fpu: Supporting XSAVE feature 0x800: 'Control-flow User registers'
[    0.158808] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.158809] x86/fpu: xstate_offset[11]:  832, xstate_sizes[11]:   16
[    0.158810] x86/fpu: Enabled xstate features 0x807, context size is 848 bytes, using 'compacted' format.
[    0.180638] pid_max: default: 32768 minimum: 301
[    0.180663] LSM: initializing lsm=lockdown,capability,landlock,integrity
[    0.180681] landlock: Up and running.
[    0.180694] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[    0.180696] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[    0.182091] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)
[    0.182208] RCU Tasks: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.
[    0.182216] RCU Tasks Trace: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.
[    0.182224] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.
[    0.182237] signal: max sigframe size: 1776
[    0.182255] rcu: Hierarchical SRCU implementation.
[    0.182255] rcu: 	Max phase no-delay instances is 1000.
[    0.182378] NMI watchdog: Perf NMI watchdog permanently disabled
[    0.182410] smp: Bringing up secondary CPUs ...
[    0.182414] smp: Brought up 1 node, 1 CPU
[    0.182415] smpboot: Max logical packages: 4
[    0.182415] ----------------
[    0.182416] | NMI testsuite:
[    0.182416] --------------------
[    0.182416]   remote IPI:  ok  |
[    0.182417]    local IPI:  ok  |
[    0.182425] --------------------
[    0.182425] Good, all   2 testcases passed! |
[    0.182426] ---------------------------------
[    0.182426] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)
[    0.182511] devtmpfs: initialized
[    0.182535] x86/mm: Memory block size: 128MB
[    0.182611] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.182620] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)
[    0.183891] NET: Registered PF_NETLINK/PF_ROUTE protocol family
[    0.183933] audit: initializing netlink subsys (disabled)
[    0.183981] thermal_sys: Registered thermal governor 'step_wise'
[    0.183986] audit: type=2000 audit(1762556618.020:1): state=initialized audit_enabled=0 res=1
[    0.183988] cpuidle: using governor ladder
[    0.183990] cpuidle: using governor menu
[    0.184006] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
[    0.185606] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)
[    0.185608] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved as E820 entry
[    0.185613] PCI: Using configuration type 1 for base access
[    0.185675] kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.
[    0.187938] HugeTLB: registered 1.00 GiB page size, pre-allocated 0 pages
[    0.187939] HugeTLB: 16380 KiB vmemmap can be freed for a 1.00 GiB page
[    0.187940] HugeTLB: registered 2.00 MiB page size, pre-allocated 0 pages
[    0.187941] HugeTLB: 28 KiB vmemmap can be freed for a 2.00 MiB page
[    0.188040] ACPI: Added _OSI(Module Device)
[    0.188041] ACPI: Added _OSI(Processor Device)
[    0.188041] ACPI: Added _OSI(3.0 _SCP Extensions)
[    0.188042] ACPI: Added _OSI(Processor Aggregator Device)
[    0.188695] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    0.192890] ACPI: _OSC evaluation for CPUs failed, trying _PDC
[    0.192964] ACPI: Interpreter enabled
[    0.192970] ACPI: PM: (supports S0 S3 S5)
[    0.192971] ACPI: Using IOAPIC for interrupt routing
[    0.192981] PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
[    0.192982] PCI: Using E820 reservations for host bridge windows
[    0.193432] ACPI: Enabled 2 GPEs in block 00 to 3F
[    0.200531] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])
[    0.200534] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]
[    0.200557] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]
[    0.200586] acpi PNP0A08:00: _OSC: OS now controls [PME PCIeCapability]
[    0.204006] PCI host bridge to bus 0000:00
[    0.204007] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]
[    0.204009] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]
[    0.204010] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]
[    0.204011] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]
[    0.204012] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]
[    0.204013] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]
[    0.204015] pci_bus 0000:00: root bus resource [bus 00-ff]
[    0.205105] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000
[    0.213209] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400
[    0.216536] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]
[    0.224539] pci 0000:00:01.0: enabling Extended Tags
[    0.244251] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400
[    0.248077] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]
[    0.256220] pci 0000:00:01.1: enabling Extended Tags
[    0.275826] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400
[    0.279570] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]
[    0.287280] pci 0000:00:01.2: enabling Extended Tags
[    0.306758] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400
[    0.309854] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]
[    0.317838] pci 0000:00:01.3: enabling Extended Tags
[    0.338513] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400
[    0.342125] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]
[    0.349364] pci 0000:00:01.4: enabling Extended Tags
[    0.368667] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400
[    0.372347] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]
[    0.380276] pci 0000:00:01.5: enabling Extended Tags
[    0.399897] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400
[    0.410065] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]
[    0.441437] pci 0000:00:01.6: enabling Extended Tags
[    0.459354] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400
[    0.463104] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]
[    0.471947] pci 0000:00:01.7: enabling Extended Tags
[    0.492185] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400
[    0.495754] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]
[    0.504041] pci 0000:00:02.0: enabling Extended Tags
[    0.523026] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400
[    0.526800] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]
[    0.533865] pci 0000:00:02.1: enabling Extended Tags
[    0.559610] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100
[    0.566125] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO
[    0.568506] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601
[    0.576395] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]
[    0.578450] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]
[    0.588419] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500
[    0.595372] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]
[    0.601665] acpiphp: Slot [0] registered
[    0.603776] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000
[    0.606822] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]
[    0.611110] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]
[    0.612889] pci 0000:01:00.0: enabling Extended Tags
[    0.627421] pci 0000:00:01.0: PCI bridge to [bus 01]
[    0.627802] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    0.628182] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    0.630741] acpiphp: Slot [0-2] registered
[    0.630927] pci 0000:00:01.1: PCI bridge to [bus 02]
[    0.631308] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    0.631706] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    0.634297] acpiphp: Slot [0-3] registered
[    0.634482] pci 0000:00:01.2: PCI bridge to [bus 03]
[    0.634864] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    0.635241] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    0.637765] acpiphp: Slot [0-4] registered
[    0.637952] pci 0000:00:01.3: PCI bridge to [bus 04]
[    0.638333] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    0.638697] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    0.641281] acpiphp: Slot [0-5] registered
[    0.643357] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000
[    0.646418] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]
[    0.650846] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]
[    0.652648] pci 0000:05:00.0: enabling Extended Tags
[    0.667035] pci 0000:00:01.4: PCI bridge to [bus 05]
[    0.667439] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    0.667820] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    0.670447] acpiphp: Slot [0-6] registered
[    0.672516] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000
[    0.675663] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]
[    0.679651] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]
[    0.682376] pci 0000:06:00.0: enabling Extended Tags
[    0.696453] pci 0000:00:01.5: PCI bridge to [bus 06]
[    0.696829] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    0.697202] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    0.699732] acpiphp: Slot [0-7] registered
[    0.701828] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000
[    0.720081] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]
[    0.750952] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]
[    0.761124] pci 0000:07:00.0: enabling Extended Tags
[    0.779076] pci 0000:00:01.6: PCI bridge to [bus 07]
[    0.779452] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    0.779831] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    0.782409] acpiphp: Slot [0-8] registered
[    0.784301] pci 0000:08:00.0: [1af4:1045] type 00 class 0x00ff00
[    0.787162] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]
[    0.791275] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]
[    0.793034] pci 0000:08:00.0: enabling Extended Tags
[    0.807534] pci 0000:00:01.7: PCI bridge to [bus 08]
[    0.807916] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    0.808283] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    0.810924] acpiphp: Slot [0-9] registered
[    0.812987] pci 0000:09:00.0: [1af4:1044] type 00 class 0x00ff00
[    0.816075] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]
[    0.820364] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]
[    0.822209] pci 0000:09:00.0: enabling Extended Tags
[    0.836340] pci 0000:00:02.0: PCI bridge to [bus 09]
[    0.836718] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    0.837099] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    0.839572] acpiphp: Slot [0-10] registered
[    0.839755] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    0.840119] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    0.840590] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    0.848697] pci_bus 0000:00: on NUMA node 0
[    0.849536] ACPI: PCI: Interrupt link LNKA configured for IRQ 10
[    0.849915] ACPI: PCI: Interrupt link LNKB configured for IRQ 10
[    0.850293] ACPI: PCI: Interrupt link LNKC configured for IRQ 11
[    0.850952] ACPI: PCI: Interrupt link LNKD configured for IRQ 11
[    0.851334] ACPI: PCI: Interrupt link LNKE configured for IRQ 10
[    0.851712] ACPI: PCI: Interrupt link LNKF configured for IRQ 10
[    0.852114] ACPI: PCI: Interrupt link LNKG configured for IRQ 11
[    0.852494] ACPI: PCI: Interrupt link LNKH configured for IRQ 11
[    0.852675] ACPI: PCI: Interrupt link GSIA configured for IRQ 16
[    0.852679] ACPI: PCI: Interrupt link GSIB configured for IRQ 17
[    0.852683] ACPI: PCI: Interrupt link GSIC configured for IRQ 18
[    0.852687] ACPI: PCI: Interrupt link GSID configured for IRQ 19
[    0.852691] ACPI: PCI: Interrupt link GSIE configured for IRQ 20
[    0.852694] ACPI: PCI: Interrupt link GSIF configured for IRQ 21
[    0.852698] ACPI: PCI: Interrupt link GSIG configured for IRQ 22
[    0.852702] ACPI: PCI: Interrupt link GSIH configured for IRQ 23
[    0.853469] iommu: Default domain type: Translated
[    0.853469] iommu: DMA domain TLB invalidation policy: lazy mode
[    0.853528] SCSI subsystem initialized
[    0.853571] libata version 3.00 loaded.
[    0.853581] pps_core: LinuxPPS API ver. 1 registered
[    0.853581] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;
[    0.853585] PTP clock support registered
[    0.853759] PCI: Using ACPI for IRQ routing
[    1.593744] PCI: pci_cache_line_size set to 64 bytes
[    1.597575] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]
[    1.597578] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]
[    1.597654] clocksource: Switched to clocksource hyperv_clocksource_tsc_page
[    1.597736] VFS: Disk quotas dquot_6.6.0
[    1.597743] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    1.597772] pnp: PnP ACPI init
[    1.597862] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved
[    1.598695] pnp: PnP ACPI: found 5 devices
[    1.598695] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns
[    1.598695] NET: Registered PF_INET protocol family
[    1.598695] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)
[    1.598695] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)
[    1.598695] Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)
[    1.598695] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)
[    1.598695] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)
[    1.598695] TCP: Hash tables configured (established 1024 bind 1024)
[    1.598695] MPTCP token hash table entries: 256 (order: 0, 6144 bytes, linear)
[    1.598695] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)
[    1.598695] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)
[    1.598695] NET: Registered PF_UNIX/PF_LOCAL protocol family
[    1.598695] NET: Registered PF_XDP protocol family
[    1.598695] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000
[    1.598695] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000
[    1.598695] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000
[    1.598695] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000
[    1.598695] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000
[    1.598695] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000
[    1.598695] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000
[    1.598695] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000
[    1.598695] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000
[    1.598695] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000
[    1.598695] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]
[    1.598695] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]
[    1.598695] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]
[    1.598695] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]
[    1.598695] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]
[    1.598695] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]
[    1.598695] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]
[    1.598695] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]
[    1.598695] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]
[    1.598695] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]
[    1.598695] pci 0000:00:01.0: PCI bridge to [bus 01]
[    1.598695] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]
[    1.599540] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    1.600471] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    1.602227] pci 0000:00:01.1: PCI bridge to [bus 02]
[    1.602427] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]
[    1.603864] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    1.604792] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    1.606602] pci 0000:00:01.2: PCI bridge to [bus 03]
[    1.606804] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]
[    1.608215] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    1.609509] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    1.610859] pci 0000:00:01.3: PCI bridge to [bus 04]
[    1.611077] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]
[    1.612291] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    1.613222] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    1.615071] pci 0000:00:01.4: PCI bridge to [bus 05]
[    1.615288] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]
[    1.616724] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    1.617546] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    1.620443] pci 0000:00:01.5: PCI bridge to [bus 06]
[    1.620768] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]
[    1.621897] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    1.622618] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    1.623900] pci 0000:00:01.6: PCI bridge to [bus 07]
[    1.624105] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]
[    1.625223] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    1.625865] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    1.627549] pci 0000:00:01.7: PCI bridge to [bus 08]
[    1.627769] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]
[    1.628838] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    1.629586] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    1.631392] pci 0000:00:02.0: PCI bridge to [bus 09]
[    1.631657] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]
[    1.632598] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    1.633328] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    1.634957] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    1.635159] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]
[    1.636263] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    1.637149] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    1.638770] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]
[    1.638771] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]
[    1.638772] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]
[    1.638773] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]
[    1.638774] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]
[    1.638775] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]
[    1.638776] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]
[    1.638776] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]
[    1.638777] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]
[    1.638778] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]
[    1.638779] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]
[    1.638779] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]
[    1.638780] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]
[    1.638781] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]
[    1.638781] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]
[    1.638782] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]
[    1.638783] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]
[    1.638784] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]
[    1.638784] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]
[    1.638785] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]
[    1.638786] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]
[    1.638786] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]
[    1.638787] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]
[    1.638788] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]
[    1.638788] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]
[    1.638789] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]
[    1.638790] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]
[    1.638791] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]
[    1.638791] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]
[    1.638792] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]
[    1.638793] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]
[    1.638793] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]
[    1.638794] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]
[    1.638795] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]
[    1.638795] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]
[    1.638796] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]
[    1.643736] PCI: CLS 0 bytes, default 64
[    1.643917] Initialise system trusted keyrings
[    1.643960] Unpacking initramfs...
[    1.669864] workingset: timestamp_bits=46 max_order=15 bucket_order=0
[    1.669870] zbud: loaded
[    1.669922] Key type asymmetric registered
[    1.669923] Asymmetric key parser 'x509' registered
[    1.669938] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 247)
[    1.670730] io scheduler mq-deadline registered
[    1.670731] io scheduler kyber registered
[    1.670736] io scheduler bfq registered
[    1.671108] ACPI: \_SB_.GSIF: Enabled at IRQ 21
[    1.679406] pcieport 0000:00:01.0: PME: Signaling with IRQ 24
[    1.698068] pcieport 0000:00:01.1: PME: Signaling with IRQ 25
[    1.716977] pcieport 0000:00:01.2: PME: Signaling with IRQ 26
[    1.734597] pcieport 0000:00:01.3: PME: Signaling with IRQ 27
[    1.752266] pcieport 0000:00:01.4: PME: Signaling with IRQ 28
[    1.770416] pcieport 0000:00:01.5: PME: Signaling with IRQ 29
[    1.783416] pcieport 0000:00:01.6: PME: Signaling with IRQ 30
[    1.795094] pcieport 0000:00:01.7: PME: Signaling with IRQ 31
[    1.799546] ACPI: \_SB_.GSIG: Enabled at IRQ 22
[    1.805930] pcieport 0000:00:02.0: PME: Signaling with IRQ 32
[    1.816013] pcieport 0000:00:02.1: PME: Signaling with IRQ 33
[    1.820353] ERST DBG: ERST support is disabled.
[    1.959824] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled
[    1.961908] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
[    2.320412] Freeing initrd memory: 8776K
[    2.321737] VMware PVSCSI driver - version 1.0.7.0-k
[    2.321759] ahci 0000:00:1f.2: version 3.0
[    2.322069] ACPI: \_SB_.GSIA: Enabled at IRQ 16
[    2.345989] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode
[    2.345991] ahci 0000:00:1f.2: flags: 64bit ncq only 
[    2.368354] scsi host0: ahci
[    2.368457] scsi host1: ahci
[    2.368539] scsi host2: ahci
[    2.368608] scsi host3: ahci
[    2.368678] scsi host4: ahci
[    2.368757] scsi host5: ahci
[    2.369080] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 36
[    2.369249] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 36
[    2.369424] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 36
[    2.369577] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 36
[    2.369854] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 36
[    2.370016] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 36
[    2.370070] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12
[    2.389138] serio: i8042 KBD port at 0x60,0x64 irq 1
[    2.389141] serio: i8042 AUX port at 0x60,0x64 irq 12
[    2.389155] rtc_cmos 00:03: RTC can wake from S4
[    2.406705] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input0
[    2.427862] rtc_cmos 00:03: registered as rtc0
[    2.429445] rtc_cmos 00:03: setting system clock to 2025-11-07T23:03:40 UTC (1762556620)
[    2.430410] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs
[    2.430419] intel_pstate: CPU model not supported
[    2.430494] gre: GRE over IPv4 demultiplexor driver
[    2.439377] NET: Registered PF_INET6 protocol family
[    2.439495] Segment Routing with IPv6
[    2.439498] In-situ OAM (IOAM) with IPv6
[    2.439524] Key type dns_resolver registered
[    2.439546] IPI shorthand broadcast: enabled
[    2.440203] sched_clock: Marking stable (2320005200, 119769000)-&gt;(2723708600, -283934400)
[    2.445586] registered taskstats version 1
[    2.445630] Loading compiled-in X.509 certificates
[    2.447468] Loaded X.509 cert 'alpinelinux.org: Alpine Linux kernel key: d76a695f66ad9cd28f5c22a8508f36e91f521f7a'
[    2.448777] Key type .fscrypt registered
[    2.448778] Key type fscrypt-provisioning registered
[    2.745373] ata1: SATA link down (SStatus 0 SControl 300)
[    2.750672] ata2: SATA link down (SStatus 0 SControl 300)
[    2.756588] ata3: SATA link down (SStatus 0 SControl 300)
[    2.762147] ata5: SATA link down (SStatus 0 SControl 300)
[    2.767322] ata4: SATA link down (SStatus 0 SControl 300)
[    2.772557] ata6: SATA link down (SStatus 0 SControl 300)
[    2.774515] Freeing unused kernel image (initmem) memory: 2696K
[    2.774517] Write protecting the kernel read-only data: 24576k
[    2.774996] Freeing unused kernel image (rodata/data gap) memory: 2008K
[    2.775000] rodata_test: all tests were successful
[    2.775003] Run /init as init process
[    2.775004]   with arguments:
[    2.775004]     /init
[    2.775005]   with environment:
[    2.775005]     HOME=/
[    2.775006]     TERM=linux
[    2.775006]     BOOT_IMAGE=/boot/vmlinuz-virt
[    2.775007]     modules=loop,squashfs,sd-mod,usb-storage
[    2.778480] Alpine Init 3.10.1-r0
[    2.778766] Loading boot drivers...
[    2.781251] loop: module loaded
[    2.782556] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    2.792347] ACPI: bus type USB registered
[    2.792364] usbcore: registered new interface driver usbfs
[    2.792369] usbcore: registered new interface driver hub
[    2.792373] usbcore: registered new device driver usb
[    2.793760] usbcore: registered new interface driver usb-storage
[    2.808123] ACPI: bus type drm_connector registered
[    2.814777] Loading boot drivers: ok.
[    2.815352] Mounting boot media...
[    2.865466] scsi host6: Virtio SCSI HBA
[    2.911631] Free page reporting enabled
[    2.952211] virtio_blk virtio3: 1/0/0 default/read/poll queues
[    2.969975] virtio_blk virtio3: [vda] 124928 512-byte logical blocks (64.0 MB/61.0 MiB)
[    2.971147]  vda: vda1 vda2
[    3.050539] ISO 9660 Extensions: Microsoft Joliet Level 3
[    3.051031] ISO 9660 Extensions: RRIP_1991A
[    3.326398] Mounting boot media: ok.
[    3.342968] Installing packages to root filesystem...
[    3.555677] Installing packages to root filesystem: ok.
[    3.783441] loop0: detected capacity change from 0 to 39312
[    3.979083] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input3
[    4.009882] ACPI: button: Power Button [PWRF]
[    4.052457] cryptd: max_cpu_qlen set to 1000
[    4.096362] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input4
[    4.130028] mousedev: PS/2 mouse device common for all mice
[    4.219456] NET: Registered PF_PACKET protocol family
localhost:~# &#65533;[6n
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: echo $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "lspci\n"
&#65533;[32mMatch for RE:&#65533;[39m "lspci((?s).*)((?s).*)(\\$ |\\# )" found: ["lspci\r\n-sh: lspci: not found\r\nlocalhost:~# " "\r\n-sh: lspci: not found\r\nlocalhost:~" "" "# "] Buffer: lspci
-sh: lspci: not found
localhost:~# &#65533;
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[34mSent:&#65533;[39m "arp\n"
&#65533;[32mMatch for RE:&#65533;[39m "arp((?s).*)((?s).*)(\\$ |\\# )" found: ["arp\r\nlocalhost:~# " "\r\nlocalhost:~" "" "# "] Buffer: arp
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "(localhost|testvmi-662jp):~\\# " found: ["localhost:~# " "localhost"] Buffer: 
localhost:~# 
Global test cleanup started.
Forwarding from 127.0.0.1:5484 -&gt; 8443
Forwarding from [::1]:5484 -&gt; 8443
Handling connection for 5484
Forwarding from 127.0.0.1:4706 -&gt; 8443
Forwarding from [::1]:4706 -&gt; 8443
Handling connection for 4706
Forwarding from 127.0.0.1:9403 -&gt; 8443
Forwarding from [::1]:9403 -&gt; 8443
Handling connection for 9403
Forwarding from 127.0.0.1:9738 -&gt; 8443
Forwarding from [::1]:9738 -&gt; 8443
Handling connection for 9738
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler is not responsive [test_id:1634]the node controller should mark the node as unschedulable when the virt-handler heartbeat has timedout" classname="KubeVirt Tests Suite" time="106.221884539" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node tainted [test_id:1635]the vmi with tolerations should be scheduled" classname="KubeVirt Tests Suite" time="19.690822146" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node tainted [test_id:1636]the vmi without tolerations should not be scheduled" classname="KubeVirt Tests Suite" time="10.361261416" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with affinity [test_id:1637]the vmi with node affinity and no conflicts should be scheduled" classname="KubeVirt Tests Suite" time="14.996763864" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with affinity [test_id:1638]the vmi with node affinity and anti-pod affinity should not be scheduled" classname="KubeVirt Tests Suite" time="16.231674238" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with default cpu model [test_id:3199]should set default cpu model when vmi doesn't have it set" classname="KubeVirt Tests Suite" time="93.206743165" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with default cpu model [test_id:3200]should not set default cpu model when vmi has it set" classname="KubeVirt Tests Suite" time="84.89986282" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with default cpu model [sig-compute][test_id:3201]should set cpu model to default when vmi does not have it set and default cpu model is not set" classname="KubeVirt Tests Suite" time="58.345113355">
          <failure type="Failure">tests/vmi_lifecycle_test.go:927
Expected CPU model to equal to the default (host-model)
Expected
    &lt;string&gt;: qemu64-v1
to equal
    &lt;string&gt;: host-model
tests/vmi_lifecycle_test.go:933</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/3_*
Skipping volume snapshot log collection
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "(localhost|testvmi-jmwzm) login: " found: ["localhost login: " "localhost"] Buffer: 
Welcome to Alpine Linux 3.20
Kernel 6.6.34-1-virt on an x86_64 (/dev/ttyS0)

localhost login: 
&#65533;[34mSent:&#65533;[39m "root\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["# " "# "] Buffer: root
Welcome to Alpine!

The Alpine Wiki contains a large amount of how-to guides and general
information about administrating Alpine systems.
See &lt;https://wiki.alpinelinux.org/&gt;.

You can setup the system with the command: setup-alpine

You may change this message by editing /etc/motd.

localhost:~# &#65533;
&#65533;[34mSent:&#65533;[39m "stty cols 500 rows 500\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["# " "# "] Buffer: [6nstty cols 500 rows 500
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "\n0\r\n.*(\\$ |\\# )" found: ["\n0\r\nlocalhost:~# " "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "dmesg -n 1\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["# " "# "] Buffer: &#65533;[6ndmesg -n 1
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "\n0\r\n.*(\\$ |\\# )" found: ["\n0\r\nlocalhost:~# " "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "ip address\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip address((?s).*)((?s).*)(\\$ |\\# )" found: ["ip address\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 96:8c:df:b6:55:ec brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~# " "\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 96:8c:df:b6:55:ec brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~" "" "# "] Buffer: ip address
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000
    link/ether 96:8c:df:b6:55:ec brd ff:ff:ff:ff:ff:ff
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "ip link\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip link((?s).*)((?s).*)(\\$ |\\# )" found: ["ip link\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 96:8c:df:b6:55:ec brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~# " "\r\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000\r\n    link/ether 96:8c:df:b6:55:ec brd ff:ff:ff:ff:ff:ff\r\nlocalhost:~" "" "# "] Buffer: ip link
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1450 qdisc noop state DOWN qlen 1000
    link/ether 96:8c:df:b6:55:ec brd ff:ff:ff:ff:ff:ff
localhost:~# &#65533;[6n
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: echo $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "ip route show table all\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip route show table all((?s).*)((?s).*)(\\$ |\\# )" found: ["ip route show table all\r\nlocalhost:~# " "\r\nlocalhost:~" "" "# "] Buffer: ip route show table all
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "dmesg\n"
&#65533;[32mMatch for RE:&#65533;[39m "dmesg((?s).*)((?s).*)(\\$ |\\# )" found: ["dmesg\r\n[    0.000000] Linux version 6.6.34-1-virt (buildozer@build-3-20-x86_64) (gcc (Alpine 13.2.1_git20240309) 13.2.1 20240309, GNU ld (GNU Binutils) 2.42) #2-Alpine SMP PREEMPT_DYNAMIC Tue, 18 Jun 2024 10:38:37 +0000\r\n[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.000000] BIOS-provided physical RAM map:\r\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable\r\n[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable\r\n[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved\r\n[    0.000000] NX (Execute Disable) protection: active\r\n[    0.000000] APIC: Static calls initialized\r\n[    0.000000] SMBIOS 2.8 present.\r\n[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014\r\n[    0.000000] Hypervisor detected: Microsoft Hyper-V\r\n[    0.000000] Hyper-V: privilege flags low 0xe7e, high 0x0, hints 0x60624, misc 0xe0130\r\n[    0.000000] Hyper-V: Host Build 10.0.26100.1381-1-0\r\n[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480\r\n[    0.000000] Hyper-V: Using hypercall for remote TLB flush\r\n[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000000] clocksource: hyperv_clocksource_msr: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000002] tsc: Marking TSC unstable due to running on Hyper-V\r\n[    0.000004] tsc: Detected 2299.999 MHz processor\r\n[    0.000182] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved\r\n[    0.000184] e820: remove [mem 0x000a0000-0x000fffff] usable\r\n[    0.000187] last_pfn = 0x7fdd max_arch_pfn = 0x400000000\r\n[    0.000207] MTRR map: 4 entries (3 fixed + 1 variable; max 19), built from 8 variable MTRRs\r\n[    0.000209] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \r\n[    0.000242] Using GB pages for direct mapping\r\n[    0.000337] RAMDISK: [mem 0x0774b000-0x07fdcfff]\r\n[    0.000338] ACPI: Early table checksum verification disabled\r\n[    0.000339] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )\r\n[    0.000342] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000345] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000349] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000351] ACPI: FACS 0x0000000007FE0000 000040\r\n[    0.000352] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000354] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000355] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000357] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000358] ACPI: Reserving FACP table memory at [mem 0x7fe2947-0x7fe2a3a]\r\n[    0.000359] ACPI: Reserving DSDT table memory at [mem 0x7fe0040-0x7fe2946]\r\n[    0.000359] ACPI: Reserving FACS table memory at [mem 0x7fe0000-0x7fe003f]\r\n[    0.000360] ACPI: Reserving APIC table memory at [mem 0x7fe2a3b-0x7fe2aca]\r\n[    0.000360] ACPI: Reserving HPET table memory at [mem 0x7fe2acb-0x7fe2b02]\r\n[    0.000361] ACPI: Reserving MCFG table memory at [mem 0x7fe2b03-0x7fe2b3e]\r\n[    0.000361] ACPI: Reserving WAET table memory at [mem 0x7fe2b3f-0x7fe2b66]\r\n[    0.000598] Zone ranges:\r\n[    0.000598]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]\r\n[    0.000600]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]\r\n[    0.000600]   Normal   empty\r\n[    0.000601] Movable zone start for each node\r\n[    0.000601] Early memory node ranges\r\n[    0.000602]   node   0: [mem 0x0000000000001000-0x000000000009efff]\r\n[    0.000603]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]\r\n[    0.000603] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]\r\n[    0.001699] On node 0, zone DMA: 1 pages in unavailable ranges\r\n[    0.001732] On node 0, zone DMA: 97 pages in unavailable ranges\r\n[    0.002460] On node 0, zone DMA32: 35 pages in unavailable ranges\r\n[    0.027714] ACPI: PM-Timer IO Port: 0x608\r\n[    0.027721] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\r\n[    0.029691] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23\r\n[    0.029694] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)\r\n[    0.029696] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\r\n[    0.029696] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\r\n[    0.029697] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\r\n[    0.029698] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\r\n[    0.029701] ACPI: Using ACPI (MADT) for SMP configuration information\r\n[    0.029702] ACPI: HPET id: 0x8086a201 base: 0xfed00000\r\n[    0.029704] smpboot: Allowing 4 CPUs, 3 hotplug CPUs\r\n[    0.029710] [mem 0x08000000-0xafffffff] available for PCI devices\r\n[    0.029711] Booting paravirtualized kernel on Hyper-V\r\n[    0.029712] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.033995] setup_percpu: NR_CPUS:256 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1\r\n[    0.034978] percpu: Embedded 57 pages/cpu s195560 r8192 d29720 u524288\r\n[    0.034983] pcpu-alloc: s195560 r8192 d29720 u524288 alloc=1*2097152\r\n[    0.034985] pcpu-alloc: [0] 0 1 2 3 \r\n[    0.034997] Hyper-V: PV spinlocks enabled\r\n[    0.034998] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    0.035000] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.035039] Unknown kernel command line parameters \"BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage\", will be passed to user space.\r\n[    0.035048] random: crng init done\r\n[    0.035070] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r\n[    0.035082] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r\n[    0.035140] Built 1 zonelists, mobility grouping on.  Total pages: 31965\r\n[    0.035527] mem auto-init: stack:all(zero), heap alloc:on, heap free:off\r\n[    0.035913] Memory: 80436K/130540K available (14336K kernel code, 1799K rwdata, 8232K rodata, 2696K init, 2032K bss, 49844K reserved, 0K cma-reserved)\r\n[    0.036076] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1\r\n[    0.036723] Dynamic Preempt: none\r\n[    0.036760] rcu: Preemptible hierarchical RCU implementation.\r\n[    0.036760] rcu: \tRCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=4.\r\n[    0.036761] \tTrampoline variant of Tasks RCU enabled.\r\n[    0.036762] \tTracing variant of Tasks RCU enabled.\r\n[    0.036762] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.\r\n[    0.036763] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4\r\n[    0.038539] NR_IRQS: 16640, nr_irqs: 456, preallocated irqs: 16\r\n[    0.039486] rcu: srcu_init: Setting srcu_struct sizes based on contention.\r\n[    0.041677] kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)\r\n[    0.044271] Console: colour *CGA 80x25\r\n[    0.044272] printk: console [tty0] enabled\r\n[    0.044287] ACPI: Core revision 20230628\r\n[    0.048865] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns\r\n[    0.052513] APIC: Switch to symmetric I/O mode setup\r\n[    0.074848] x2apic enabled\r\n[    0.075122] APIC: Switched APIC routing to: physical x2apic\r\n[    0.075140] Hyper-V: Disabling IBT because of Hyper-V bug\r\n[    0.075141] Hyper-V: Using IPI hypercalls\r\n[    0.075142] APIC: send_IPI() replaced with hv_send_ipi()\r\n[    0.075146] APIC: send_IPI_mask() replaced with hv_send_ipi_mask()\r\n[    0.075148] APIC: send_IPI_mask_allbutself() replaced with hv_send_ipi_mask_allbutself()\r\n[    0.075150] APIC: send_IPI_allbutself() replaced with hv_send_ipi_allbutself()\r\n[    0.075152] APIC: send_IPI_all() replaced with hv_send_ipi_all()\r\n[    0.075154] APIC: send_IPI_self() replaced with hv_send_ipi_self()\r\n[    0.172616] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1\r\n[    0.174812] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=22999990)\r\n[    0.174884] x86/cpu: User Mode Instruction Prevention (UMIP) activated\r\n[    0.174892] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0\r\n[    0.174893] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0\r\n[    0.174897] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization\r\n[    0.174899] Spectre V2 : Mitigation: Retpolines\r\n[    0.174900] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch\r\n[    0.174900] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT\r\n[    0.174901] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!\r\n[    0.174902] RETBleed: Vulnerable\r\n[    0.174903] Speculative Store Bypass: Vulnerable\r\n[    0.174903] MMIO Stale Data: Unknown: No mitigations\r\n[    0.174920] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'\r\n[    0.174921] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'\r\n[    0.174922] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'\r\n[    0.174922] x86/fpu: Supporting XSAVE feature 0x800: 'Control-flow User registers'\r\n[    0.174923] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256\r\n[    0.174924] x86/fpu: xstate_offset[11]:  832, xstate_sizes[11]:   16\r\n[    0.174925] x86/fpu: Enabled xstate features 0x807, context size is 848 bytes, using 'compacted' format.\r\n[    0.191766] pid_max: default: 32768 minimum: 301\r\n[    0.191795] LSM: initializing lsm=lockdown,capability,landlock,integrity\r\n[    0.191814] landlock: Up and running.\r\n[    0.191830] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.191832] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.193253] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)\r\n[    0.193397] RCU Tasks: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.193408] RCU Tasks Trace: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.193418] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.\r\n[    0.193432] signal: max sigframe size: 1776\r\n[    0.193454] rcu: Hierarchical SRCU implementation.\r\n[    0.193454] rcu: \tMax phase no-delay instances is 1000.\r\n[    0.193605] NMI watchdog: Perf NMI watchdog permanently disabled\r\n[    0.193650] smp: Bringing up secondary CPUs ...\r\n[    0.193655] smp: Brought up 1 node, 1 CPU\r\n[    0.193656] smpboot: Max logical packages: 4\r\n[    0.193657] ----------------\r\n[    0.193658] | NMI testsuite:\r\n[    0.193658] --------------------\r\n[    0.193658]   remote IPI:  ok  |\r\n[    0.193659]    local IPI:  ok  |\r\n[    0.193667] --------------------\r\n[    0.193668] Good, all   2 testcases passed! |\r\n[    0.193668] ---------------------------------\r\n[    0.193669] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)\r\n[    0.193770] devtmpfs: initialized\r\n[    0.193798] x86/mm: Memory block size: 128MB\r\n[    0.193883] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.193897] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)\r\n[    0.194808] NET: Registered PF_NETLINK/PF_ROUTE protocol family\r\n[    0.194808] audit: initializing netlink subsys (disabled)\r\n[    0.194808] thermal_sys: Registered thermal governor 'step_wise'\r\n[    0.194808] audit: type=2000 audit(1762557020.010:1): state=initialized audit_enabled=0 res=1\r\n[    0.194808] cpuidle: using governor ladder\r\n[    0.194808] cpuidle: using governor menu\r\n[    0.194808] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5\r\n[    0.194808] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)\r\n[    0.194808] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved as E820 entry\r\n[    0.194808] PCI: Using configuration type 1 for base access\r\n[    0.194808] kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.\r\n[    0.194808] HugeTLB: registered 1.00 GiB page size, pre-allocated 0 pages\r\n[    0.194808] HugeTLB: 16380 KiB vmemmap can be freed for a 1.00 GiB page\r\n[    0.194808] HugeTLB: registered 2.00 MiB page size, pre-allocated 0 pages\r\n[    0.194808] HugeTLB: 28 KiB vmemmap can be freed for a 2.00 MiB page\r\n[    0.194808] ACPI: Added _OSI(Module Device)\r\n[    0.194808] ACPI: Added _OSI(Processor Device)\r\n[    0.194808] ACPI: Added _OSI(3.0 _SCP Extensions)\r\n[    0.194808] ACPI: Added _OSI(Processor Aggregator Device)\r\n[    0.194808] ACPI: 1 ACPI AML tables successfully acquired and loaded\r\n[    0.200580] ACPI: _OSC evaluation for CPUs failed, trying _PDC\r\n[    0.200642] ACPI: Interpreter enabled\r\n[    0.200647] ACPI: PM: (supports S0 S3 S5)\r\n[    0.200648] ACPI: Using IOAPIC for interrupt routing\r\n[    0.200659] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\r\n[    0.200660] PCI: Using E820 reservations for host bridge windows\r\n[    0.201128] ACPI: Enabled 2 GPEs in block 00 to 3F\r\n[    0.208715] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\r\n[    0.208719] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]\r\n[    0.208743] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]\r\n[    0.208772] acpi PNP0A08:00: _OSC: OS now controls [PME PCIeCapability]\r\n[    0.211716] PCI host bridge to bus 0000:00\r\n[    0.211717] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]\r\n[    0.211719] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]\r\n[    0.211720] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]\r\n[    0.211721] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]\r\n[    0.211722] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]\r\n[    0.211723] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]\r\n[    0.211724] pci_bus 0000:00: root bus resource [bus 00-ff]\r\n[    0.212877] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000\r\n[    0.221415] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400\r\n[    0.224666] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]\r\n[    0.233828] pci 0000:00:01.0: enabling Extended Tags\r\n[    0.254557] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400\r\n[    0.258319] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]\r\n[    0.266824] pci 0000:00:01.1: enabling Extended Tags\r\n[    0.287673] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400\r\n[    0.292099] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]\r\n[    0.300133] pci 0000:00:01.2: enabling Extended Tags\r\n[    0.322122] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400\r\n[    0.326175] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]\r\n[    0.335134] pci 0000:00:01.3: enabling Extended Tags\r\n[    0.355618] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400\r\n[    0.360025] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]\r\n[    0.367602] pci 0000:00:01.4: enabling Extended Tags\r\n[    0.386769] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400\r\n[    0.389814] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]\r\n[    0.397188] pci 0000:00:01.5: enabling Extended Tags\r\n[    0.414573] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400\r\n[    0.426469] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]\r\n[    0.457655] pci 0000:00:01.6: enabling Extended Tags\r\n[    0.478517] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400\r\n[    0.481185] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]\r\n[    0.489863] pci 0000:00:01.7: enabling Extended Tags\r\n[    0.510464] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400\r\n[    0.513559] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]\r\n[    0.519596] pci 0000:00:02.0: enabling Extended Tags\r\n[    0.540828] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400\r\n[    0.544566] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]\r\n[    0.552428] pci 0000:00:02.1: enabling Extended Tags\r\n[    0.577533] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100\r\n[    0.583564] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO\r\n[    0.586222] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601\r\n[    0.594308] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]\r\n[    0.595989] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]\r\n[    0.605721] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500\r\n[    0.611546] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]\r\n[    0.618074] acpiphp: Slot [0] registered\r\n[    0.620342] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000\r\n[    0.623469] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]\r\n[    0.628327] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]\r\n[    0.630235] pci 0000:01:00.0: enabling Extended Tags\r\n[    0.646203] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    0.646631] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    0.647056] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    0.650049] acpiphp: Slot [0-2] registered\r\n[    0.650254] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    0.650668] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    0.651096] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    0.653901] acpiphp: Slot [0-3] registered\r\n[    0.654102] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    0.654526] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    0.654918] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    0.657582] acpiphp: Slot [0-4] registered\r\n[    0.657785] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    0.658211] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    0.658730] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    0.661466] acpiphp: Slot [0-5] registered\r\n[    0.663761] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000\r\n[    0.666809] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]\r\n[    0.671252] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]\r\n[    0.673174] pci 0000:05:00.0: enabling Extended Tags\r\n[    0.689204] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    0.689628] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    0.690053] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    0.692762] acpiphp: Slot [0-6] registered\r\n[    0.694998] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000\r\n[    0.698148] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]\r\n[    0.702860] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]\r\n[    0.704810] pci 0000:06:00.0: enabling Extended Tags\r\n[    0.721085] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    0.721527] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    0.721959] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    0.724794] acpiphp: Slot [0-7] registered\r\n[    0.727048] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000\r\n[    0.746237] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]\r\n[    0.777011] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]\r\n[    0.787612] pci 0000:07:00.0: enabling Extended Tags\r\n[    0.807911] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    0.808329] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    0.808760] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    0.811536] acpiphp: Slot [0-8] registered\r\n[    0.813838] pci 0000:08:00.0: [1af4:1045] type 00 class 0x00ff00\r\n[    0.816870] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]\r\n[    0.821032] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]\r\n[    0.823143] pci 0000:08:00.0: enabling Extended Tags\r\n[    0.839281] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    0.839710] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    0.840139] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    0.842935] acpiphp: Slot [0-9] registered\r\n[    0.845101] pci 0000:09:00.0: [1af4:1044] type 00 class 0x00ff00\r\n[    0.848557] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]\r\n[    0.852649] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]\r\n[    0.854773] pci 0000:09:00.0: enabling Extended Tags\r\n[    0.870847] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    0.871271] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    0.871708] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    0.874476] acpiphp: Slot [0-10] registered\r\n[    0.874680] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    0.875027] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    0.875451] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    0.884240] pci_bus 0000:00: on NUMA node 0\r\n[    0.885125] ACPI: PCI: Interrupt link LNKA configured for IRQ 10\r\n[    0.885564] ACPI: PCI: Interrupt link LNKB configured for IRQ 10\r\n[    0.885987] ACPI: PCI: Interrupt link LNKC configured for IRQ 11\r\n[    0.886418] ACPI: PCI: Interrupt link LNKD configured for IRQ 11\r\n[    0.887157] ACPI: PCI: Interrupt link LNKE configured for IRQ 10\r\n[    0.887578] ACPI: PCI: Interrupt link LNKF configured for IRQ 10\r\n[    0.888013] ACPI: PCI: Interrupt link LNKG configured for IRQ 11\r\n[    0.888441] ACPI: PCI: Interrupt link LNKH configured for IRQ 11\r\n[    0.888660] ACPI: PCI: Interrupt link GSIA configured for IRQ 16\r\n[    0.888665] ACPI: PCI: Interrupt link GSIB configured for IRQ 17\r\n[    0.888670] ACPI: PCI: Interrupt link GSIC configured for IRQ 18\r\n[    0.888675] ACPI: PCI: Interrupt link GSID configured for IRQ 19\r\n[    0.888681] ACPI: PCI: Interrupt link GSIE configured for IRQ 20\r\n[    0.888685] ACPI: PCI: Interrupt link GSIF configured for IRQ 21\r\n[    0.888689] ACPI: PCI: Interrupt link GSIG configured for IRQ 22\r\n[    0.888693] ACPI: PCI: Interrupt link GSIH configured for IRQ 23\r\n[    0.889633] iommu: Default domain type: Translated\r\n[    0.889634] iommu: DMA domain TLB invalidation policy: lazy mode\r\n[    0.889715] SCSI subsystem initialized\r\n[    0.889782] libata version 3.00 loaded.\r\n[    0.889796] pps_core: LinuxPPS API ver. 1 registered\r\n[    0.889797] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;\r\n[    0.889801] PTP clock support registered\r\n[    0.890020] PCI: Using ACPI for IRQ routing\r\n[    1.731738] PCI: pci_cache_line_size set to 64 bytes\r\n[    1.736021] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]\r\n[    1.736024] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]\r\n[    1.736109] clocksource: Switched to clocksource hyperv_clocksource_tsc_page\r\n[    1.736214] VFS: Disk quotas dquot_6.6.0\r\n[    1.736222] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\r\n[    1.736254] pnp: PnP ACPI init\r\n[    1.736350] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved\r\n[    1.737623] pnp: PnP ACPI: found 5 devices\r\n[    1.744792] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns\r\n[    1.744808] NET: Registered PF_INET protocol family\r\n[    1.744808] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)\r\n[    1.744808] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    1.744808] Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)\r\n[    1.744808] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r\n[    1.744808] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)\r\n[    1.744808] TCP: Hash tables configured (established 1024 bind 1024)\r\n[    1.744808] MPTCP token hash table entries: 256 (order: 0, 6144 bytes, linear)\r\n[    1.744808] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.744808] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.744808] NET: Registered PF_UNIX/PF_LOCAL protocol family\r\n[    1.744808] NET: Registered PF_XDP protocol family\r\n[    1.744808] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000\r\n[    1.744808] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000\r\n[    1.744808] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000\r\n[    1.744808] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000\r\n[    1.744808] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000\r\n[    1.744808] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000\r\n[    1.744808] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000\r\n[    1.744808] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000\r\n[    1.744808] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000\r\n[    1.744808] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000\r\n[    1.744808] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]\r\n[    1.744808] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]\r\n[    1.744808] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]\r\n[    1.744808] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]\r\n[    1.744808] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]\r\n[    1.744808] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]\r\n[    1.744808] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]\r\n[    1.744808] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]\r\n[    1.744808] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]\r\n[    1.744808] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]\r\n[    1.744808] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    1.744848] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]\r\n[    1.746544] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    1.747536] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.749612] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    1.749832] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]\r\n[    1.751502] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    1.752487] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.754371] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    1.754591] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]\r\n[    1.756223] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    1.757038] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.758583] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    1.758818] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]\r\n[    1.760102] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    1.760994] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.762658] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    1.762884] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]\r\n[    1.764056] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    1.765041] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.767330] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    1.767544] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]\r\n[    1.768711] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    1.769491] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.771077] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    1.771350] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]\r\n[    1.772507] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    1.773337] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.775103] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    1.775344] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]\r\n[    1.776641] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    1.778173] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.779536] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    1.779746] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]\r\n[    1.780894] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    1.781650] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.782923] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    1.783134] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]\r\n[    1.784317] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    1.785001] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.786801] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]\r\n[    1.786802] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]\r\n[    1.786803] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]\r\n[    1.786804] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]\r\n[    1.786805] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]\r\n[    1.786806] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]\r\n[    1.786806] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]\r\n[    1.786807] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]\r\n[    1.786808] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.786809] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]\r\n[    1.786810] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]\r\n[    1.786810] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.786811] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]\r\n[    1.786812] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]\r\n[    1.786813] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.786813] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]\r\n[    1.786814] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]\r\n[    1.786815] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.786816] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]\r\n[    1.786816] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]\r\n[    1.786817] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.786818] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]\r\n[    1.786819] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]\r\n[    1.786819] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.786820] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]\r\n[    1.786821] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]\r\n[    1.786821] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.786822] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]\r\n[    1.786823] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]\r\n[    1.786824] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.786824] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]\r\n[    1.786825] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]\r\n[    1.786826] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.786827] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]\r\n[    1.786827] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]\r\n[    1.786828] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.791674] PCI: CLS 0 bytes, default 64\r\n[    1.792016] Initialise system trusted keyrings\r\n[    1.792080] Unpacking initramfs...\r\n[    1.823255] workingset: timestamp_bits=46 max_order=15 bucket_order=0\r\n[    1.823262] zbud: loaded\r\n[    1.823325] Key type asymmetric registered\r\n[    1.823326] Asymmetric key parser 'x509' registered\r\n[    1.823346] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 247)\r\n[    1.824279] io scheduler mq-deadline registered\r\n[    1.824279] io scheduler kyber registered\r\n[    1.824284] io scheduler bfq registered\r\n[    1.824606] ACPI: \\_SB_.GSIF: Enabled at IRQ 21\r\n[    1.834338] pcieport 0000:00:01.0: PME: Signaling with IRQ 24\r\n[    1.853579] pcieport 0000:00:01.1: PME: Signaling with IRQ 25\r\n[    1.872612] pcieport 0000:00:01.2: PME: Signaling with IRQ 26\r\n[    1.892409] pcieport 0000:00:01.3: PME: Signaling with IRQ 27\r\n[    1.911798] pcieport 0000:00:01.4: PME: Signaling with IRQ 28\r\n[    1.930916] pcieport 0000:00:01.5: PME: Signaling with IRQ 29\r\n[    1.950020] pcieport 0000:00:01.6: PME: Signaling with IRQ 30\r\n[    1.969136] pcieport 0000:00:01.7: PME: Signaling with IRQ 31\r\n[    1.978296] ACPI: \\_SB_.GSIG: Enabled at IRQ 22\r\n[    1.988345] pcieport 0000:00:02.0: PME: Signaling with IRQ 32\r\n[    2.008020] pcieport 0000:00:02.1: PME: Signaling with IRQ 33\r\n[    2.016802] ERST DBG: ERST support is disabled.\r\n[    2.223266] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled\r\n[    2.225729] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\r\n[    2.603963] Freeing initrd memory: 8776K\r\n[    2.606519] VMware PVSCSI driver - version 1.0.7.0-k\r\n[    2.606540] ahci 0000:00:1f.2: version 3.0\r\n[    2.606873] ACPI: \\_SB_.GSIA: Enabled at IRQ 16\r\n[    2.632355] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode\r\n[    2.632358] ahci 0000:00:1f.2: flags: 64bit ncq only \r\n[    2.657535] scsi host0: ahci\r\n[    2.657652] scsi host1: ahci\r\n[    2.657737] scsi host2: ahci\r\n[    2.657805] scsi host3: ahci\r\n[    2.657869] scsi host4: ahci\r\n[    2.657954] scsi host5: ahci\r\n[    2.658184] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 36\r\n[    2.658482] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 36\r\n[    2.658661] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 36\r\n[    2.659040] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 36\r\n[    2.659220] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 36\r\n[    2.659516] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 36\r\n[    2.659572] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\r\n[    2.679738] serio: i8042 KBD port at 0x60,0x64 irq 1\r\n[    2.679742] serio: i8042 AUX port at 0x60,0x64 irq 12\r\n[    2.679757] rtc_cmos 00:03: RTC can wake from S4\r\n[    2.701304] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input0\r\n[    2.727625] rtc_cmos 00:03: registered as rtc0\r\n[    2.730816] rtc_cmos 00:03: setting system clock to 2025-11-07T23:10:23 UTC (1762557023)\r\n[    2.731713] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs\r\n[    2.731723] intel_pstate: CPU model not supported\r\n[    2.731800] gre: GRE over IPv4 demultiplexor driver\r\n[    2.740746] NET: Registered PF_INET6 protocol family\r\n[    2.740881] Segment Routing with IPv6\r\n[    2.740885] In-situ OAM (IOAM) with IPv6\r\n[    2.740916] Key type dns_resolver registered\r\n[    2.740941] IPI shorthand broadcast: enabled\r\n[    2.741656] sched_clock: Marking stable (2600003100, 133202100)-&gt;(3051690400, -318485200)\r\n[    2.747042] registered taskstats version 1\r\n[    2.747094] Loading compiled-in X.509 certificates\r\n[    2.749194] Loaded X.509 cert 'alpinelinux.org: Alpine Linux kernel key: d76a695f66ad9cd28f5c22a8508f36e91f521f7a'\r\n[    2.750518] Key type .fscrypt registered\r\n[    2.750520] Key type fscrypt-provisioning registered\r\n[    3.040250] ata1: SATA link down (SStatus 0 SControl 300)\r\n[    3.051877] ata2: SATA link down (SStatus 0 SControl 300)\r\n[    3.057725] ata3: SATA link down (SStatus 0 SControl 300)\r\n[    3.064160] ata4: SATA link down (SStatus 0 SControl 300)\r\n[    3.070012] ata5: SATA link down (SStatus 0 SControl 300)\r\n[    3.075425] ata6: SATA link down (SStatus 0 SControl 300)\r\n[    3.077547] Freeing unused kernel image (initmem) memory: 2696K\r\n[    3.077550] Write protecting the kernel read-only data: 24576k\r\n[    3.078154] Freeing unused kernel image (rodata/data gap) memory: 2008K\r\n[    3.078159] rodata_test: all tests were successful\r\n[    3.078163] Run /init as init process\r\n[    3.078163]   with arguments:\r\n[    3.078164]     /init\r\n[    3.078165]   with environment:\r\n[    3.078165]     HOME=/\r\n[    3.078166]     TERM=linux\r\n[    3.078166]     BOOT_IMAGE=/boot/vmlinuz-virt\r\n[    3.078166]     modules=loop,squashfs,sd-mod,usb-storage\r\n[    3.081820] Alpine Init 3.10.1-r0\r\n[    3.082102] Loading boot drivers...\r\n[    3.084795] loop: module loaded\r\n[    3.086145] squashfs: version 4.0 (2009/01/31) Phillip Lougher\r\n[    3.096134] ACPI: bus type USB registered\r\n[    3.096151] usbcore: registered new interface driver usbfs\r\n[    3.096155] usbcore: registered new interface driver hub\r\n[    3.096159] usbcore: registered new device driver usb\r\n[    3.097555] usbcore: registered new interface driver usb-storage\r\n[    3.112030] ACPI: bus type drm_connector registered\r\n[    3.118702] Loading boot drivers: ok.\r\n[    3.119289] Mounting boot media...\r\n[    3.174809] scsi host6: Virtio SCSI HBA\r\n[    3.226310] Free page reporting enabled\r\n[    3.271131] virtio_blk virtio3: 1/0/0 default/read/poll queues\r\n[    3.290621] virtio_blk virtio3: [vda] 124928 512-byte logical blocks (64.0 MB/61.0 MiB)\r\n[    3.291914]  vda: vda1 vda2\r\n[    3.369387] ISO 9660 Extensions: Microsoft Joliet Level 3\r\n[    3.369866] ISO 9660 Extensions: RRIP_1991A\r\n[    3.646390] Mounting boot media: ok.\r\n[    3.663188] Installing packages to root filesystem...\r\n[    3.884643] Installing packages to root filesystem: ok.\r\n[    4.119278] loop0: detected capacity change from 0 to 39312\r\n[    4.321131] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input3\r\n[    4.353225] ACPI: button: Power Button [PWRF]\r\n[    4.398449] cryptd: max_cpu_qlen set to 1000\r\n[    4.457797] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input4\r\n[    4.474034] mousedev: PS/2 mouse device common for all mice\r\n[    4.586174] NET: Registered PF_PACKET protocol family\r\nlocalhost:~# " "\r\n[    0.000000] Linux version 6.6.34-1-virt (buildozer@build-3-20-x86_64) (gcc (Alpine 13.2.1_git20240309) 13.2.1 20240309, GNU ld (GNU Binutils) 2.42) #2-Alpine SMP PREEMPT_DYNAMIC Tue, 18 Jun 2024 10:38:37 +0000\r\n[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.000000] BIOS-provided physical RAM map:\r\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable\r\n[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable\r\n[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved\r\n[    0.000000] NX (Execute Disable) protection: active\r\n[    0.000000] APIC: Static calls initialized\r\n[    0.000000] SMBIOS 2.8 present.\r\n[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014\r\n[    0.000000] Hypervisor detected: Microsoft Hyper-V\r\n[    0.000000] Hyper-V: privilege flags low 0xe7e, high 0x0, hints 0x60624, misc 0xe0130\r\n[    0.000000] Hyper-V: Host Build 10.0.26100.1381-1-0\r\n[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480\r\n[    0.000000] Hyper-V: Using hypercall for remote TLB flush\r\n[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000000] clocksource: hyperv_clocksource_msr: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    0.000002] tsc: Marking TSC unstable due to running on Hyper-V\r\n[    0.000004] tsc: Detected 2299.999 MHz processor\r\n[    0.000182] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved\r\n[    0.000184] e820: remove [mem 0x000a0000-0x000fffff] usable\r\n[    0.000187] last_pfn = 0x7fdd max_arch_pfn = 0x400000000\r\n[    0.000207] MTRR map: 4 entries (3 fixed + 1 variable; max 19), built from 8 variable MTRRs\r\n[    0.000209] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \r\n[    0.000242] Using GB pages for direct mapping\r\n[    0.000337] RAMDISK: [mem 0x0774b000-0x07fdcfff]\r\n[    0.000338] ACPI: Early table checksum verification disabled\r\n[    0.000339] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )\r\n[    0.000342] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000345] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000349] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000351] ACPI: FACS 0x0000000007FE0000 000040\r\n[    0.000352] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000354] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000355] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000357] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.000358] ACPI: Reserving FACP table memory at [mem 0x7fe2947-0x7fe2a3a]\r\n[    0.000359] ACPI: Reserving DSDT table memory at [mem 0x7fe0040-0x7fe2946]\r\n[    0.000359] ACPI: Reserving FACS table memory at [mem 0x7fe0000-0x7fe003f]\r\n[    0.000360] ACPI: Reserving APIC table memory at [mem 0x7fe2a3b-0x7fe2aca]\r\n[    0.000360] ACPI: Reserving HPET table memory at [mem 0x7fe2acb-0x7fe2b02]\r\n[    0.000361] ACPI: Reserving MCFG table memory at [mem 0x7fe2b03-0x7fe2b3e]\r\n[    0.000361] ACPI: Reserving WAET table memory at [mem 0x7fe2b3f-0x7fe2b66]\r\n[    0.000598] Zone ranges:\r\n[    0.000598]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]\r\n[    0.000600]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]\r\n[    0.000600]   Normal   empty\r\n[    0.000601] Movable zone start for each node\r\n[    0.000601] Early memory node ranges\r\n[    0.000602]   node   0: [mem 0x0000000000001000-0x000000000009efff]\r\n[    0.000603]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]\r\n[    0.000603] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]\r\n[    0.001699] On node 0, zone DMA: 1 pages in unavailable ranges\r\n[    0.001732] On node 0, zone DMA: 97 pages in unavailable ranges\r\n[    0.002460] On node 0, zone DMA32: 35 pages in unavailable ranges\r\n[    0.027714] ACPI: PM-Timer IO Port: 0x608\r\n[    0.027721] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\r\n[    0.029691] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23\r\n[    0.029694] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)\r\n[    0.029696] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\r\n[    0.029696] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\r\n[    0.029697] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\r\n[    0.029698] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\r\n[    0.029701] ACPI: Using ACPI (MADT) for SMP configuration information\r\n[    0.029702] ACPI: HPET id: 0x8086a201 base: 0xfed00000\r\n[    0.029704] smpboot: Allowing 4 CPUs, 3 hotplug CPUs\r\n[    0.029710] [mem 0x08000000-0xafffffff] available for PCI devices\r\n[    0.029711] Booting paravirtualized kernel on Hyper-V\r\n[    0.029712] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.033995] setup_percpu: NR_CPUS:256 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1\r\n[    0.034978] percpu: Embedded 57 pages/cpu s195560 r8192 d29720 u524288\r\n[    0.034983] pcpu-alloc: s195560 r8192 d29720 u524288 alloc=1*2097152\r\n[    0.034985] pcpu-alloc: [0] 0 1 2 3 \r\n[    0.034997] Hyper-V: PV spinlocks enabled\r\n[    0.034998] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    0.035000] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt\r\n[    0.035039] Unknown kernel command line parameters \"BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage\", will be passed to user space.\r\n[    0.035048] random: crng init done\r\n[    0.035070] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r\n[    0.035082] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r\n[    0.035140] Built 1 zonelists, mobility grouping on.  Total pages: 31965\r\n[    0.035527] mem auto-init: stack:all(zero), heap alloc:on, heap free:off\r\n[    0.035913] Memory: 80436K/130540K available (14336K kernel code, 1799K rwdata, 8232K rodata, 2696K init, 2032K bss, 49844K reserved, 0K cma-reserved)\r\n[    0.036076] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1\r\n[    0.036723] Dynamic Preempt: none\r\n[    0.036760] rcu: Preemptible hierarchical RCU implementation.\r\n[    0.036760] rcu: \tRCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=4.\r\n[    0.036761] \tTrampoline variant of Tasks RCU enabled.\r\n[    0.036762] \tTracing variant of Tasks RCU enabled.\r\n[    0.036762] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.\r\n[    0.036763] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4\r\n[    0.038539] NR_IRQS: 16640, nr_irqs: 456, preallocated irqs: 16\r\n[    0.039486] rcu: srcu_init: Setting srcu_struct sizes based on contention.\r\n[    0.041677] kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)\r\n[    0.044271] Console: colour *CGA 80x25\r\n[    0.044272] printk: console [tty0] enabled\r\n[    0.044287] ACPI: Core revision 20230628\r\n[    0.048865] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns\r\n[    0.052513] APIC: Switch to symmetric I/O mode setup\r\n[    0.074848] x2apic enabled\r\n[    0.075122] APIC: Switched APIC routing to: physical x2apic\r\n[    0.075140] Hyper-V: Disabling IBT because of Hyper-V bug\r\n[    0.075141] Hyper-V: Using IPI hypercalls\r\n[    0.075142] APIC: send_IPI() replaced with hv_send_ipi()\r\n[    0.075146] APIC: send_IPI_mask() replaced with hv_send_ipi_mask()\r\n[    0.075148] APIC: send_IPI_mask_allbutself() replaced with hv_send_ipi_mask_allbutself()\r\n[    0.075150] APIC: send_IPI_allbutself() replaced with hv_send_ipi_allbutself()\r\n[    0.075152] APIC: send_IPI_all() replaced with hv_send_ipi_all()\r\n[    0.075154] APIC: send_IPI_self() replaced with hv_send_ipi_self()\r\n[    0.172616] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1\r\n[    0.174812] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=22999990)\r\n[    0.174884] x86/cpu: User Mode Instruction Prevention (UMIP) activated\r\n[    0.174892] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0\r\n[    0.174893] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0\r\n[    0.174897] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization\r\n[    0.174899] Spectre V2 : Mitigation: Retpolines\r\n[    0.174900] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch\r\n[    0.174900] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT\r\n[    0.174901] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!\r\n[    0.174902] RETBleed: Vulnerable\r\n[    0.174903] Speculative Store Bypass: Vulnerable\r\n[    0.174903] MMIO Stale Data: Unknown: No mitigations\r\n[    0.174920] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'\r\n[    0.174921] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'\r\n[    0.174922] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'\r\n[    0.174922] x86/fpu: Supporting XSAVE feature 0x800: 'Control-flow User registers'\r\n[    0.174923] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256\r\n[    0.174924] x86/fpu: xstate_offset[11]:  832, xstate_sizes[11]:   16\r\n[    0.174925] x86/fpu: Enabled xstate features 0x807, context size is 848 bytes, using 'compacted' format.\r\n[    0.191766] pid_max: default: 32768 minimum: 301\r\n[    0.191795] LSM: initializing lsm=lockdown,capability,landlock,integrity\r\n[    0.191814] landlock: Up and running.\r\n[    0.191830] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.191832] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    0.193253] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)\r\n[    0.193397] RCU Tasks: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.193408] RCU Tasks Trace: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.\r\n[    0.193418] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.\r\n[    0.193432] signal: max sigframe size: 1776\r\n[    0.193454] rcu: Hierarchical SRCU implementation.\r\n[    0.193454] rcu: \tMax phase no-delay instances is 1000.\r\n[    0.193605] NMI watchdog: Perf NMI watchdog permanently disabled\r\n[    0.193650] smp: Bringing up secondary CPUs ...\r\n[    0.193655] smp: Brought up 1 node, 1 CPU\r\n[    0.193656] smpboot: Max logical packages: 4\r\n[    0.193657] ----------------\r\n[    0.193658] | NMI testsuite:\r\n[    0.193658] --------------------\r\n[    0.193658]   remote IPI:  ok  |\r\n[    0.193659]    local IPI:  ok  |\r\n[    0.193667] --------------------\r\n[    0.193668] Good, all   2 testcases passed! |\r\n[    0.193668] ---------------------------------\r\n[    0.193669] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)\r\n[    0.193770] devtmpfs: initialized\r\n[    0.193798] x86/mm: Memory block size: 128MB\r\n[    0.193883] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns\r\n[    0.193897] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)\r\n[    0.194808] NET: Registered PF_NETLINK/PF_ROUTE protocol family\r\n[    0.194808] audit: initializing netlink subsys (disabled)\r\n[    0.194808] thermal_sys: Registered thermal governor 'step_wise'\r\n[    0.194808] audit: type=2000 audit(1762557020.010:1): state=initialized audit_enabled=0 res=1\r\n[    0.194808] cpuidle: using governor ladder\r\n[    0.194808] cpuidle: using governor menu\r\n[    0.194808] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5\r\n[    0.194808] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)\r\n[    0.194808] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved as E820 entry\r\n[    0.194808] PCI: Using configuration type 1 for base access\r\n[    0.194808] kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.\r\n[    0.194808] HugeTLB: registered 1.00 GiB page size, pre-allocated 0 pages\r\n[    0.194808] HugeTLB: 16380 KiB vmemmap can be freed for a 1.00 GiB page\r\n[    0.194808] HugeTLB: registered 2.00 MiB page size, pre-allocated 0 pages\r\n[    0.194808] HugeTLB: 28 KiB vmemmap can be freed for a 2.00 MiB page\r\n[    0.194808] ACPI: Added _OSI(Module Device)\r\n[    0.194808] ACPI: Added _OSI(Processor Device)\r\n[    0.194808] ACPI: Added _OSI(3.0 _SCP Extensions)\r\n[    0.194808] ACPI: Added _OSI(Processor Aggregator Device)\r\n[    0.194808] ACPI: 1 ACPI AML tables successfully acquired and loaded\r\n[    0.200580] ACPI: _OSC evaluation for CPUs failed, trying _PDC\r\n[    0.200642] ACPI: Interpreter enabled\r\n[    0.200647] ACPI: PM: (supports S0 S3 S5)\r\n[    0.200648] ACPI: Using IOAPIC for interrupt routing\r\n[    0.200659] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\r\n[    0.200660] PCI: Using E820 reservations for host bridge windows\r\n[    0.201128] ACPI: Enabled 2 GPEs in block 00 to 3F\r\n[    0.208715] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\r\n[    0.208719] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]\r\n[    0.208743] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]\r\n[    0.208772] acpi PNP0A08:00: _OSC: OS now controls [PME PCIeCapability]\r\n[    0.211716] PCI host bridge to bus 0000:00\r\n[    0.211717] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]\r\n[    0.211719] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]\r\n[    0.211720] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]\r\n[    0.211721] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]\r\n[    0.211722] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]\r\n[    0.211723] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]\r\n[    0.211724] pci_bus 0000:00: root bus resource [bus 00-ff]\r\n[    0.212877] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000\r\n[    0.221415] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400\r\n[    0.224666] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]\r\n[    0.233828] pci 0000:00:01.0: enabling Extended Tags\r\n[    0.254557] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400\r\n[    0.258319] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]\r\n[    0.266824] pci 0000:00:01.1: enabling Extended Tags\r\n[    0.287673] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400\r\n[    0.292099] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]\r\n[    0.300133] pci 0000:00:01.2: enabling Extended Tags\r\n[    0.322122] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400\r\n[    0.326175] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]\r\n[    0.335134] pci 0000:00:01.3: enabling Extended Tags\r\n[    0.355618] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400\r\n[    0.360025] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]\r\n[    0.367602] pci 0000:00:01.4: enabling Extended Tags\r\n[    0.386769] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400\r\n[    0.389814] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]\r\n[    0.397188] pci 0000:00:01.5: enabling Extended Tags\r\n[    0.414573] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400\r\n[    0.426469] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]\r\n[    0.457655] pci 0000:00:01.6: enabling Extended Tags\r\n[    0.478517] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400\r\n[    0.481185] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]\r\n[    0.489863] pci 0000:00:01.7: enabling Extended Tags\r\n[    0.510464] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400\r\n[    0.513559] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]\r\n[    0.519596] pci 0000:00:02.0: enabling Extended Tags\r\n[    0.540828] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400\r\n[    0.544566] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]\r\n[    0.552428] pci 0000:00:02.1: enabling Extended Tags\r\n[    0.577533] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100\r\n[    0.583564] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO\r\n[    0.586222] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601\r\n[    0.594308] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]\r\n[    0.595989] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]\r\n[    0.605721] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500\r\n[    0.611546] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]\r\n[    0.618074] acpiphp: Slot [0] registered\r\n[    0.620342] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000\r\n[    0.623469] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]\r\n[    0.628327] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]\r\n[    0.630235] pci 0000:01:00.0: enabling Extended Tags\r\n[    0.646203] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    0.646631] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    0.647056] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    0.650049] acpiphp: Slot [0-2] registered\r\n[    0.650254] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    0.650668] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    0.651096] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    0.653901] acpiphp: Slot [0-3] registered\r\n[    0.654102] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    0.654526] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    0.654918] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    0.657582] acpiphp: Slot [0-4] registered\r\n[    0.657785] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    0.658211] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    0.658730] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    0.661466] acpiphp: Slot [0-5] registered\r\n[    0.663761] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000\r\n[    0.666809] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]\r\n[    0.671252] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]\r\n[    0.673174] pci 0000:05:00.0: enabling Extended Tags\r\n[    0.689204] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    0.689628] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    0.690053] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    0.692762] acpiphp: Slot [0-6] registered\r\n[    0.694998] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000\r\n[    0.698148] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]\r\n[    0.702860] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]\r\n[    0.704810] pci 0000:06:00.0: enabling Extended Tags\r\n[    0.721085] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    0.721527] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    0.721959] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    0.724794] acpiphp: Slot [0-7] registered\r\n[    0.727048] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000\r\n[    0.746237] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]\r\n[    0.777011] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]\r\n[    0.787612] pci 0000:07:00.0: enabling Extended Tags\r\n[    0.807911] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    0.808329] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    0.808760] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    0.811536] acpiphp: Slot [0-8] registered\r\n[    0.813838] pci 0000:08:00.0: [1af4:1045] type 00 class 0x00ff00\r\n[    0.816870] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]\r\n[    0.821032] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]\r\n[    0.823143] pci 0000:08:00.0: enabling Extended Tags\r\n[    0.839281] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    0.839710] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    0.840139] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    0.842935] acpiphp: Slot [0-9] registered\r\n[    0.845101] pci 0000:09:00.0: [1af4:1044] type 00 class 0x00ff00\r\n[    0.848557] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]\r\n[    0.852649] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]\r\n[    0.854773] pci 0000:09:00.0: enabling Extended Tags\r\n[    0.870847] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    0.871271] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    0.871708] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    0.874476] acpiphp: Slot [0-10] registered\r\n[    0.874680] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    0.875027] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    0.875451] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    0.884240] pci_bus 0000:00: on NUMA node 0\r\n[    0.885125] ACPI: PCI: Interrupt link LNKA configured for IRQ 10\r\n[    0.885564] ACPI: PCI: Interrupt link LNKB configured for IRQ 10\r\n[    0.885987] ACPI: PCI: Interrupt link LNKC configured for IRQ 11\r\n[    0.886418] ACPI: PCI: Interrupt link LNKD configured for IRQ 11\r\n[    0.887157] ACPI: PCI: Interrupt link LNKE configured for IRQ 10\r\n[    0.887578] ACPI: PCI: Interrupt link LNKF configured for IRQ 10\r\n[    0.888013] ACPI: PCI: Interrupt link LNKG configured for IRQ 11\r\n[    0.888441] ACPI: PCI: Interrupt link LNKH configured for IRQ 11\r\n[    0.888660] ACPI: PCI: Interrupt link GSIA configured for IRQ 16\r\n[    0.888665] ACPI: PCI: Interrupt link GSIB configured for IRQ 17\r\n[    0.888670] ACPI: PCI: Interrupt link GSIC configured for IRQ 18\r\n[    0.888675] ACPI: PCI: Interrupt link GSID configured for IRQ 19\r\n[    0.888681] ACPI: PCI: Interrupt link GSIE configured for IRQ 20\r\n[    0.888685] ACPI: PCI: Interrupt link GSIF configured for IRQ 21\r\n[    0.888689] ACPI: PCI: Interrupt link GSIG configured for IRQ 22\r\n[    0.888693] ACPI: PCI: Interrupt link GSIH configured for IRQ 23\r\n[    0.889633] iommu: Default domain type: Translated\r\n[    0.889634] iommu: DMA domain TLB invalidation policy: lazy mode\r\n[    0.889715] SCSI subsystem initialized\r\n[    0.889782] libata version 3.00 loaded.\r\n[    0.889796] pps_core: LinuxPPS API ver. 1 registered\r\n[    0.889797] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;\r\n[    0.889801] PTP clock support registered\r\n[    0.890020] PCI: Using ACPI for IRQ routing\r\n[    1.731738] PCI: pci_cache_line_size set to 64 bytes\r\n[    1.736021] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]\r\n[    1.736024] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]\r\n[    1.736109] clocksource: Switched to clocksource hyperv_clocksource_tsc_page\r\n[    1.736214] VFS: Disk quotas dquot_6.6.0\r\n[    1.736222] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\r\n[    1.736254] pnp: PnP ACPI init\r\n[    1.736350] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved\r\n[    1.737623] pnp: PnP ACPI: found 5 devices\r\n[    1.744792] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns\r\n[    1.744808] NET: Registered PF_INET protocol family\r\n[    1.744808] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)\r\n[    1.744808] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    1.744808] Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)\r\n[    1.744808] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r\n[    1.744808] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)\r\n[    1.744808] TCP: Hash tables configured (established 1024 bind 1024)\r\n[    1.744808] MPTCP token hash table entries: 256 (order: 0, 6144 bytes, linear)\r\n[    1.744808] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.744808] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    1.744808] NET: Registered PF_UNIX/PF_LOCAL protocol family\r\n[    1.744808] NET: Registered PF_XDP protocol family\r\n[    1.744808] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000\r\n[    1.744808] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000\r\n[    1.744808] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000\r\n[    1.744808] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000\r\n[    1.744808] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000\r\n[    1.744808] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000\r\n[    1.744808] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000\r\n[    1.744808] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000\r\n[    1.744808] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000\r\n[    1.744808] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000\r\n[    1.744808] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]\r\n[    1.744808] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]\r\n[    1.744808] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]\r\n[    1.744808] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]\r\n[    1.744808] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]\r\n[    1.744808] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]\r\n[    1.744808] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]\r\n[    1.744808] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]\r\n[    1.744808] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]\r\n[    1.744808] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]\r\n[    1.744808] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    1.744848] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]\r\n[    1.746544] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    1.747536] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.749612] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    1.749832] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]\r\n[    1.751502] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    1.752487] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.754371] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    1.754591] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]\r\n[    1.756223] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    1.757038] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.758583] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    1.758818] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]\r\n[    1.760102] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    1.760994] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.762658] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    1.762884] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]\r\n[    1.764056] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    1.765041] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.767330] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    1.767544] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]\r\n[    1.768711] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    1.769491] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.771077] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    1.771350] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]\r\n[    1.772507] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    1.773337] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.775103] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    1.775344] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]\r\n[    1.776641] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    1.778173] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.779536] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    1.779746] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]\r\n[    1.780894] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    1.781650] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.782923] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    1.783134] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]\r\n[    1.784317] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    1.785001] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.786801] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]\r\n[    1.786802] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]\r\n[    1.786803] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]\r\n[    1.786804] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]\r\n[    1.786805] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]\r\n[    1.786806] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]\r\n[    1.786806] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]\r\n[    1.786807] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]\r\n[    1.786808] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.786809] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]\r\n[    1.786810] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]\r\n[    1.786810] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.786811] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]\r\n[    1.786812] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]\r\n[    1.786813] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.786813] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]\r\n[    1.786814] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]\r\n[    1.786815] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.786816] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]\r\n[    1.786816] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]\r\n[    1.786817] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.786818] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]\r\n[    1.786819] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]\r\n[    1.786819] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    1.786820] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]\r\n[    1.786821] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]\r\n[    1.786821] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    1.786822] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]\r\n[    1.786823] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]\r\n[    1.786824] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    1.786824] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]\r\n[    1.786825] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]\r\n[    1.786826] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    1.786827] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]\r\n[    1.786827] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]\r\n[    1.786828] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    1.791674] PCI: CLS 0 bytes, default 64\r\n[    1.792016] Initialise system trusted keyrings\r\n[    1.792080] Unpacking initramfs...\r\n[    1.823255] workingset: timestamp_bits=46 max_order=15 bucket_order=0\r\n[    1.823262] zbud: loaded\r\n[    1.823325] Key type asymmetric registered\r\n[    1.823326] Asymmetric key parser 'x509' registered\r\n[    1.823346] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 247)\r\n[    1.824279] io scheduler mq-deadline registered\r\n[    1.824279] io scheduler kyber registered\r\n[    1.824284] io scheduler bfq registered\r\n[    1.824606] ACPI: \\_SB_.GSIF: Enabled at IRQ 21\r\n[    1.834338] pcieport 0000:00:01.0: PME: Signaling with IRQ 24\r\n[    1.853579] pcieport 0000:00:01.1: PME: Signaling with IRQ 25\r\n[    1.872612] pcieport 0000:00:01.2: PME: Signaling with IRQ 26\r\n[    1.892409] pcieport 0000:00:01.3: PME: Signaling with IRQ 27\r\n[    1.911798] pcieport 0000:00:01.4: PME: Signaling with IRQ 28\r\n[    1.930916] pcieport 0000:00:01.5: PME: Signaling with IRQ 29\r\n[    1.950020] pcieport 0000:00:01.6: PME: Signaling with IRQ 30\r\n[    1.969136] pcieport 0000:00:01.7: PME: Signaling with IRQ 31\r\n[    1.978296] ACPI: \\_SB_.GSIG: Enabled at IRQ 22\r\n[    1.988345] pcieport 0000:00:02.0: PME: Signaling with IRQ 32\r\n[    2.008020] pcieport 0000:00:02.1: PME: Signaling with IRQ 33\r\n[    2.016802] ERST DBG: ERST support is disabled.\r\n[    2.223266] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled\r\n[    2.225729] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\r\n[    2.603963] Freeing initrd memory: 8776K\r\n[    2.606519] VMware PVSCSI driver - version 1.0.7.0-k\r\n[    2.606540] ahci 0000:00:1f.2: version 3.0\r\n[    2.606873] ACPI: \\_SB_.GSIA: Enabled at IRQ 16\r\n[    2.632355] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode\r\n[    2.632358] ahci 0000:00:1f.2: flags: 64bit ncq only \r\n[    2.657535] scsi host0: ahci\r\n[    2.657652] scsi host1: ahci\r\n[    2.657737] scsi host2: ahci\r\n[    2.657805] scsi host3: ahci\r\n[    2.657869] scsi host4: ahci\r\n[    2.657954] scsi host5: ahci\r\n[    2.658184] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 36\r\n[    2.658482] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 36\r\n[    2.658661] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 36\r\n[    2.659040] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 36\r\n[    2.659220] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 36\r\n[    2.659516] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 36\r\n[    2.659572] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\r\n[    2.679738] serio: i8042 KBD port at 0x60,0x64 irq 1\r\n[    2.679742] serio: i8042 AUX port at 0x60,0x64 irq 12\r\n[    2.679757] rtc_cmos 00:03: RTC can wake from S4\r\n[    2.701304] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input0\r\n[    2.727625] rtc_cmos 00:03: registered as rtc0\r\n[    2.730816] rtc_cmos 00:03: setting system clock to 2025-11-07T23:10:23 UTC (1762557023)\r\n[    2.731713] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs\r\n[    2.731723] intel_pstate: CPU model not supported\r\n[    2.731800] gre: GRE over IPv4 demultiplexor driver\r\n[    2.740746] NET: Registered PF_INET6 protocol family\r\n[    2.740881] Segment Routing with IPv6\r\n[    2.740885] In-situ OAM (IOAM) with IPv6\r\n[    2.740916] Key type dns_resolver registered\r\n[    2.740941] IPI shorthand broadcast: enabled\r\n[    2.741656] sched_clock: Marking stable (2600003100, 133202100)-&gt;(3051690400, -318485200)\r\n[    2.747042] registered taskstats version 1\r\n[    2.747094] Loading compiled-in X.509 certificates\r\n[    2.749194] Loaded X.509 cert 'alpinelinux.org: Alpine Linux kernel key: d76a695f66ad9cd28f5c22a8508f36e91f521f7a'\r\n[    2.750518] Key type .fscrypt registered\r\n[    2.750520] Key type fscrypt-provisioning registered\r\n[    3.040250] ata1: SATA link down (SStatus 0 SControl 300)\r\n[    3.051877] ata2: SATA link down (SStatus 0 SControl 300)\r\n[    3.057725] ata3: SATA link down (SStatus 0 SControl 300)\r\n[    3.064160] ata4: SATA link down (SStatus 0 SControl 300)\r\n[    3.070012] ata5: SATA link down (SStatus 0 SControl 300)\r\n[    3.075425] ata6: SATA link down (SStatus 0 SControl 300)\r\n[    3.077547] Freeing unused kernel image (initmem) memory: 2696K\r\n[    3.077550] Write protecting the kernel read-only data: 24576k\r\n[    3.078154] Freeing unused kernel image (rodata/data gap) memory: 2008K\r\n[    3.078159] rodata_test: all tests were successful\r\n[    3.078163] Run /init as init process\r\n[    3.078163]   with arguments:\r\n[    3.078164]     /init\r\n[    3.078165]   with environment:\r\n[    3.078165]     HOME=/\r\n[    3.078166]     TERM=linux\r\n[    3.078166]     BOOT_IMAGE=/boot/vmlinuz-virt\r\n[    3.078166]     modules=loop,squashfs,sd-mod,usb-storage\r\n[    3.081820] Alpine Init 3.10.1-r0\r\n[    3.082102] Loading boot drivers...\r\n[    3.084795] loop: module loaded\r\n[    3.086145] squashfs: version 4.0 (2009/01/31) Phillip Lougher\r\n[    3.096134] ACPI: bus type USB registered\r\n[    3.096151] usbcore: registered new interface driver usbfs\r\n[    3.096155] usbcore: registered new interface driver hub\r\n[    3.096159] usbcore: registered new device driver usb\r\n[    3.097555] usbcore: registered new interface driver usb-storage\r\n[    3.112030] ACPI: bus type drm_connector registered\r\n[    3.118702] Loading boot drivers: ok.\r\n[    3.119289] Mounting boot media...\r\n[    3.174809] scsi host6: Virtio SCSI HBA\r\n[    3.226310] Free page reporting enabled\r\n[    3.271131] virtio_blk virtio3: 1/0/0 default/read/poll queues\r\n[    3.290621] virtio_blk virtio3: [vda] 124928 512-byte logical blocks (64.0 MB/61.0 MiB)\r\n[    3.291914]  vda: vda1 vda2\r\n[    3.369387] ISO 9660 Extensions: Microsoft Joliet Level 3\r\n[    3.369866] ISO 9660 Extensions: RRIP_1991A\r\n[    3.646390] Mounting boot media: ok.\r\n[    3.663188] Installing packages to root filesystem...\r\n[    3.884643] Installing packages to root filesystem: ok.\r\n[    4.119278] loop0: detected capacity change from 0 to 39312\r\n[    4.321131] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input3\r\n[    4.353225] ACPI: button: Power Button [PWRF]\r\n[    4.398449] cryptd: max_cpu_qlen set to 1000\r\n[    4.457797] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input4\r\n[    4.474034] mousedev: PS/2 mouse device common for all mice\r\n[    4.586174] NET: Registered PF_PACKET protocol family\r\nlocalhost:~" "" "# "] Buffer: dmesg
[    0.000000] Linux version 6.6.34-1-virt (buildozer@build-3-20-x86_64) (gcc (Alpine 13.2.1_git20240309) 13.2.1 20240309, GNU ld (GNU Binutils) 2.42) #2-Alpine SMP PREEMPT_DYNAMIC Tue, 18 Jun 2024 10:38:37 +0000
[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable
[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved
[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] APIC: Static calls initialized
[    0.000000] SMBIOS 2.8 present.
[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014
[    0.000000] Hypervisor detected: Microsoft Hyper-V
[    0.000000] Hyper-V: privilege flags low 0xe7e, high 0x0, hints 0x60624, misc 0xe0130
[    0.000000] Hyper-V: Host Build 10.0.26100.1381-1-0
[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480
[    0.000000] Hyper-V: Using hypercall for remote TLB flush
[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000000] clocksource: hyperv_clocksource_msr: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000002] tsc: Marking TSC unstable due to running on Hyper-V
[    0.000004] tsc: Detected 2299.999 MHz processor
[    0.000182] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved
[    0.000184] e820: remove [mem 0x000a0000-0x000fffff] usable
[    0.000187] last_pfn = 0x7fdd max_arch_pfn = 0x400000000
[    0.000207] MTRR map: 4 entries (3 fixed + 1 variable; max 19), built from 8 variable MTRRs
[    0.000209] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  
[    0.000242] Using GB pages for direct mapping
[    0.000337] RAMDISK: [mem 0x0774b000-0x07fdcfff]
[    0.000338] ACPI: Early table checksum verification disabled
[    0.000339] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )
[    0.000342] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000345] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000349] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000351] ACPI: FACS 0x0000000007FE0000 000040
[    0.000352] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000354] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000355] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000357] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.000358] ACPI: Reserving FACP table memory at [mem 0x7fe2947-0x7fe2a3a]
[    0.000359] ACPI: Reserving DSDT table memory at [mem 0x7fe0040-0x7fe2946]
[    0.000359] ACPI: Reserving FACS table memory at [mem 0x7fe0000-0x7fe003f]
[    0.000360] ACPI: Reserving APIC table memory at [mem 0x7fe2a3b-0x7fe2aca]
[    0.000360] ACPI: Reserving HPET table memory at [mem 0x7fe2acb-0x7fe2b02]
[    0.000361] ACPI: Reserving MCFG table memory at [mem 0x7fe2b03-0x7fe2b3e]
[    0.000361] ACPI: Reserving WAET table memory at [mem 0x7fe2b3f-0x7fe2b66]
[    0.000598] Zone ranges:
[    0.000598]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.000600]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]
[    0.000600]   Normal   empty
[    0.000601] Movable zone start for each node
[    0.000601] Early memory node ranges
[    0.000602]   node   0: [mem 0x0000000000001000-0x000000000009efff]
[    0.000603]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]
[    0.000603] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]
[    0.001699] On node 0, zone DMA: 1 pages in unavailable ranges
[    0.001732] On node 0, zone DMA: 97 pages in unavailable ranges
[    0.002460] On node 0, zone DMA32: 35 pages in unavailable ranges
[    0.027714] ACPI: PM-Timer IO Port: 0x608
[    0.027721] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])
[    0.029691] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23
[    0.029694] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
[    0.029696] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)
[    0.029696] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.029697] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)
[    0.029698] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)
[    0.029701] ACPI: Using ACPI (MADT) for SMP configuration information
[    0.029702] ACPI: HPET id: 0x8086a201 base: 0xfed00000
[    0.029704] smpboot: Allowing 4 CPUs, 3 hotplug CPUs
[    0.029710] [mem 0x08000000-0xafffffff] available for PCI devices
[    0.029711] Booting paravirtualized kernel on Hyper-V
[    0.029712] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.033995] setup_percpu: NR_CPUS:256 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1
[    0.034978] percpu: Embedded 57 pages/cpu s195560 r8192 d29720 u524288
[    0.034983] pcpu-alloc: s195560 r8192 d29720 u524288 alloc=1*2097152
[    0.034985] pcpu-alloc: [0] 0 1 2 3 
[    0.034997] Hyper-V: PV spinlocks enabled
[    0.034998] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)
[    0.035000] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage quiet  initrd=/boot/initramfs-virt
[    0.035039] Unknown kernel command line parameters "BOOT_IMAGE=/boot/vmlinuz-virt modules=loop,squashfs,sd-mod,usb-storage", will be passed to user space.
[    0.035048] random: crng init done
[    0.035070] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)
[    0.035082] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)
[    0.035140] Built 1 zonelists, mobility grouping on.  Total pages: 31965
[    0.035527] mem auto-init: stack:all(zero), heap alloc:on, heap free:off
[    0.035913] Memory: 80436K/130540K available (14336K kernel code, 1799K rwdata, 8232K rodata, 2696K init, 2032K bss, 49844K reserved, 0K cma-reserved)
[    0.036076] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1
[    0.036723] Dynamic Preempt: none
[    0.036760] rcu: Preemptible hierarchical RCU implementation.
[    0.036760] rcu: 	RCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=4.
[    0.036761] 	Trampoline variant of Tasks RCU enabled.
[    0.036762] 	Tracing variant of Tasks RCU enabled.
[    0.036762] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.
[    0.036763] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4
[    0.038539] NR_IRQS: 16640, nr_irqs: 456, preallocated irqs: 16
[    0.039486] rcu: srcu_init: Setting srcu_struct sizes based on contention.
[    0.041677] kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)
[    0.044271] Console: colour *CGA 80x25
[    0.044272] printk: console [tty0] enabled
[    0.044287] ACPI: Core revision 20230628
[    0.048865] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns
[    0.052513] APIC: Switch to symmetric I/O mode setup
[    0.074848] x2apic enabled
[    0.075122] APIC: Switched APIC routing to: physical x2apic
[    0.075140] Hyper-V: Disabling IBT because of Hyper-V bug
[    0.075141] Hyper-V: Using IPI hypercalls
[    0.075142] APIC: send_IPI() replaced with hv_send_ipi()
[    0.075146] APIC: send_IPI_mask() replaced with hv_send_ipi_mask()
[    0.075148] APIC: send_IPI_mask_allbutself() replaced with hv_send_ipi_mask_allbutself()
[    0.075150] APIC: send_IPI_allbutself() replaced with hv_send_ipi_allbutself()
[    0.075152] APIC: send_IPI_all() replaced with hv_send_ipi_all()
[    0.075154] APIC: send_IPI_self() replaced with hv_send_ipi_self()
[    0.172616] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
[    0.174812] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=22999990)
[    0.174884] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    0.174892] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
[    0.174893] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
[    0.174897] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
[    0.174899] Spectre V2 : Mitigation: Retpolines
[    0.174900] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
[    0.174900] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT
[    0.174901] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!
[    0.174902] RETBleed: Vulnerable
[    0.174903] Speculative Store Bypass: Vulnerable
[    0.174903] MMIO Stale Data: Unknown: No mitigations
[    0.174920] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.174921] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.174922] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.174922] x86/fpu: Supporting XSAVE feature 0x800: 'Control-flow User registers'
[    0.174923] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.174924] x86/fpu: xstate_offset[11]:  832, xstate_sizes[11]:   16
[    0.174925] x86/fpu: Enabled xstate features 0x807, context size is 848 bytes, using 'compacted' format.
[    0.191766] pid_max: default: 32768 minimum: 301
[    0.191795] LSM: initializing lsm=lockdown,capability,landlock,integrity
[    0.191814] landlock: Up and running.
[    0.191830] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[    0.191832] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[    0.193253] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)
[    0.193397] RCU Tasks: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.
[    0.193408] RCU Tasks Trace: Setting shift to 2 and lim to 1 rcu_task_cb_adjust=1.
[    0.193418] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.
[    0.193432] signal: max sigframe size: 1776
[    0.193454] rcu: Hierarchical SRCU implementation.
[    0.193454] rcu: 	Max phase no-delay instances is 1000.
[    0.193605] NMI watchdog: Perf NMI watchdog permanently disabled
[    0.193650] smp: Bringing up secondary CPUs ...
[    0.193655] smp: Brought up 1 node, 1 CPU
[    0.193656] smpboot: Max logical packages: 4
[    0.193657] ----------------
[    0.193658] | NMI testsuite:
[    0.193658] --------------------
[    0.193658]   remote IPI:  ok  |
[    0.193659]    local IPI:  ok  |
[    0.193667] --------------------
[    0.193668] Good, all   2 testcases passed! |
[    0.193668] ---------------------------------
[    0.193669] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)
[    0.193770] devtmpfs: initialized
[    0.193798] x86/mm: Memory block size: 128MB
[    0.193883] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.193897] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)
[    0.194808] NET: Registered PF_NETLINK/PF_ROUTE protocol family
[    0.194808] audit: initializing netlink subsys (disabled)
[    0.194808] thermal_sys: Registered thermal governor 'step_wise'
[    0.194808] audit: type=2000 audit(1762557020.010:1): state=initialized audit_enabled=0 res=1
[    0.194808] cpuidle: using governor ladder
[    0.194808] cpuidle: using governor menu
[    0.194808] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
[    0.194808] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)
[    0.194808] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved as E820 entry
[    0.194808] PCI: Using configuration type 1 for base access
[    0.194808] kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.
[    0.194808] HugeTLB: registered 1.00 GiB page size, pre-allocated 0 pages
[    0.194808] HugeTLB: 16380 KiB vmemmap can be freed for a 1.00 GiB page
[    0.194808] HugeTLB: registered 2.00 MiB page size, pre-allocated 0 pages
[    0.194808] HugeTLB: 28 KiB vmemmap can be freed for a 2.00 MiB page
[    0.194808] ACPI: Added _OSI(Module Device)
[    0.194808] ACPI: Added _OSI(Processor Device)
[    0.194808] ACPI: Added _OSI(3.0 _SCP Extensions)
[    0.194808] ACPI: Added _OSI(Processor Aggregator Device)
[    0.194808] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    0.200580] ACPI: _OSC evaluation for CPUs failed, trying _PDC
[    0.200642] ACPI: Interpreter enabled
[    0.200647] ACPI: PM: (supports S0 S3 S5)
[    0.200648] ACPI: Using IOAPIC for interrupt routing
[    0.200659] PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
[    0.200660] PCI: Using E820 reservations for host bridge windows
[    0.201128] ACPI: Enabled 2 GPEs in block 00 to 3F
[    0.208715] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])
[    0.208719] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]
[    0.208743] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]
[    0.208772] acpi PNP0A08:00: _OSC: OS now controls [PME PCIeCapability]
[    0.211716] PCI host bridge to bus 0000:00
[    0.211717] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]
[    0.211719] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]
[    0.211720] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]
[    0.211721] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]
[    0.211722] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]
[    0.211723] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]
[    0.211724] pci_bus 0000:00: root bus resource [bus 00-ff]
[    0.212877] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000
[    0.221415] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400
[    0.224666] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]
[    0.233828] pci 0000:00:01.0: enabling Extended Tags
[    0.254557] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400
[    0.258319] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]
[    0.266824] pci 0000:00:01.1: enabling Extended Tags
[    0.287673] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400
[    0.292099] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]
[    0.300133] pci 0000:00:01.2: enabling Extended Tags
[    0.322122] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400
[    0.326175] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]
[    0.335134] pci 0000:00:01.3: enabling Extended Tags
[    0.355618] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400
[    0.360025] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]
[    0.367602] pci 0000:00:01.4: enabling Extended Tags
[    0.386769] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400
[    0.389814] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]
[    0.397188] pci 0000:00:01.5: enabling Extended Tags
[    0.414573] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400
[    0.426469] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]
[    0.457655] pci 0000:00:01.6: enabling Extended Tags
[    0.478517] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400
[    0.481185] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]
[    0.489863] pci 0000:00:01.7: enabling Extended Tags
[    0.510464] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400
[    0.513559] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]
[    0.519596] pci 0000:00:02.0: enabling Extended Tags
[    0.540828] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400
[    0.544566] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]
[    0.552428] pci 0000:00:02.1: enabling Extended Tags
[    0.577533] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100
[    0.583564] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO
[    0.586222] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601
[    0.594308] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]
[    0.595989] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]
[    0.605721] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500
[    0.611546] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]
[    0.618074] acpiphp: Slot [0] registered
[    0.620342] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000
[    0.623469] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]
[    0.628327] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]
[    0.630235] pci 0000:01:00.0: enabling Extended Tags
[    0.646203] pci 0000:00:01.0: PCI bridge to [bus 01]
[    0.646631] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    0.647056] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    0.650049] acpiphp: Slot [0-2] registered
[    0.650254] pci 0000:00:01.1: PCI bridge to [bus 02]
[    0.650668] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    0.651096] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    0.653901] acpiphp: Slot [0-3] registered
[    0.654102] pci 0000:00:01.2: PCI bridge to [bus 03]
[    0.654526] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    0.654918] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    0.657582] acpiphp: Slot [0-4] registered
[    0.657785] pci 0000:00:01.3: PCI bridge to [bus 04]
[    0.658211] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    0.658730] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    0.661466] acpiphp: Slot [0-5] registered
[    0.663761] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000
[    0.666809] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]
[    0.671252] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]
[    0.673174] pci 0000:05:00.0: enabling Extended Tags
[    0.689204] pci 0000:00:01.4: PCI bridge to [bus 05]
[    0.689628] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    0.690053] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    0.692762] acpiphp: Slot [0-6] registered
[    0.694998] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000
[    0.698148] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]
[    0.702860] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]
[    0.704810] pci 0000:06:00.0: enabling Extended Tags
[    0.721085] pci 0000:00:01.5: PCI bridge to [bus 06]
[    0.721527] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    0.721959] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    0.724794] acpiphp: Slot [0-7] registered
[    0.727048] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000
[    0.746237] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]
[    0.777011] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]
[    0.787612] pci 0000:07:00.0: enabling Extended Tags
[    0.807911] pci 0000:00:01.6: PCI bridge to [bus 07]
[    0.808329] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    0.808760] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    0.811536] acpiphp: Slot [0-8] registered
[    0.813838] pci 0000:08:00.0: [1af4:1045] type 00 class 0x00ff00
[    0.816870] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]
[    0.821032] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]
[    0.823143] pci 0000:08:00.0: enabling Extended Tags
[    0.839281] pci 0000:00:01.7: PCI bridge to [bus 08]
[    0.839710] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    0.840139] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    0.842935] acpiphp: Slot [0-9] registered
[    0.845101] pci 0000:09:00.0: [1af4:1044] type 00 class 0x00ff00
[    0.848557] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]
[    0.852649] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]
[    0.854773] pci 0000:09:00.0: enabling Extended Tags
[    0.870847] pci 0000:00:02.0: PCI bridge to [bus 09]
[    0.871271] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    0.871708] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    0.874476] acpiphp: Slot [0-10] registered
[    0.874680] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    0.875027] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    0.875451] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    0.884240] pci_bus 0000:00: on NUMA node 0
[    0.885125] ACPI: PCI: Interrupt link LNKA configured for IRQ 10
[    0.885564] ACPI: PCI: Interrupt link LNKB configured for IRQ 10
[    0.885987] ACPI: PCI: Interrupt link LNKC configured for IRQ 11
[    0.886418] ACPI: PCI: Interrupt link LNKD configured for IRQ 11
[    0.887157] ACPI: PCI: Interrupt link LNKE configured for IRQ 10
[    0.887578] ACPI: PCI: Interrupt link LNKF configured for IRQ 10
[    0.888013] ACPI: PCI: Interrupt link LNKG configured for IRQ 11
[    0.888441] ACPI: PCI: Interrupt link LNKH configured for IRQ 11
[    0.888660] ACPI: PCI: Interrupt link GSIA configured for IRQ 16
[    0.888665] ACPI: PCI: Interrupt link GSIB configured for IRQ 17
[    0.888670] ACPI: PCI: Interrupt link GSIC configured for IRQ 18
[    0.888675] ACPI: PCI: Interrupt link GSID configured for IRQ 19
[    0.888681] ACPI: PCI: Interrupt link GSIE configured for IRQ 20
[    0.888685] ACPI: PCI: Interrupt link GSIF configured for IRQ 21
[    0.888689] ACPI: PCI: Interrupt link GSIG configured for IRQ 22
[    0.888693] ACPI: PCI: Interrupt link GSIH configured for IRQ 23
[    0.889633] iommu: Default domain type: Translated
[    0.889634] iommu: DMA domain TLB invalidation policy: lazy mode
[    0.889715] SCSI subsystem initialized
[    0.889782] libata version 3.00 loaded.
[    0.889796] pps_core: LinuxPPS API ver. 1 registered
[    0.889797] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;
[    0.889801] PTP clock support registered
[    0.890020] PCI: Using ACPI for IRQ routing
[    1.731738] PCI: pci_cache_line_size set to 64 bytes
[    1.736021] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]
[    1.736024] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]
[    1.736109] clocksource: Switched to clocksource hyperv_clocksource_tsc_page
[    1.736214] VFS: Disk quotas dquot_6.6.0
[    1.736222] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    1.736254] pnp: PnP ACPI init
[    1.736350] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved
[    1.737623] pnp: PnP ACPI: found 5 devices
[    1.744792] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns
[    1.744808] NET: Registered PF_INET protocol family
[    1.744808] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)
[    1.744808] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)
[    1.744808] Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)
[    1.744808] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)
[    1.744808] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)
[    1.744808] TCP: Hash tables configured (established 1024 bind 1024)
[    1.744808] MPTCP token hash table entries: 256 (order: 0, 6144 bytes, linear)
[    1.744808] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)
[    1.744808] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)
[    1.744808] NET: Registered PF_UNIX/PF_LOCAL protocol family
[    1.744808] NET: Registered PF_XDP protocol family
[    1.744808] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000
[    1.744808] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000
[    1.744808] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000
[    1.744808] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000
[    1.744808] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000
[    1.744808] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000
[    1.744808] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000
[    1.744808] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000
[    1.744808] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000
[    1.744808] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000
[    1.744808] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]
[    1.744808] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]
[    1.744808] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]
[    1.744808] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]
[    1.744808] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]
[    1.744808] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]
[    1.744808] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]
[    1.744808] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]
[    1.744808] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]
[    1.744808] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]
[    1.744808] pci 0000:00:01.0: PCI bridge to [bus 01]
[    1.744848] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]
[    1.746544] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    1.747536] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    1.749612] pci 0000:00:01.1: PCI bridge to [bus 02]
[    1.749832] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]
[    1.751502] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    1.752487] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    1.754371] pci 0000:00:01.2: PCI bridge to [bus 03]
[    1.754591] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]
[    1.756223] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    1.757038] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    1.758583] pci 0000:00:01.3: PCI bridge to [bus 04]
[    1.758818] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]
[    1.760102] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    1.760994] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    1.762658] pci 0000:00:01.4: PCI bridge to [bus 05]
[    1.762884] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]
[    1.764056] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    1.765041] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    1.767330] pci 0000:00:01.5: PCI bridge to [bus 06]
[    1.767544] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]
[    1.768711] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    1.769491] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    1.771077] pci 0000:00:01.6: PCI bridge to [bus 07]
[    1.771350] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]
[    1.772507] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    1.773337] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    1.775103] pci 0000:00:01.7: PCI bridge to [bus 08]
[    1.775344] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]
[    1.776641] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    1.778173] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    1.779536] pci 0000:00:02.0: PCI bridge to [bus 09]
[    1.779746] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]
[    1.780894] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    1.781650] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    1.782923] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    1.783134] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]
[    1.784317] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    1.785001] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    1.786801] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]
[    1.786802] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]
[    1.786803] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]
[    1.786804] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]
[    1.786805] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]
[    1.786806] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]
[    1.786806] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]
[    1.786807] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]
[    1.786808] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]
[    1.786809] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]
[    1.786810] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]
[    1.786810] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]
[    1.786811] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]
[    1.786812] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]
[    1.786813] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]
[    1.786813] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]
[    1.786814] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]
[    1.786815] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]
[    1.786816] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]
[    1.786816] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]
[    1.786817] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]
[    1.786818] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]
[    1.786819] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]
[    1.786819] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]
[    1.786820] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]
[    1.786821] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]
[    1.786821] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]
[    1.786822] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]
[    1.786823] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]
[    1.786824] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]
[    1.786824] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]
[    1.786825] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]
[    1.786826] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]
[    1.786827] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]
[    1.786827] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]
[    1.786828] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]
[    1.791674] PCI: CLS 0 bytes, default 64
[    1.792016] Initialise system trusted keyrings
[    1.792080] Unpacking initramfs...
[    1.823255] workingset: timestamp_bits=46 max_order=15 bucket_order=0
[    1.823262] zbud: loaded
[    1.823325] Key type asymmetric registered
[    1.823326] Asymmetric key parser 'x509' registered
[    1.823346] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 247)
[    1.824279] io scheduler mq-deadline registered
[    1.824279] io scheduler kyber registered
[    1.824284] io scheduler bfq registered
[    1.824606] ACPI: \_SB_.GSIF: Enabled at IRQ 21
[    1.834338] pcieport 0000:00:01.0: PME: Signaling with IRQ 24
[    1.853579] pcieport 0000:00:01.1: PME: Signaling with IRQ 25
[    1.872612] pcieport 0000:00:01.2: PME: Signaling with IRQ 26
[    1.892409] pcieport 0000:00:01.3: PME: Signaling with IRQ 27
[    1.911798] pcieport 0000:00:01.4: PME: Signaling with IRQ 28
[    1.930916] pcieport 0000:00:01.5: PME: Signaling with IRQ 29
[    1.950020] pcieport 0000:00:01.6: PME: Signaling with IRQ 30
[    1.969136] pcieport 0000:00:01.7: PME: Signaling with IRQ 31
[    1.978296] ACPI: \_SB_.GSIG: Enabled at IRQ 22
[    1.988345] pcieport 0000:00:02.0: PME: Signaling with IRQ 32
[    2.008020] pcieport 0000:00:02.1: PME: Signaling with IRQ 33
[    2.016802] ERST DBG: ERST support is disabled.
[    2.223266] Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled
[    2.225729] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
[    2.603963] Freeing initrd memory: 8776K
[    2.606519] VMware PVSCSI driver - version 1.0.7.0-k
[    2.606540] ahci 0000:00:1f.2: version 3.0
[    2.606873] ACPI: \_SB_.GSIA: Enabled at IRQ 16
[    2.632355] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode
[    2.632358] ahci 0000:00:1f.2: flags: 64bit ncq only 
[    2.657535] scsi host0: ahci
[    2.657652] scsi host1: ahci
[    2.657737] scsi host2: ahci
[    2.657805] scsi host3: ahci
[    2.657869] scsi host4: ahci
[    2.657954] scsi host5: ahci
[    2.658184] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 36
[    2.658482] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 36
[    2.658661] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 36
[    2.659040] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 36
[    2.659220] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 36
[    2.659516] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 36
[    2.659572] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12
[    2.679738] serio: i8042 KBD port at 0x60,0x64 irq 1
[    2.679742] serio: i8042 AUX port at 0x60,0x64 irq 12
[    2.679757] rtc_cmos 00:03: RTC can wake from S4
[    2.701304] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input0
[    2.727625] rtc_cmos 00:03: registered as rtc0
[    2.730816] rtc_cmos 00:03: setting system clock to 2025-11-07T23:10:23 UTC (1762557023)
[    2.731713] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs
[    2.731723] intel_pstate: CPU model not supported
[    2.731800] gre: GRE over IPv4 demultiplexor driver
[    2.740746] NET: Registered PF_INET6 protocol family
[    2.740881] Segment Routing with IPv6
[    2.740885] In-situ OAM (IOAM) with IPv6
[    2.740916] Key type dns_resolver registered
[    2.740941] IPI shorthand broadcast: enabled
[    2.741656] sched_clock: Marking stable (2600003100, 133202100)-&gt;(3051690400, -318485200)
[    2.747042] registered taskstats version 1
[    2.747094] Loading compiled-in X.509 certificates
[    2.749194] Loaded X.509 cert 'alpinelinux.org: Alpine Linux kernel key: d76a695f66ad9cd28f5c22a8508f36e91f521f7a'
[    2.750518] Key type .fscrypt registered
[    2.750520] Key type fscrypt-provisioning registered
[    3.040250] ata1: SATA link down (SStatus 0 SControl 300)
[    3.051877] ata2: SATA link down (SStatus 0 SControl 300)
[    3.057725] ata3: SATA link down (SStatus 0 SControl 300)
[    3.064160] ata4: SATA link down (SStatus 0 SControl 300)
[    3.070012] ata5: SATA link down (SStatus 0 SControl 300)
[    3.075425] ata6: SATA link down (SStatus 0 SControl 300)
[    3.077547] Freeing unused kernel image (initmem) memory: 2696K
[    3.077550] Write protecting the kernel read-only data: 24576k
[    3.078154] Freeing unused kernel image (rodata/data gap) memory: 2008K
[    3.078159] rodata_test: all tests were successful
[    3.078163] Run /init as init process
[    3.078163]   with arguments:
[    3.078164]     /init
[    3.078165]   with environment:
[    3.078165]     HOME=/
[    3.078166]     TERM=linux
[    3.078166]     BOOT_IMAGE=/boot/vmlinuz-virt
[    3.078166]     modules=loop,squashfs,sd-mod,usb-storage
[    3.081820] Alpine Init 3.10.1-r0
[    3.082102] Loading boot drivers...
[    3.084795] loop: module loaded
[    3.086145] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    3.096134] ACPI: bus type USB registered
[    3.096151] usbcore: registered new interface driver usbfs
[    3.096155] usbcore: registered new interface driver hub
[    3.096159] usbcore: registered new device driver usb
[    3.097555] usbcore: registered new interface driver usb-storage
[    3.112030] ACPI: bus type drm_connector registered
[    3.118702] Loading boot drivers: ok.
[    3.119289] Mounting boot media...
[    3.174809] scsi host6: Virtio SCSI HBA
[    3.226310] Free page reporting enabled
[    3.271131] virtio_blk virtio3: 1/0/0 default/read/poll queues
[    3.290621] virtio_blk virtio3: [vda] 124928 512-byte logical blocks (64.0 MB/61.0 MiB)
[    3.291914]  vda: vda1 vda2
[    3.369387] ISO 9660 Extensions: Microsoft Joliet Level 3
[    3.369866] ISO 9660 Extensions: RRIP_1991A
[    3.646390] Mounting boot media: ok.
[    3.663188] Installing packages to root filesystem...
[    3.884643] Installing packages to root filesystem: ok.
[    4.119278] loop0: detected capacity change from 0 to 39312
[    4.321131] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input3
[    4.353225] ACPI: button: Power Button [PWRF]
[    4.398449] cryptd: max_cpu_qlen set to 1000
[    4.457797] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input4
[    4.474034] mousedev: PS/2 mouse device common for all mice
[    4.586174] NET: Registered PF_PACKET protocol family
localhost:~# &#65533;[6n
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: echo $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "lspci\n"
&#65533;[32mMatch for RE:&#65533;[39m "lspci((?s).*)((?s).*)(\\$ |\\# )" found: ["lspci\r\n-sh: lspci: not found\r\nlocalhost:~# " "\r\n-sh: lspci: not found\r\nlocalhost:~" "" "# "] Buffer: lspci
-sh: lspci: not found
localhost:~# &#65533;
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[34mSent:&#65533;[39m "arp\n"
&#65533;[32mMatch for RE:&#65533;[39m "arp((?s).*)((?s).*)(\\$ |\\# )" found: ["arp\r\nlocalhost:~# " "\r\nlocalhost:~" "" "# "] Buffer: arp
localhost:~# 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\nlocalhost:~# " "\r" "localhost:~" "# "] Buffer: &#65533;[6necho $?
0
localhost:~# 
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "(localhost|testvmi-jmwzm):~\\# " found: ["localhost:~# " "localhost"] Buffer: 
localhost:~# 
Forwarding from 127.0.0.1:7625 -&gt; 8443
Forwarding from [::1]:7625 -&gt; 8443
Handling connection for 7625
Forwarding from 127.0.0.1:9146 -&gt; 8443
Forwarding from [::1]:9146 -&gt; 8443
Handling connection for 9146
Forwarding from 127.0.0.1:7323 -&gt; 8443
Forwarding from [::1]:7323 -&gt; 8443
Handling connection for 7323
Forwarding from 127.0.0.1:6836 -&gt; 8443
Forwarding from [::1]:6836 -&gt; 8443
Handling connection for 6836
Global test cleanup started.
Forwarding from 127.0.0.1:4981 -&gt; 8443
Forwarding from [::1]:4981 -&gt; 8443
Handling connection for 4981
Forwarding from 127.0.0.1:7269 -&gt; 8443
Forwarding from [::1]:7269 -&gt; 8443
Handling connection for 7269
Forwarding from 127.0.0.1:7635 -&gt; 8443
Forwarding from [::1]:7635 -&gt; 8443
Handling connection for 7635
Forwarding from 127.0.0.1:9993 -&gt; 8443
Forwarding from [::1]:9993 -&gt; 8443
Handling connection for 9993
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with default cpu model should add node selector to virt-launcher when setting default cpuModel in kubevirtCR" classname="KubeVirt Tests Suite" time="89.11020005" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with default cpu model should prefer node selector of the vmi if cpuModel field is set in kubevirtCR and in the vmi" classname="KubeVirt Tests Suite" time="88.082461724" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node feature discovery [test_id:1639]the vmi with cpu.model matching a nfd label on a node should be scheduled" classname="KubeVirt Tests Suite" time="87.674604639" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node feature discovery [test_id:1640]the vmi with cpu.model that cannot match an nfd label on node should not be scheduled" classname="KubeVirt Tests Suite" time="155.320777956">
          <failure type="Failure">tests/vmi_lifecycle_test.go:1028
Timed out after 60.000s.
VMI should be unchedulable
Expected
    &lt;string&gt;: 
to equal
    &lt;string&gt;: Unschedulable
tests/vmi_lifecycle_test.go:1051</failure>
          <system-out>Forwarding from 127.0.0.1:5495 -&gt; 8443
Forwarding from [::1]:5495 -&gt; 8443
Handling connection for 5495
Forwarding from 127.0.0.1:4732 -&gt; 8443
Forwarding from [::1]:4732 -&gt; 8443
Handling connection for 4732
Forwarding from 127.0.0.1:7445 -&gt; 8443
Forwarding from [::1]:7445 -&gt; 8443
Handling connection for 7445
Forwarding from 127.0.0.1:9935 -&gt; 8443
Forwarding from [::1]:9935 -&gt; 8443
Handling connection for 9935
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/4_*
Skipping volume snapshot log collection
Global test cleanup started.
Forwarding from 127.0.0.1:7192 -&gt; 8443
Forwarding from [::1]:7192 -&gt; 8443
Handling connection for 7192
Forwarding from 127.0.0.1:7730 -&gt; 8443
Forwarding from [::1]:7730 -&gt; 8443
Handling connection for 7730
Forwarding from 127.0.0.1:7544 -&gt; 8443
Forwarding from [::1]:7544 -&gt; 8443
Handling connection for 7544
Forwarding from 127.0.0.1:9662 -&gt; 8443
Forwarding from [::1]:9662 -&gt; 8443
Handling connection for 9662
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node feature discovery [test_id:3202]the vmi with cpu.features matching nfd labels on a node should be scheduled" classname="KubeVirt Tests Suite" time="88.686986361" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node feature discovery [test_id:3203]the vmi with cpu.features that cannot match nfd labels on a node should not be scheduled" classname="KubeVirt Tests Suite" time="78.170137077" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with node feature discovery [test_id:3204]the vmi with cpu.feature policy 'forbid' should not be scheduled on a node with that cpu feature label" classname="KubeVirt Tests Suite" time="82.235658649" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with non default namespace [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]should log libvirt start and stop lifecycle events of the domain [test_id:1641]Default test namespace" classname="KubeVirt Tests Suite" time="16.31510152" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance with non default namespace [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]should log libvirt start and stop lifecycle events of the domain [test_id:1642]Alternative test namespace" classname="KubeVirt Tests Suite" time="16.305461204" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance VM Accelerated Mode [test_id:1648]Should provide hypervisor via plugin framework" classname="KubeVirt Tests Suite" time="7.45317453" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Freeze/Unfreeze a VirtualMachineInstance [test_id:7476][test_id:7477]should fail without guest agent" classname="KubeVirt Tests Suite" time="16.129717738" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Freeze/Unfreeze a VirtualMachineInstance [test_id:7479] should succeed" classname="KubeVirt Tests Suite" time="74.829534472" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Freeze/Unfreeze a VirtualMachineInstance [test_id:7480] should succeed multiple times" classname="KubeVirt Tests Suite" time="52.743543829000004" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Freeze/Unfreeze a VirtualMachineInstance Freeze without Unfreeze should trigger unfreeze after timeout" classname="KubeVirt Tests Suite" time="57.058017058" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Softreboot a VirtualMachineInstance soft reboot vmi with agent connected should succeed" classname="KubeVirt Tests Suite" time="90.320771767">
          <failure type="Failure">tests/vmi_lifecycle_test.go:1393
Expected success, but got an error:
    &lt;*errors.errorString | 0xc007032000&gt;: 
    send to spawned process command reached the timeout 19.880717497s
    {
        s: "send to spawned process command reached the timeout 19.880717497s",
    }
tests/vmi_lifecycle_test.go:1772</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/5_*
Skipping volume snapshot log collection
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Softreboot a VirtualMachineInstance soft reboot vmi with ACPI feature enabled should succeed" classname="KubeVirt Tests Suite" time="29.582998322999998" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Softreboot a VirtualMachineInstance soft reboot vmi neither have the agent connected nor the ACPI feature enabled should fail" classname="KubeVirt Tests Suite" time="27.603825965" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Softreboot a VirtualMachineInstance soft reboot vmi should fail to soft reboot a paused vmi" classname="KubeVirt Tests Suite" time="93.560846332">
          <failure type="Failure">tests/vmi_lifecycle_test.go:1446
Expected success, but got an error:
    &lt;*errors.errorString | 0xc001d79760&gt;: 
    send to spawned process command reached the timeout 19.883765154s
    {
        s: "send to spawned process command reached the timeout 19.883765154s",
    }
tests/vmi_lifecycle_test.go:1772</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/6_*
Skipping volume snapshot log collection
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Pausing/Unpausing a VirtualMachineInstance [test_id:4597]should signal paused state with condition" classname="KubeVirt Tests Suite" time="31.371877792" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Pausing/Unpausing a VirtualMachineInstance [test_id:3083][test_id:3084]should be able to connect to serial console and VNC" classname="KubeVirt Tests Suite" time="120.476327773">
          <failure type="Failure">tests/vmi_lifecycle_test.go:1491
Unexpected error:
    &lt;*errors.StatusError | 0xc007f55b80&gt;: 
    Internal error occurred: Put "https://10.42.0.9:8186/v1/namespaces/kubevirt-test-default1/virtualmachineinstances/testvmi-2grkr/pause": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
    {
        ErrStatus: {
            TypeMeta: {Kind: "", APIVersion: ""},
            ListMeta: {
                SelfLink: "",
                ResourceVersion: "",
                Continue: "",
                RemainingItemCount: nil,
            },
            Status: "Failure",
            Message: "Internal error occurred: Put \"https://10.42.0.9:8186/v1/namespaces/kubevirt-test-default1/virtualmachineinstances/testvmi-2grkr/pause\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)",
            Reason: "InternalError",
            Details: {
                Name: "",
                Group: "",
                Kind: "",
                UID: "",
                Causes: [
                    {
                        Type: "",
                        Message: "Put \"https://10.42.0.9:8186/v1/namespaces/kubevirt-test-default1/virtualmachineinstances/testvmi-2grkr/pause\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)",
                        Field: "",
                    },
                ],
                RetryAfterSeconds: 0,
            },
            Code: 500,
        },
    }
occurred
tests/vmi_lifecycle_test.go:1496</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/7_*
Skipping volume snapshot log collection
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle Pausing/Unpausing a VirtualMachineInstance [test_id:3090]should result in a difference in the uptime after pause" classname="KubeVirt Tests Suite" time="69.136780797">
          <failure type="Failure">tests/vmi_lifecycle_test.go:1509
guest should be paused for at least 6 seconds
Expected
    &lt;float64&gt;: 0.026402238999999383
to be &gt;=
    &lt;int&gt;: 6
tests/vmi_lifecycle_test.go:1559</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "login as 'cirros' user. default password: 'gocubsgo'. use 'sudo' for root." found: ["login as 'cirros' user. default password: 'gocubsgo'. use 'sudo' for root."] Buffer: 01] add_size 1000
[    3.299199] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000
[    3.310529] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000
[    3.319817] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000
[    3.329332] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000
[    3.338947] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000
[    3.348656] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000
[    3.358086] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000
[    3.367529] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000
[    3.377195] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000
[    3.386434] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]
[    3.393467] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]
[    3.400839] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]
[    3.407848] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]
[    3.414812] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]
[    3.422389] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]
[    3.429309] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]
[    3.436428] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]
[    3.443479] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]
[    3.460804] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]
[    3.468378] pci 0000:00:01.0: PCI bridge to [bus 01]
[    3.474319] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]
[    3.483078] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    3.493353] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    3.503326] pci 0000:00:01.1: PCI bridge to [bus 02]
[    3.509930] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]
[    3.518615] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    3.528686] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    3.539461] pci 0000:00:01.2: PCI bridge to [bus 03]
[    3.547144] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]
[    3.558878] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    3.568182] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    3.579741] pci 0000:00:01.3: PCI bridge to [bus 04]
[    3.585666] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]
[    3.594155] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    3.602830] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    3.613430] pci 0000:00:01.4: PCI bridge to [bus 05]
[    3.619769] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]
[    3.628125] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    3.636681] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    3.646996] pci 0000:00:01.5: PCI bridge to [bus 06]
[    3.653274] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]
[    3.661233] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    3.670173] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    3.680220] pci 0000:00:01.6: PCI bridge to [bus 07]
[    3.686488] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]
[    3.694663] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    3.703240] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    3.713267] pci 0000:00:01.7: PCI bridge to [bus 08]
[    3.719215] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]
[    3.727401] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    3.736152] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    3.746803] pci 0000:00:02.0: PCI bridge to [bus 09]
[    3.753114] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]
[    3.760882] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    3.769529] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    3.781525] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    3.787782] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]
[    3.795692] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    3.804438] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    3.814817] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]
[    3.821920] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]
[    3.829417] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]
[    3.837336] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]
[    3.845299] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]
[    3.853042] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]
[    3.861053] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]
[    3.867426] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]
[    3.874881] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]
[    3.882877] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]
[    3.890160] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]
[    3.897861] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]
[    3.906097] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]
[    3.912607] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]
[    3.919997] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]
[    3.928305] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]
[    3.934978] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]
[    3.942377] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]
[    3.950379] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]
[    3.957050] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]
[    3.964279] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]
[    3.972602] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]
[    3.979143] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]
[    3.986664] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]
[    3.994727] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]
[    4.001328] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]
[    4.008564] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]
[    4.017124] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]
[    4.023517] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]
[    4.030528] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]
[    4.042384] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]
[    4.048884] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]
[    4.056027] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]
[    4.064155] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]
[    4.070574] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]
[    4.077802] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]
[    4.086329] NET: Registered protocol family 2
[    4.091775] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)
[    4.101112] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)
[    4.109449] TCP bind hash table entries: 1024 (order: 2, 16384 bytes, linear)
[    4.117450] TCP: Hash tables configured (established 1024 bind 1024)
[    4.124820] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)
[    4.132179] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)
[    4.139970] NET: Registered protocol family 1
[    4.145287] NET: Registered protocol family 44
[    4.152404] PCI: CLS 0 bytes, default 64
[    4.157442] Trying to unpack rootfs image as initramfs...
[    4.247510] Freeing initrd memory: 6396K
[    4.255920] check: Scanning for low memory corruption every 60 seconds
[    4.264234] Initialise system trusted keyrings
[    4.269882] Key type blacklist registered
[    4.274886] workingset: timestamp_bits=36 max_order=15 bucket_order=0
[    4.282990] zbud: loaded
[    4.286782] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    4.293788] fuse: init (API version 7.31)
[    4.298856] Platform Keyring initialized
[    4.307164] Key type asymmetric registered
[    4.312160] Asymmetric key parser 'x509' registered
[    4.317992] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 244)
[    4.326243] io scheduler mq-deadline registered
[    4.332012] PCI Interrupt Link [GSIF] enabled at IRQ 21
[    4.343931] pcieport 0000:00:01.0: PME: Signaling with IRQ 24
[    4.352995] pcieport 0000:00:01.0: AER: enabled with IRQ 24
[    4.368964] pcieport 0000:00:01.1: PME: Signaling with IRQ 25
[    4.377813] pcieport 0000:00:01.1: AER: enabled with IRQ 25
[    4.394346] pcieport 0000:00:01.2: PME: Signaling with IRQ 26
[    4.402636] pcieport 0000:00:01.2: AER: enabled with IRQ 26
[    4.419432] pcieport 0000:00:01.3: PME: Signaling with IRQ 27
[    4.428544] pcieport 0000:00:01.3: AER: enabled with IRQ 27
[    4.451508] pcieport 0000:00:01.4: PME: Signaling with IRQ 28
[    4.465609] pcieport 0000:00:01.4: AER: enabled with IRQ 28
[    4.481355] pcieport 0000:00:01.5: PME: Signaling with IRQ 29
[    4.490292] pcieport 0000:00:01.5: AER: enabled with IRQ 29
[    4.506496] pcieport 0000:00:01.6: PME: Signaling with IRQ 30
[    4.515198] pcieport 0000:00:01.6: AER: enabled with IRQ 30
[    4.531949] pcieport 0000:00:01.7: PME: Signaling with IRQ 31
[    4.541370] pcieport 0000:00:01.7: AER: enabled with IRQ 31
[    4.551728] PCI Interrupt Link [GSIG] enabled at IRQ 22
[    4.564212] pcieport 0000:00:02.0: PME: Signaling with IRQ 32
[    4.574483] pcieport 0000:00:02.0: AER: enabled with IRQ 32
[    4.590979] pcieport 0000:00:02.1: PME: Signaling with IRQ 33
[    4.599834] pcieport 0000:00:02.1: AER: enabled with IRQ 33
[    4.610300] shpchp: Standard Hot Plug PCI Controller Driver version: 0.4
[    4.617873] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0
[    4.626289] ACPI: Power Button [PWRF]
[    4.775399] Serial: 8250/16550 driver, 32 ports, IRQ sharing enabled
[    4.828058] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
[    5.113742] Linux agpgart interface v0.103
[    5.123381] loop: module loaded
[    5.127809] libphy: Fixed MDIO Bus: probed
[    5.132796] tun: Universal TUN/TAP device driver, 1.6
[    5.138740] PPP generic driver version 2.4.2
[    5.143983] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver
[    5.151330] ehci-pci: EHCI PCI platform driver
[    5.156600] ehci-platform: EHCI generic platform driver
[    5.162725] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver
[    5.169801] ohci-pci: OHCI PCI platform driver
[    5.175248] ohci-platform: OHCI generic platform driver
[    5.181288] uhci_hcd: USB Universal Host Controller Interface driver
[    5.188672] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12
[    5.208670] serio: i8042 KBD port at 0x60,0x64 irq 1
[    5.214564] serio: i8042 AUX port at 0x60,0x64 irq 12
[    5.220593] mousedev: PS/2 mouse device common for all mice
[    5.228628] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1
[    5.238336] rtc_cmos 00:03: RTC can wake from S4
[    5.250466] rtc_cmos 00:03: registered as rtc0
[    5.255937] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs
[    5.265136] i2c /dev entries driver
[    5.269612] device-mapper: uevent: version 1.0.3
[    5.275186] device-mapper: ioctl: 4.40.0-ioctl (2019-01-18) initialised: dm-devel@redhat.com
[    5.284969] platform eisa.0: Probing EISA bus 0
[    5.290503] platform eisa.0: EISA: Cannot allocate resource for mainboard
[    5.298184] platform eisa.0: Cannot allocate resource for EISA slot 1
[    5.305623] platform eisa.0: Cannot allocate resource for EISA slot 2
[    5.312919] platform eisa.0: Cannot allocate resource for EISA slot 3
[    5.320451] platform eisa.0: Cannot allocate resource for EISA slot 4
[    5.327747] platform eisa.0: Cannot allocate resource for EISA slot 5
[    5.335077] platform eisa.0: Cannot allocate resource for EISA slot 6
[    5.342315] platform eisa.0: Cannot allocate resource for EISA slot 7
[    5.349603] platform eisa.0: Cannot allocate resource for EISA slot 8
[    5.356792] platform eisa.0: EISA: Detected 0 cards
[    5.362544] intel_pstate: CPU model not supported
[    5.368285] ledtrig-cpu: registered to indicate activity on CPUs
[    5.375270] NET: Registered protocol family 10
[    5.383613] Segment Routing with IPv6
[    5.388214] NET: Registered protocol family 17
[    5.393707] Key type dns_resolver registered
[    5.399296] RAS: Correctable Errors collector initialized.
[    5.405646] registered taskstats version 1
[    5.411102] Loading compiled-in X.509 certificates
[    5.417754] Loaded X.509 cert 'Build time autogenerated kernel key: 8098f9b3401d48cb244b138af0c5bac131caef8a'
[    5.428832] zswap: loaded using pool lzo/zbud
[    5.436792] Key type big_key registered
[    5.443458] Key type encrypted registered
[    5.448344] AppArmor: AppArmor sha1 policy hashing enabled
[    5.454690] ima: No TPM chip found, activating TPM-bypass!
[    5.465021] ima: Allocated hash algorithm: sha1
[    5.471181] No architecture policies found
[    5.476343] evm: Initialising EVM extended attributes:
[    5.482416] evm: security.selinux
[    5.486636] evm: security.SMACK64
[    5.490967] evm: security.SMACK64EXEC
[    5.495585] evm: security.SMACK64TRANSMUTE
[    5.500609] evm: security.SMACK64MMAP
[    5.506682] evm: security.apparmor
[    5.511176] evm: security.ima
[    5.515108] evm: security.capability
[    5.519628] evm: HMAC attrs: 0x1
[    5.525304] PM:   Magic number: 1:476:554
[    5.530243] acpi PNP0C0F:05: hash matches
[    5.535231] acpi PNP0C01:00: hash matches
[    5.541115] rtc_cmos 00:03: setting system clock to 2025-11-07T23:32:54 UTC (1762558374)
[    5.550123] Unstable clock detected, switching default tracing clock to "global"
[    5.550123] If you want to keep using the local clock, then add:
[    5.550123]   "trace_clock=local"
[    5.550123] on the kernel command line
[    5.581609] Freeing unused decrypted memory: 2040K
[    5.588031] Freeing unused kernel image memory: 2660K
[    5.594122] Write protecting the kernel read-only data: 22528k
[    5.602238] Freeing unused kernel image memory: 2008K
[    5.608412] Freeing unused kernel image memory: 1476K
[    5.619736] x86/mm: Checked W+X mappings: passed, no W+X pages found.
[    5.627091] Run /init as init process

info: initramfs: up at 4.65
[    5.767539] virtio_blk virtio3: [vda] 229376 512-byte logical blocks (117 MB/112 MiB)
[    5.800889] virtio_blk virtio4: [vdb] 2048 512-byte logical blocks (1.05 MB/1.00 MiB)
currently loaded modules: 8139cp 8390 9pnet 9pnet_virtio ahci drm drm_kms_helper e1000 failover fb_sys_fops hid hid_generic ip_tables isofs libahci mii ne2k_pci net_failover nls_ascii nls_iso8859_1 nls_utf8 pcnet32 qemu_fw_cfg syscopyarea sysfillrect sysimgblt ttm usbhid virtio_blk virtio_gpu virtio_input virtio_net virtio_rng virtio_scsi x_tables 
info: copying initramfs to /dev/vda1
info: initramfs loading root from /dev/vda1
info: /etc/init.d/rc.sysinit: up at 5.51
info: container: none
currently loaded modules: 8139cp 8390 9pnet 9pnet_virtio ahci drm drm_kms_helper e1000 failover fb_sys_fops hid hid_generic ip_tables isofs libahci mii ne2k_pci net_failover nls_ascii nls_iso8859_1 nls_utf8 pcnet32 qemu_fw_cfg syscopyarea sysfillrect sysimgblt ttm usbhid virtio_blk virtio_gpu virtio_input virtio_net virtio_rng virtio_scsi x_tables 
Initializing random number generator... done.
Starting acpid: OK
mcb [info=/dev/vdb dev=/dev/vdb target=tmp unmount=true callback=mcu_drop_dev_arg]: mount '/dev/vdb' '-o,ro' '/tmp/nocloud.mp.gLV0DW'
mcudda: fn=cp dev=/dev/vdb mp=/tmp/nocloud.mp.gLV0DW : -a /tmp/cirros-ds.kJaN0f/nocloud/raw
Starting network: udhcpc: started, v1.29.3
udhcpc: sending discover
udhcpc: sending select for 10.42.0.38
udhcpc: lease of 10.42.0.38 obtained, lease time 86313600
route: SIOCADDRT: File exists
WARN: failed: route add -net "0.0.0.0/0" gw "10.42.0.1"
OK
Top of dropbear init script
Starting dropbear sshd: OK
GROWROOT: NOCHANGE: partition 1 is size 210911. it cannot be grown
/dev/root resized successfully [took 0.03s]
/sbin/cirros-userdata: line 69: /run/cirros/datasource/data/user-data: not found
WARN: /etc/rc3.d/S95-cirros-userdata failed
=== system information ===
Platform: KubeVirt None
Container: none
Arch: x86_64
CPU(s): 1 @ 2299.999 MHz
Cores/Sockets/Threads: 1/1/1
Virt-type: 
RAM Size: 100MB
Disks:
NAME  MAJ:MIN      SIZE LABEL         MOUNTPOINT
vda   252:0   117440512               
vda1  252:1   107986432 cirros-rootfs /
vda15 252:15    8388608               
vdb   252:16    1048576 cidata        
=== sshd host keys ===
-----BEGIN SSH HOST KEY KEYS-----
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDKV6mSKkqp7F+Es5qa35tJVKfUt+TrRWGL7pfHc2SP7JB5FlB7T+8HLmXuioiWryqd29DgXZ9n04N4sxt60fb+eVCMpyPpXj6icVvBnKhLRrk9DNzc3gKmhz1de9tdBunAfH9t9eKMpieeRosnHF6UO2Sxs/WzuLg88eJQdDAlpCsntqQUFDwagivqH8e6Qgy/72iLOwpYvq2rCspN+YWGA6JJk29reHiDVQGIxfQ87li17Y06Bsi+RVuCQ84bisghNlze54asD3HBIcnb9sT8Z8eFBFwhVg1irmEZeCXseXjppK/m1edegPFL084nxtkKa4h4dgzMo9Chkm3jB+7j root@testvmi-ffv97
ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBE/f2pWUsOYpBd9zs2W16utUVkTa+ueuu/PMEfmiShXCij4/uFusWn6F4d+tEogDGs32E7g9k0IC98sIJOkwcR8= root@testvmi-ffv97
-----END SSH HOST KEY KEYS-----
=== network info ===
if-info: lo,up,127.0.0.1,8,,
if-info: eth0,up,10.42.0.38,24,fe80::b8d7:f0ff:fe40:571e/64,
ip-route:default via 10.42.0.1 dev eth0 
ip-route:10.42.0.0/24 dev eth0 scope link  src 10.42.0.38 
ip-route:10.42.0.0/16 via 10.42.0.1 dev eth0 
ip-route6:fe80::/64 dev eth0  metric 256 
ip-route6:ff00::/8 dev eth0  metric 256 
=== datasource: nocloud local ===
instance-id: 3f6a8aae-b123-4e6f-ac3f-636f0e590779
name: N/A
availability-zone: N/A
local-hostname: testvmi-ffv97
launch-index: N/A
=== cirros: current=0.5.2 latest=0.6.3 uptime=6.14 ===
  ____               ____  ____
 / __/ __ ____ ____ / __ \/ __/
/ /__ / // __// __// /_/ /\ \ 
\___//_//_/  /_/   \____/___/ 
   http://cirros-cloud.net


login as 'cirros' user. default password: 'gocubsgo'. use 'sudo' for root.
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "testvmi-ffv97 login:" found: ["testvmi-ffv97 login:"] Buffer: 
testvmi-ffv97 login:
&#65533;[34mSent:&#65533;[39m "cirros\n"
&#65533;[32mMatch for RE:&#65533;[39m "Password:" found: ["Password:"] Buffer:  
login as 'cirros' user. default password: 'gocubsgo'. use 'sudo' for root.
testvmi-ffv97 login: cirros
Password:
&#65533;[34mSent:&#65533;[39m "gocubsgo\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["$ " "$ "] Buffer:  
$ 
&#65533;[34mSent:&#65533;[39m "stty cols 500 rows 500\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["$ " "$ "] Buffer: stty cols 500 rows 500
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "\n0\r\n.*(\\$ |\\# )" found: ["\n0\r\n$ " "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "sudo dmesg -n 1\n"
&#65533;[32mMatch for RE:&#65533;[39m "(\\$ |\\# )" found: ["$ " "$ "] Buffer: sudo dmesg -n 1
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "\n0\r\n.*(\\$ |\\# )" found: ["\n0\r\n$ " "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "cat /proc/uptime | awk '{print $1;}'\n"
&#65533;[32mMatch for RE:&#65533;[39m "cat /proc/uptime \\| awk '\\{print \\$1;\\}'((?s).*)\n[0-9\\.]+\r\n((?s).*)(\\$ |\\# )" found: ["cat /proc/uptime | awk '{print $1;}'\r\n6.78\r\n$ " "\r" "" "$ "] Buffer: cat /proc/uptime | awk '{print $1;}'
6.78
$ 
&#65533;[34mSent:&#65533;[39m "cat /proc/uptime | awk '{print $1;}'\n"
&#65533;[32mMatch for RE:&#65533;[39m "cat /proc/uptime \\| awk '\\{print \\$1;\\}'((?s).*)\n[0-9\\.]+\r\n((?s).*)(\\$ |\\# )" found: ["cat /proc/uptime | awk '{print $1;}'\r\n20.66\r\n$ " "\r" "" "$ "] Buffer: cat /proc/uptime | awk '{print $1;}'
20.66
$ 
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/8_*
Skipping volume snapshot log collection
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "\\$" found: ["$"] Buffer: 
$
&#65533;[34mSent:&#65533;[39m "ip address\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip address((?s).*)((?s).*)(\\$ |\\# )" found: ["ip address\r\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n    inet 127.0.0.1/8 scope host lo\r\n       valid_lft forever preferred_lft forever\r\n    inet6 ::1/128 scope host \r\n       valid_lft forever preferred_lft forever\r\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast qlen 1000\r\n    link/ether ba:d7:f0:40:57:1e brd ff:ff:ff:ff:ff:ff\r\n    inet 10.42.0.38/24 brd 10.42.0.255 scope global eth0\r\n       valid_lft forever preferred_lft forever\r\n    inet6 fe80::b8d7:f0ff:fe40:571e/64 scope link \r\n       valid_lft forever preferred_lft forever\r\n$ " "\r\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n    inet 127.0.0.1/8 scope host lo\r\n       valid_lft forever preferred_lft forever\r\n    inet6 ::1/128 scope host \r\n       valid_lft forever preferred_lft forever\r\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast qlen 1000\r\n    link/ether ba:d7:f0:40:57:1e brd ff:ff:ff:ff:ff:ff\r\n    inet 10.42.0.38/24 brd 10.42.0.255 scope global eth0\r\n       valid_lft forever preferred_lft forever\r\n    inet6 fe80::b8d7:f0ff:fe40:571e/64 scope link \r\n       valid_lft forever preferred_lft forever\r\n" "" "$ "] Buffer: ip address
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast qlen 1000
    link/ether ba:d7:f0:40:57:1e brd ff:ff:ff:ff:ff:ff
    inet 10.42.0.38/24 brd 10.42.0.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::b8d7:f0ff:fe40:571e/64 scope link 
       valid_lft forever preferred_lft forever
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\n$ " "\r" "" "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "ip link\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip link((?s).*)((?s).*)(\\$ |\\# )" found: ["ip link\r\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast qlen 1000\r\n    link/ether ba:d7:f0:40:57:1e brd ff:ff:ff:ff:ff:ff\r\n$ " "\r\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast qlen 1000\r\n    link/ether ba:d7:f0:40:57:1e brd ff:ff:ff:ff:ff:ff\r\n" "" "$ "] Buffer: ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast qlen 1000
    link/ether ba:d7:f0:40:57:1e brd ff:ff:ff:ff:ff:ff
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\n$ " "\r" "" "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "ip route show table all\n"
&#65533;[32mMatch for RE:&#65533;[39m "ip route show table all((?s).*)((?s).*)(\\$ |\\# )" found: ["ip route show table all\r\ndefault via 10.42.0.1 dev eth0 \r\n10.42.0.0/24 dev eth0 scope link  src 10.42.0.38 \r\n10.42.0.0/16 via 10.42.0.1 dev eth0 \r\nbroadcast 10.42.0.0 dev eth0 table local scope link  src 10.42.0.38 \r\nlocal 10.42.0.38 dev eth0 table local scope host  src 10.42.0.38 \r\nbroadcast 10.42.0.255 dev eth0 table local scope link  src 10.42.0.38 \r\nbroadcast 127.0.0.0 dev lo table local scope link  src 127.0.0.1 \r\nlocal 127.0.0.0/8 dev lo table local scope host  src 127.0.0.1 \r\nlocal 127.0.0.1 dev lo table local scope host  src 127.0.0.1 \r\nbroadcast 127.255.255.255 dev lo table local scope link  src 127.0.0.1 \r\nfe80::/64 dev eth0  metric 256 \r\nlocal ::1 dev lo table local  metric 0 \r\nlocal fe80::b8d7:f0ff:fe40:571e dev eth0 table local  metric 0 \r\nff00::/8 dev eth0 table local  metric 256 \r\n$ " "\r\ndefault via 10.42.0.1 dev eth0 \r\n10.42.0.0/24 dev eth0 scope link  src 10.42.0.38 \r\n10.42.0.0/16 via 10.42.0.1 dev eth0 \r\nbroadcast 10.42.0.0 dev eth0 table local scope link  src 10.42.0.38 \r\nlocal 10.42.0.38 dev eth0 table local scope host  src 10.42.0.38 \r\nbroadcast 10.42.0.255 dev eth0 table local scope link  src 10.42.0.38 \r\nbroadcast 127.0.0.0 dev lo table local scope link  src 127.0.0.1 \r\nlocal 127.0.0.0/8 dev lo table local scope host  src 127.0.0.1 \r\nlocal 127.0.0.1 dev lo table local scope host  src 127.0.0.1 \r\nbroadcast 127.255.255.255 dev lo table local scope link  src 127.0.0.1 \r\nfe80::/64 dev eth0  metric 256 \r\nlocal ::1 dev lo table local  metric 0 \r\nlocal fe80::b8d7:f0ff:fe40:571e dev eth0 table local  metric 0 \r\nff00::/8 dev eth0 table local  metric 256 \r\n" "" "$ "] Buffer: ip route show table all
default via 10.42.0.1 dev eth0 
10.42.0.0/24 dev eth0 scope link  src 10.42.0.38 
10.42.0.0/16 via 10.42.0.1 dev eth0 
broadcast 10.42.0.0 dev eth0 table local scope link  src 10.42.0.38 
local 10.42.0.38 dev eth0 table local scope host  src 10.42.0.38 
broadcast 10.42.0.255 dev eth0 table local scope link  src 10.42.0.38 
broadcast 127.0.0.0 dev lo table local scope link  src 127.0.0.1 
local 127.0.0.0/8 dev lo table local scope host  src 127.0.0.1 
local 127.0.0.1 dev lo table local scope host  src 127.0.0.1 
broadcast 127.255.255.255 dev lo table local scope link  src 127.0.0.1 
fe80::/64 dev eth0  metric 256 
local ::1 dev lo table local  metric 0 
local fe80::b8d7:f0ff:fe40:571e dev eth0 table local  metric 0 
ff00::/8 dev eth0 table local  metric 256 
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\n$ " "\r" "" "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "dmesg\n"
&#65533;[32mMatch for RE:&#65533;[39m "dmesg((?s).*)((?s).*)(\\$ |\\# )" found: ["dmesg\r\n[    0.000000] Linux version 5.3.0-26-generic (buildd@lgw01-amd64-039) (gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1)) #28~18.04.1-Ubuntu SMP Wed Dec 18 16:40:14 UTC 2019 (Ubuntu 5.3.0-26.28~18.04.1-generic 5.3.13)\r\n[    0.000000] Command line: LABEL=cirros-rootfs ro console=tty1 console=ttyS0\r\n[    0.000000] KERNEL supported cpus:\r\n[    0.000000]   Intel GenuineIntel\r\n[    0.000000]   AMD AuthenticAMD\r\n[    0.000000]   Hygon HygonGenuine\r\n[    0.000000]   Centaur CentaurHauls\r\n[    0.000000]   zhaoxin   Shanghai  \r\n[    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'\r\n[    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'\r\n[    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'\r\n[    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256\r\n[    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format.\r\n[    0.000000] BIOS-provided physical RAM map:\r\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable\r\n[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable\r\n[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved\r\n[    0.000000] NX (Execute Disable) protection: active\r\n[    0.000000] SMBIOS 2.8 present.\r\n[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014\r\n[    0.000000] Hypervisor detected: Microsoft Hyper-V\r\n[    0.000000] Hyper-V: features 0xe7e, hints 0x60624\r\n[    0.000000] Hyper-V Host Build:26100-10.0-1-0.1381\r\n[    0.000000] Hyper-V: LAPIC Timer Frequency: 0xc3500\r\n[    0.000000] tsc: Marking TSC unstable due to running on Hyper-V\r\n[    0.000000] Hyper-V: Using hypercall for remote TLB flush\r\n[    0.000000] tsc: Detected 2299.999 MHz processor\r\n[    0.000713] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved\r\n[    0.000714] e820: remove [mem 0x000a0000-0x000fffff] usable\r\n[    0.000716] last_pfn = 0x7fdd max_arch_pfn = 0x400000000\r\n[    0.000741] MTRR default type: write-back\r\n[    0.000742] MTRR fixed ranges enabled:\r\n[    0.000742]   00000-9FFFF write-back\r\n[    0.000743]   A0000-BFFFF uncachable\r\n[    0.000744]   C0000-FFFFF write-protect\r\n[    0.000744] MTRR variable ranges enabled:\r\n[    0.000745]   0 base 0000C0000000 mask FFFFC0000000 uncachable\r\n[    0.000745]   1 disabled\r\n[    0.000746]   2 disabled\r\n[    0.000746]   3 disabled\r\n[    0.000746]   4 disabled\r\n[    0.000747]   5 disabled\r\n[    0.000747]   6 disabled\r\n[    0.000747]   7 disabled\r\n[    0.000754] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \r\n[    0.003905] found SMP MP-table at [mem 0x000f5470-0x000f547f]\r\n[    0.003961] check: Scanning 1 areas for low memory corruption\r\n[    0.004456] Using GB pages for direct mapping\r\n[    0.004461] BRK [0x05e01000, 0x05e01fff] PGTABLE\r\n[    0.004462] BRK [0x05e02000, 0x05e02fff] PGTABLE\r\n[    0.004463] BRK [0x05e03000, 0x05e03fff] PGTABLE\r\n[    0.004494] BRK [0x05e04000, 0x05e04fff] PGTABLE\r\n[    0.004592] BRK [0x05e05000, 0x05e05fff] PGTABLE\r\n[    0.004622] RAMDISK: [mem 0x0798e000-0x07fccfff]\r\n[    0.004775] ACPI: Early table checksum verification disabled\r\n[    0.004778] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )\r\n[    0.004781] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004785] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004788] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004790] ACPI: FACS 0x0000000007FE0000 000040\r\n[    0.004792] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004794] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004795] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004797] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004802] ACPI: Local APIC address 0xfee00000\r\n[    0.010519] No NUMA configuration found\r\n[    0.010521] Faking a node at [mem 0x0000000000000000-0x0000000007fdcfff]\r\n[    0.010528] NODE_DATA(0) allocated [mem 0x07963000-0x0798dfff]\r\n[    0.010681] Zone ranges:\r\n[    0.010682]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]\r\n[    0.010683]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]\r\n[    0.010683]   Normal   empty\r\n[    0.010684]   Device   empty\r\n[    0.010685] Movable zone start for each node\r\n[    0.010688] Early memory node ranges\r\n[    0.010689]   node   0: [mem 0x0000000000001000-0x000000000009efff]\r\n[    0.010689]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]\r\n[    0.011713] Zeroed struct page in unavailable ranges: 98 pages\r\n[    0.011715] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]\r\n[    0.011718] On node 0 totalpages: 32635\r\n[    0.011719]   DMA zone: 64 pages used for memmap\r\n[    0.011720]   DMA zone: 21 pages reserved\r\n[    0.011720]   DMA zone: 3998 pages, LIFO batch:0\r\n[    0.011753]   DMA32 zone: 448 pages used for memmap\r\n[    0.011754]   DMA32 zone: 28637 pages, LIFO batch:7\r\n[    0.030250] ACPI: PM-Timer IO Port: 0x608\r\n[    0.030254] ACPI: Local APIC address 0xfee00000\r\n[    0.030262] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\r\n[    0.032018] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23\r\n[    0.032020] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)\r\n[    0.032022] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\r\n[    0.032022] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\r\n[    0.032023] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\r\n[    0.032024] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\r\n[    0.032025] ACPI: IRQ0 used by override.\r\n[    0.032026] ACPI: IRQ5 used by override.\r\n[    0.032026] ACPI: IRQ9 used by override.\r\n[    0.032026] ACPI: IRQ10 used by override.\r\n[    0.032027] ACPI: IRQ11 used by override.\r\n[    0.032028] Using ACPI (MADT) for SMP configuration information\r\n[    0.032030] ACPI: HPET id: 0x8086a201 base: 0xfed00000\r\n[    0.032033] smpboot: Allowing 4 CPUs, 3 hotplug CPUs\r\n[    0.032041] PM: Registered nosave memory: [mem 0x00000000-0x00000fff]\r\n[    0.032042] PM: Registered nosave memory: [mem 0x0009f000-0x0009ffff]\r\n[    0.032042] PM: Registered nosave memory: [mem 0x000a0000-0x000effff]\r\n[    0.032043] PM: Registered nosave memory: [mem 0x000f0000-0x000fffff]\r\n[    0.032044] [mem 0x08000000-0xafffffff] available for PCI devices\r\n[    0.032045] Booting paravirtualized kernel on bare hardware\r\n[    0.032048] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645519600211568 ns\r\n[    0.032051] setup_percpu: NR_CPUS:8192 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1\r\n[    0.032771] percpu: Embedded 54 pages/cpu s184320 r8192 d28672 u524288\r\n[    0.032776] pcpu-alloc: s184320 r8192 d28672 u524288 alloc=1*2097152\r\n[    0.032776] pcpu-alloc: [0] 0 1 2 3 \r\n[    0.032788] Hyper-V: PV spinlocks enabled\r\n[    0.032790] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    0.032793] Built 1 zonelists, mobility grouping on.  Total pages: 32102\r\n[    0.032794] Policy zone: DMA32\r\n[    0.032795] Kernel command line: LABEL=cirros-rootfs ro console=tty1 console=ttyS0\r\n[    0.032826] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r\n[    0.032832] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r\n[    0.032875] mem auto-init: stack:off, heap alloc:on, heap free:off\r\n[    0.032878] Calgary: detecting Calgary via BIOS EBDA area\r\n[    0.032879] Calgary: Unable to locate Rio Grande table in EBDA - bailing!\r\n[    0.033093] Memory: 87908K/130540K available (14339K kernel code, 2370K rwdata, 4668K rodata, 2660K init, 5076K bss, 42632K reserved, 0K cma-reserved)\r\n[    0.033168] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1\r\n[    0.033177] ftrace: allocating 42927 entries in 168 pages\r\n[    0.048856] rcu: Hierarchical RCU implementation.\r\n[    0.048858] rcu: \tRCU restricting CPUs from NR_CPUS=8192 to nr_cpu_ids=4.\r\n[    0.048859] \tTasks RCU enabled.\r\n[    0.048860] rcu: RCU calculated value of scheduler-enlistment delay is 25 jiffies.\r\n[    0.048861] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4\r\n[    0.051062] NR_IRQS: 524544, nr_irqs: 456, preallocated irqs: 16\r\n[    0.058275] random: crng done (trusting CPU's manufacturer)\r\n[    0.059854] Console: colour *CGA 80x25\r\n[    0.149532] printk: console [tty1] enabled\r\n[    0.890239] printk: console [ttyS0] enabled\r\n[    0.895949] ACPI: Core revision 20190703\r\n[    0.903912] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns\r\n[    0.916556] APIC: Switch to symmetric I/O mode setup\r\n[    0.938387] x2apic enabled\r\n[    0.942570] Switched APIC routing to physical x2apic.\r\n[    0.948618] Hyper-V: Using IPI hypercalls\r\n[    0.953648] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    1.034221] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1\r\n[    1.042741] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=9199996)\r\n[    1.046743] pid_max: default: 32768 minimum: 301\r\n[    1.050765] LSM: Security Framework initializing\r\n[    1.054746] Yama: becoming mindful.\r\n[    1.058766] AppArmor: AppArmor initialized\r\n[    1.062764] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    1.066742] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    1.070851] *** VALIDATE proc ***\r\n[    1.074779] *** VALIDATE cgroup1 ***\r\n[    1.078740] *** VALIDATE cgroup2 ***\r\n[    1.082828] x86/cpu: User Mode Instruction Prevention (UMIP) activated\r\n[    1.086757] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0\r\n[    1.090739] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0\r\n[    1.094742] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization\r\n[    1.098740] Spectre V2 : Mitigation: Full generic retpoline\r\n[    1.102739] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch\r\n[    1.106740] Speculative Store Bypass: Vulnerable\r\n[    1.117463] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)\r\n[    1.118828] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.\r\n[    1.122765] rcu: Hierarchical SRCU implementation.\r\n[    1.126896] NMI watchdog: Perf NMI watchdog permanently disabled\r\n[    1.130797] smp: Bringing up secondary CPUs ...\r\n[    1.134741] smp: Brought up 1 node, 1 CPU\r\n[    1.138739] smpboot: Max logical packages: 4\r\n[    1.142739] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)\r\n[    1.146849] devtmpfs: initialized\r\n[    1.150820] x86/mm: Memory block size: 128MB\r\n[    1.154865] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns\r\n[    1.158750] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)\r\n[    1.162789] pinctrl core: initialized pinctrl subsystem\r\n[    1.167542] PM: RTC time: 23:32:49, date: 2025-11-07\r\n[    1.170814] NET: Registered protocol family 16\r\n[    1.174781] audit: initializing netlink subsys (disabled)\r\n[    1.178831] EISA bus registered\r\n[    1.182741] audit: type=2000 audit(1762558368.136:1): state=initialized audit_enabled=0 res=1\r\n[    1.186740] cpuidle: using governor ladder\r\n[    1.190742] cpuidle: using governor menu\r\n[    1.194768] ACPI: bus type PCI registered\r\n[    1.198739] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5\r\n[    1.203439] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)\r\n[    1.206740] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved in E820\r\n[    1.210746] PCI: Using configuration type 1 for base access\r\n[    1.215631] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages\r\n[    1.218741] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages\r\n[    1.223723] ACPI: Added _OSI(Module Device)\r\n[    1.226743] ACPI: Added _OSI(Processor Device)\r\n[    1.230740] ACPI: Added _OSI(3.0 _SCP Extensions)\r\n[    1.234740] ACPI: Added _OSI(Processor Aggregator Device)\r\n[    1.238755] ACPI: Added _OSI(Linux-Dell-Video)\r\n[    1.242849] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)\r\n[    1.246745] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)\r\n[    1.255743] ACPI: 1 ACPI AML tables successfully acquired and loaded\r\n[    1.263853] ACPI: Interpreter enabled\r\n[    1.266748] ACPI: (supports S0 S3 S4 S5)\r\n[    1.270739] ACPI: Using IOAPIC for interrupt routing\r\n[    1.274762] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\r\n[    1.278948] ACPI: Enabled 2 GPEs in block 00 to 3F\r\n[    1.287885] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\r\n[    1.290745] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]\r\n[    1.294832] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]\r\n[    1.298817] acpi PNP0A08:00: _OSC: OS now controls [SHPCHotplug PME AER PCIeCapability]\r\n[    1.304019] PCI host bridge to bus 0000:00\r\n[    1.306741] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]\r\n[    1.310741] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]\r\n[    1.314742] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]\r\n[    1.318739] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]\r\n[    1.322741] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]\r\n[    1.326740] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]\r\n[    1.330741] pci_bus 0000:00: root bus resource [bus 00-ff]\r\n[    1.335090] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000\r\n[    1.351040] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400\r\n[    1.362626] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]\r\n[    1.368756] pci 0000:00:01.0: enabling Extended Tags\r\n[    1.378985] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400\r\n[    1.387312] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]\r\n[    1.396403] pci 0000:00:01.1: enabling Extended Tags\r\n[    1.406935] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400\r\n[    1.416685] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]\r\n[    1.425932] pci 0000:00:01.2: enabling Extended Tags\r\n[    1.436352] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400\r\n[    1.441905] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]\r\n[    1.450822] pci 0000:00:01.3: enabling Extended Tags\r\n[    1.465426] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400\r\n[    1.472157] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]\r\n[    1.480476] pci 0000:00:01.4: enabling Extended Tags\r\n[    1.491154] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400\r\n[    1.501203] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]\r\n[    1.509370] pci 0000:00:01.5: enabling Extended Tags\r\n[    1.520090] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400\r\n[    1.532092] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]\r\n[    1.560400] pci 0000:00:01.6: enabling Extended Tags\r\n[    1.574610] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400\r\n[    1.580552] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]\r\n[    1.589137] pci 0000:00:01.7: enabling Extended Tags\r\n[    1.600179] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400\r\n[    1.608972] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]\r\n[    1.616858] pci 0000:00:02.0: enabling Extended Tags\r\n[    1.628922] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400\r\n[    1.635149] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]\r\n[    1.644353] pci 0000:00:02.1: enabling Extended Tags\r\n[    1.666218] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100\r\n[    1.674438] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO\r\n[    1.676586] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601\r\n[    1.689617] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]\r\n[    1.691931] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]\r\n[    1.702536] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500\r\n[    1.711658] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]\r\n[    1.723868] acpiphp: Slot [0] registered\r\n[    1.728565] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000\r\n[    1.737640] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]\r\n[    1.744934] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]\r\n[    1.751919] pci 0000:01:00.0: enabling Extended Tags\r\n[    1.774766] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    1.779067] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    1.783081] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.792003] acpiphp: Slot [0-2] registered\r\n[    1.803026] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    1.807097] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    1.811061] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.821097] acpiphp: Slot [0-3] registered\r\n[    1.832235] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    1.835074] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    1.839096] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.845248] acpiphp: Slot [0-4] registered\r\n[    1.852839] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    1.858923] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    1.863080] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.869196] acpiphp: Slot [0-5] registered\r\n[    1.872105] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000\r\n[    1.879398] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]\r\n[    1.887191] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]\r\n[    1.892637] pci 0000:05:00.0: enabling Extended Tags\r\n[    1.914840] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    1.919086] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    1.923089] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.932150] acpiphp: Slot [0-6] registered\r\n[    1.938739] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000\r\n[    1.949752] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]\r\n[    1.957581] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]\r\n[    1.964033] pci 0000:06:00.0: enabling Extended Tags\r\n[    1.983730] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    1.987089] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    1.991090] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    2.000881] acpiphp: Slot [0-7] registered\r\n[    2.007407] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000\r\n[    2.031828] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]\r\n[    2.060875] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]\r\n[    2.073062] pci 0000:07:00.0: enabling Extended Tags\r\n[    2.092279] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    2.095065] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    2.099072] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    2.105239] acpiphp: Slot [0-8] registered\r\n[    2.108126] pci 0000:08:00.0: [1af4:1042] type 00 class 0x010000\r\n[    2.115338] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]\r\n[    2.127137] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]\r\n[    2.132609] pci 0000:08:00.0: enabling Extended Tags\r\n[    2.166289] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    2.167052] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    2.171070] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    2.180442] acpiphp: Slot [0-9] registered\r\n[    2.187088] pci 0000:09:00.0: [1af4:1045] type 00 class 0x00ff00\r\n[    2.198740] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]\r\n[    2.207900] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]\r\n[    2.212867] pci 0000:09:00.0: enabling Extended Tags\r\n[    2.233961] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    2.235085] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    2.239091] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    2.247134] acpiphp: Slot [0-10] registered\r\n[    2.258352] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    2.259096] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    2.263084] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    2.279584] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11)\r\n[    2.283091] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11)\r\n[    2.287099] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11)\r\n[    2.291115] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11)\r\n[    2.295096] ACPI: PCI Interrupt Link [LNKE] (IRQs 5 *10 11)\r\n[    2.302752] ACPI: PCI Interrupt Link [LNKF] (IRQs 5 *10 11)\r\n[    2.307120] ACPI: PCI Interrupt Link [LNKG] (IRQs 5 10 *11)\r\n[    2.311103] ACPI: PCI Interrupt Link [LNKH] (IRQs 5 10 *11)\r\n[    2.314908] ACPI: PCI Interrupt Link [GSIA] (IRQs *16)\r\n[    2.318750] ACPI: PCI Interrupt Link [GSIB] (IRQs *17)\r\n[    2.322745] ACPI: PCI Interrupt Link [GSIC] (IRQs *18)\r\n[    2.326752] ACPI: PCI Interrupt Link [GSID] (IRQs *19)\r\n[    2.330746] ACPI: PCI Interrupt Link [GSIE] (IRQs *20)\r\n[    2.334746] ACPI: PCI Interrupt Link [GSIF] (IRQs *21)\r\n[    2.338745] ACPI: PCI Interrupt Link [GSIG] (IRQs *22)\r\n[    2.342745] ACPI: PCI Interrupt Link [GSIH] (IRQs *23)\r\n[    2.347692] SCSI subsystem initialized\r\n[    2.350759] libata version 3.00 loaded.\r\n[    2.350782] vgaarb: loaded\r\n[    2.354751] ACPI: bus type USB registered\r\n[    2.358750] usbcore: registered new interface driver usbfs\r\n[    2.362745] usbcore: registered new interface driver hub\r\n[    2.366747] usbcore: registered new device driver usb\r\n[    2.370767] pps_core: LinuxPPS API ver. 1 registered\r\n[    2.374739] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;\r\n[    2.378740] PTP clock support registered\r\n[    2.382774] EDAC MC: Ver: 3.0.0\r\n[    2.394633] PCI: Using ACPI for IRQ routing\r\n[    3.126061] PCI: pci_cache_line_size set to 64 bytes\r\n[    3.129522] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]\r\n[    3.129524] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]\r\n[    3.129614] NetLabel: Initializing\r\n[    3.130740] NetLabel:  domain hash size = 128\r\n[    3.134739] NetLabel:  protocols = UNLABELED CIPSOv4 CALIPSO\r\n[    3.138754] NetLabel:  unlabeled traffic allowed by default\r\n[    3.142827] hpet: 3 channels of 0 reserved for per-cpu timers\r\n[    3.146952] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0\r\n[    3.150739] hpet0: 3 comparators, 64-bit 100.000000 MHz counter\r\n[    3.158750] clocksource: Switched to clocksource hyperv_clocksource_tsc_page\r\n[    3.174220] VFS: Disk quotas dquot_6.6.0\r\n[    3.179228] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\r\n[    3.187246] *** VALIDATE hugetlbfs ***\r\n[    3.192026] AppArmor: AppArmor Filesystem Enabled\r\n[    3.219047] pnp: PnP ACPI init\r\n[    3.223717] pnp 00:00: Plug and Play ACPI device, IDs PNP0501 (active)\r\n[    3.223730] pnp 00:01: Plug and Play ACPI device, IDs PNP0303 (active)\r\n[    3.223740] pnp 00:02: Plug and Play ACPI device, IDs PNP0f13 (active)\r\n[    3.223752] pnp 00:03: Plug and Play ACPI device, IDs PNP0b00 (active)\r\n[    3.223776] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved\r\n[    3.231967] system 00:04: Plug and Play ACPI device, IDs PNP0c01 (active)\r\n[    3.233085] pnp: PnP ACPI: found 5 devices\r\n[    3.239216] thermal_sys: Registered thermal governor 'fair_share'\r\n[    3.239216] thermal_sys: Registered thermal governor 'bang_bang'\r\n[    3.246465] thermal_sys: Registered thermal governor 'step_wise'\r\n[    3.253466] thermal_sys: Registered thermal governor 'user_space'\r\n[    3.260288] thermal_sys: Registered thermal governor 'power_allocator'\r\n[    3.272588] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns\r\n[    3.290125] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000\r\n[    3.299199] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000\r\n[    3.310529] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000\r\n[    3.319817] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000\r\n[    3.329332] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000\r\n[    3.338947] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000\r\n[    3.348656] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000\r\n[    3.358086] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000\r\n[    3.367529] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000\r\n[    3.377195] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000\r\n[    3.386434] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]\r\n[    3.393467] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]\r\n[    3.400839] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]\r\n[    3.407848] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]\r\n[    3.414812] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]\r\n[    3.422389] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]\r\n[    3.429309] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]\r\n[    3.436428] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]\r\n[    3.443479] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]\r\n[    3.460804] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]\r\n[    3.468378] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    3.474319] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]\r\n[    3.483078] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    3.493353] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    3.503326] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    3.509930] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]\r\n[    3.518615] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    3.528686] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    3.539461] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    3.547144] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]\r\n[    3.558878] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    3.568182] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    3.579741] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    3.585666] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]\r\n[    3.594155] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    3.602830] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    3.613430] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    3.619769] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]\r\n[    3.628125] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    3.636681] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    3.646996] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    3.653274] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]\r\n[    3.661233] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    3.670173] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    3.680220] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    3.686488] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]\r\n[    3.694663] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    3.703240] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    3.713267] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    3.719215] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]\r\n[    3.727401] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    3.736152] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    3.746803] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    3.753114] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]\r\n[    3.760882] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    3.769529] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    3.781525] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    3.787782] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]\r\n[    3.795692] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    3.804438] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    3.814817] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]\r\n[    3.821920] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]\r\n[    3.829417] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]\r\n[    3.837336] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]\r\n[    3.845299] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]\r\n[    3.853042] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]\r\n[    3.861053] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]\r\n[    3.867426] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]\r\n[    3.874881] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    3.882877] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]\r\n[    3.890160] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]\r\n[    3.897861] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    3.906097] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]\r\n[    3.912607] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]\r\n[    3.919997] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    3.928305] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]\r\n[    3.934978] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]\r\n[    3.942377] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    3.950379] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]\r\n[    3.957050] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]\r\n[    3.964279] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    3.972602] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]\r\n[    3.979143] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]\r\n[    3.986664] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    3.994727] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]\r\n[    4.001328] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]\r\n[    4.008564] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    4.017124] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]\r\n[    4.023517] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]\r\n[    4.030528] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    4.042384] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]\r\n[    4.048884] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]\r\n[    4.056027] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    4.064155] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]\r\n[    4.070574] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]\r\n[    4.077802] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    4.086329] NET: Registered protocol family 2\r\n[    4.091775] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    4.101112] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r\n[    4.109449] TCP bind hash table entries: 1024 (order: 2, 16384 bytes, linear)\r\n[    4.117450] TCP: Hash tables configured (established 1024 bind 1024)\r\n[    4.124820] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    4.132179] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    4.139970] NET: Registered protocol family 1\r\n[    4.145287] NET: Registered protocol family 44\r\n[    4.152404] PCI: CLS 0 bytes, default 64\r\n[    4.157442] Trying to unpack rootfs image as initramfs...\r\n[    4.247510] Freeing initrd memory: 6396K\r\n[    4.255920] check: Scanning for low memory corruption every 60 seconds\r\n[    4.264234] Initialise system trusted keyrings\r\n[    4.269882] Key type blacklist registered\r\n[    4.274886] workingset: timestamp_bits=36 max_order=15 bucket_order=0\r\n[    4.282990] zbud: loaded\r\n[    4.286782] squashfs: version 4.0 (2009/01/31) Phillip Lougher\r\n[    4.293788] fuse: init (API version 7.31)\r\n[    4.298856] Platform Keyring initialized\r\n[    4.307164] Key type asymmetric registered\r\n[    4.312160] Asymmetric key parser 'x509' registered\r\n[    4.317992] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 244)\r\n[    4.326243] io scheduler mq-deadline registered\r\n[    4.332012] PCI Interrupt Link [GSIF] enabled at IRQ 21\r\n[    4.343931] pcieport 0000:00:01.0: PME: Signaling with IRQ 24\r\n[    4.352995] pcieport 0000:00:01.0: AER: enabled with IRQ 24\r\n[    4.368964] pcieport 0000:00:01.1: PME: Signaling with IRQ 25\r\n[    4.377813] pcieport 0000:00:01.1: AER: enabled with IRQ 25\r\n[    4.394346] pcieport 0000:00:01.2: PME: Signaling with IRQ 26\r\n[    4.402636] pcieport 0000:00:01.2: AER: enabled with IRQ 26\r\n[    4.419432] pcieport 0000:00:01.3: PME: Signaling with IRQ 27\r\n[    4.428544] pcieport 0000:00:01.3: AER: enabled with IRQ 27\r\n[    4.451508] pcieport 0000:00:01.4: PME: Signaling with IRQ 28\r\n[    4.465609] pcieport 0000:00:01.4: AER: enabled with IRQ 28\r\n[    4.481355] pcieport 0000:00:01.5: PME: Signaling with IRQ 29\r\n[    4.490292] pcieport 0000:00:01.5: AER: enabled with IRQ 29\r\n[    4.506496] pcieport 0000:00:01.6: PME: Signaling with IRQ 30\r\n[    4.515198] pcieport 0000:00:01.6: AER: enabled with IRQ 30\r\n[    4.531949] pcieport 0000:00:01.7: PME: Signaling with IRQ 31\r\n[    4.541370] pcieport 0000:00:01.7: AER: enabled with IRQ 31\r\n[    4.551728] PCI Interrupt Link [GSIG] enabled at IRQ 22\r\n[    4.564212] pcieport 0000:00:02.0: PME: Signaling with IRQ 32\r\n[    4.574483] pcieport 0000:00:02.0: AER: enabled with IRQ 32\r\n[    4.590979] pcieport 0000:00:02.1: PME: Signaling with IRQ 33\r\n[    4.599834] pcieport 0000:00:02.1: AER: enabled with IRQ 33\r\n[    4.610300] shpchp: Standard Hot Plug PCI Controller Driver version: 0.4\r\n[    4.617828] intel_idle: does not run on family 6 model 207\r\n[    4.617873] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0\r\n[    4.626289] ACPI: Power Button [PWRF]\r\n[    4.775399] Serial: 8250/16550 driver, 32 ports, IRQ sharing enabled\r\n[    4.828058] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\r\n[    5.113742] Linux agpgart interface v0.103\r\n[    5.123381] loop: module loaded\r\n[    5.127809] libphy: Fixed MDIO Bus: probed\r\n[    5.132796] tun: Universal TUN/TAP device driver, 1.6\r\n[    5.138740] PPP generic driver version 2.4.2\r\n[    5.143983] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver\r\n[    5.151330] ehci-pci: EHCI PCI platform driver\r\n[    5.156600] ehci-platform: EHCI generic platform driver\r\n[    5.162725] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver\r\n[    5.169801] ohci-pci: OHCI PCI platform driver\r\n[    5.175248] ohci-platform: OHCI generic platform driver\r\n[    5.181288] uhci_hcd: USB Universal Host Controller Interface driver\r\n[    5.188672] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\r\n[    5.208670] serio: i8042 KBD port at 0x60,0x64 irq 1\r\n[    5.214564] serio: i8042 AUX port at 0x60,0x64 irq 12\r\n[    5.220593] mousedev: PS/2 mouse device common for all mice\r\n[    5.228628] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1\r\n[    5.238336] rtc_cmos 00:03: RTC can wake from S4\r\n[    5.250466] rtc_cmos 00:03: registered as rtc0\r\n[    5.255937] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs\r\n[    5.265136] i2c /dev entries driver\r\n[    5.269612] device-mapper: uevent: version 1.0.3\r\n[    5.275186] device-mapper: ioctl: 4.40.0-ioctl (2019-01-18) initialised: dm-devel@redhat.com\r\n[    5.284969] platform eisa.0: Probing EISA bus 0\r\n[    5.290503] platform eisa.0: EISA: Cannot allocate resource for mainboard\r\n[    5.298184] platform eisa.0: Cannot allocate resource for EISA slot 1\r\n[    5.305623] platform eisa.0: Cannot allocate resource for EISA slot 2\r\n[    5.312919] platform eisa.0: Cannot allocate resource for EISA slot 3\r\n[    5.320451] platform eisa.0: Cannot allocate resource for EISA slot 4\r\n[    5.327747] platform eisa.0: Cannot allocate resource for EISA slot 5\r\n[    5.335077] platform eisa.0: Cannot allocate resource for EISA slot 6\r\n[    5.342315] platform eisa.0: Cannot allocate resource for EISA slot 7\r\n[    5.349603] platform eisa.0: Cannot allocate resource for EISA slot 8\r\n[    5.356792] platform eisa.0: EISA: Detected 0 cards\r\n[    5.362544] intel_pstate: CPU model not supported\r\n[    5.368285] ledtrig-cpu: registered to indicate activity on CPUs\r\n[    5.375270] NET: Registered protocol family 10\r\n[    5.383613] Segment Routing with IPv6\r\n[    5.388214] NET: Registered protocol family 17\r\n[    5.393707] Key type dns_resolver registered\r\n[    5.399296] RAS: Correctable Errors collector initialized.\r\n[    5.405646] registered taskstats version 1\r\n[    5.411102] Loading compiled-in X.509 certificates\r\n[    5.417754] Loaded X.509 cert 'Build time autogenerated kernel key: 8098f9b3401d48cb244b138af0c5bac131caef8a'\r\n[    5.428832] zswap: loaded using pool lzo/zbud\r\n[    5.436792] Key type big_key registered\r\n[    5.443458] Key type encrypted registered\r\n[    5.448344] AppArmor: AppArmor sha1 policy hashing enabled\r\n[    5.454690] ima: No TPM chip found, activating TPM-bypass!\r\n[    5.465021] ima: Allocated hash algorithm: sha1\r\n[    5.471181] No architecture policies found\r\n[    5.476343] evm: Initialising EVM extended attributes:\r\n[    5.482416] evm: security.selinux\r\n[    5.486636] evm: security.SMACK64\r\n[    5.490967] evm: security.SMACK64EXEC\r\n[    5.495585] evm: security.SMACK64TRANSMUTE\r\n[    5.500609] evm: security.SMACK64MMAP\r\n[    5.506682] evm: security.apparmor\r\n[    5.511176] evm: security.ima\r\n[    5.515108] evm: security.capability\r\n[    5.519628] evm: HMAC attrs: 0x1\r\n[    5.525304] PM:   Magic number: 1:476:554\r\n[    5.530243] acpi PNP0C0F:05: hash matches\r\n[    5.535231] acpi PNP0C01:00: hash matches\r\n[    5.541115] rtc_cmos 00:03: setting system clock to 2025-11-07T23:32:54 UTC (1762558374)\r\n[    5.550123] Unstable clock detected, switching default tracing clock to \"global\"\r\n               If you want to keep using the local clock, then add:\r\n                 \"trace_clock=local\"\r\n               on the kernel command line\r\n[    5.581609] Freeing unused decrypted memory: 2040K\r\n[    5.588031] Freeing unused kernel image memory: 2660K\r\n[    5.594122] Write protecting the kernel read-only data: 22528k\r\n[    5.602238] Freeing unused kernel image memory: 2008K\r\n[    5.608412] Freeing unused kernel image memory: 1476K\r\n[    5.619736] x86/mm: Checked W+X mappings: passed, no W+X pages found.\r\n[    5.627091] Run /init as init process\r\n[    5.648471] e1000: Intel(R) PRO/1000 Network Driver - version 7.3.21-k8-NAPI\r\n[    5.648472] e1000: Copyright (c) 1999-2006 Intel Corporation.\r\n[    5.650353] ne2k-pci.c:v1.03 9/22/2003 D. Becker/P. Gortmaker\r\n[    5.653866] pcnet32: pcnet32.c:v1.35 21.Apr.2008 tsbogend@alpha.franken.de\r\n[    5.656260] 9pnet: Installing 9P2000 support\r\n[    5.767539] virtio_blk virtio3: [vda] 229376 512-byte logical blocks (117 MB/112 MiB)\r\n[    5.781915]  vda: vda1 vda15\r\n[    5.800889] virtio_blk virtio4: [vdb] 2048 512-byte logical blocks (1.05 MB/1.00 MiB)\r\n[    5.872277] scsi host0: Virtio SCSI HBA\r\n[    5.909275] hidraw: raw HID events driver (C) Jiri Kosina\r\n[    5.910108] usbcore: registered new interface driver usbhid\r\n[    5.910109] usbhid: USB HID core driver\r\n[    5.919941] ahci 0000:00:1f.2: version 3.0\r\n[    5.920502] PCI Interrupt Link [GSIA] enabled at IRQ 16\r\n[    5.932220] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode\r\n[    5.932221] ahci 0000:00:1f.2: flags: 64bit ncq only \r\n[    5.944900] scsi host1: ahci\r\n[    5.944946] scsi host2: ahci\r\n[    5.944984] scsi host3: ahci\r\n[    5.945016] scsi host4: ahci\r\n[    5.945051] scsi host5: ahci\r\n[    5.945085] scsi host6: ahci\r\n[    5.945254] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 49\r\n[    5.945393] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 49\r\n[    5.945558] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 49\r\n[    5.945699] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 49\r\n[    5.945830] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 49\r\n[    5.945964] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 49\r\n[    6.262477] ata2: SATA link down (SStatus 0 SControl 300)\r\n[    6.266434] ata1: SATA link down (SStatus 0 SControl 300)\r\n[    6.270321] ata3: SATA link down (SStatus 0 SControl 300)\r\n[    6.274383] ata4: SATA link down (SStatus 0 SControl 300)\r\n[    6.278151] ata5: SATA link down (SStatus 0 SControl 300)\r\n[    6.282013] ata6: SATA link down (SStatus 0 SControl 300)\r\n[    6.329634] EXT4-fs (vda1): mounting ext3 file system using the ext4 subsystem\r\n[    6.332577] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)\r\n[    6.334781] EXT4-fs (vda1): mounting ext3 file system using the ext4 subsystem\r\n[    6.349983] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)\r\n[    6.484299] EXT4-fs (vda1): re-mounted. Opts: (null)\r\n[    6.504463] EXT4-fs (vda1): re-mounted. Opts: (null)\r\n[    6.590429] ISO 9660 Extensions: Microsoft Joliet Level 3\r\n[    6.591050] ISO 9660 Extensions: RRIP_1991A\r\n[    6.866747] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready\r\n[    6.954983] EXT4-fs (vda1): resizing filesystem from 25600 to 26363 blocks\r\n[    6.954992] EXT4-fs (vda1): resized filesystem to 26363\r\n$ " "\r\n[    0.000000] Linux version 5.3.0-26-generic (buildd@lgw01-amd64-039) (gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1)) #28~18.04.1-Ubuntu SMP Wed Dec 18 16:40:14 UTC 2019 (Ubuntu 5.3.0-26.28~18.04.1-generic 5.3.13)\r\n[    0.000000] Command line: LABEL=cirros-rootfs ro console=tty1 console=ttyS0\r\n[    0.000000] KERNEL supported cpus:\r\n[    0.000000]   Intel GenuineIntel\r\n[    0.000000]   AMD AuthenticAMD\r\n[    0.000000]   Hygon HygonGenuine\r\n[    0.000000]   Centaur CentaurHauls\r\n[    0.000000]   zhaoxin   Shanghai  \r\n[    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'\r\n[    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'\r\n[    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'\r\n[    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256\r\n[    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format.\r\n[    0.000000] BIOS-provided physical RAM map:\r\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable\r\n[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable\r\n[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved\r\n[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved\r\n[    0.000000] NX (Execute Disable) protection: active\r\n[    0.000000] SMBIOS 2.8 present.\r\n[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014\r\n[    0.000000] Hypervisor detected: Microsoft Hyper-V\r\n[    0.000000] Hyper-V: features 0xe7e, hints 0x60624\r\n[    0.000000] Hyper-V Host Build:26100-10.0-1-0.1381\r\n[    0.000000] Hyper-V: LAPIC Timer Frequency: 0xc3500\r\n[    0.000000] tsc: Marking TSC unstable due to running on Hyper-V\r\n[    0.000000] Hyper-V: Using hypercall for remote TLB flush\r\n[    0.000000] tsc: Detected 2299.999 MHz processor\r\n[    0.000713] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved\r\n[    0.000714] e820: remove [mem 0x000a0000-0x000fffff] usable\r\n[    0.000716] last_pfn = 0x7fdd max_arch_pfn = 0x400000000\r\n[    0.000741] MTRR default type: write-back\r\n[    0.000742] MTRR fixed ranges enabled:\r\n[    0.000742]   00000-9FFFF write-back\r\n[    0.000743]   A0000-BFFFF uncachable\r\n[    0.000744]   C0000-FFFFF write-protect\r\n[    0.000744] MTRR variable ranges enabled:\r\n[    0.000745]   0 base 0000C0000000 mask FFFFC0000000 uncachable\r\n[    0.000745]   1 disabled\r\n[    0.000746]   2 disabled\r\n[    0.000746]   3 disabled\r\n[    0.000746]   4 disabled\r\n[    0.000747]   5 disabled\r\n[    0.000747]   6 disabled\r\n[    0.000747]   7 disabled\r\n[    0.000754] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \r\n[    0.003905] found SMP MP-table at [mem 0x000f5470-0x000f547f]\r\n[    0.003961] check: Scanning 1 areas for low memory corruption\r\n[    0.004456] Using GB pages for direct mapping\r\n[    0.004461] BRK [0x05e01000, 0x05e01fff] PGTABLE\r\n[    0.004462] BRK [0x05e02000, 0x05e02fff] PGTABLE\r\n[    0.004463] BRK [0x05e03000, 0x05e03fff] PGTABLE\r\n[    0.004494] BRK [0x05e04000, 0x05e04fff] PGTABLE\r\n[    0.004592] BRK [0x05e05000, 0x05e05fff] PGTABLE\r\n[    0.004622] RAMDISK: [mem 0x0798e000-0x07fccfff]\r\n[    0.004775] ACPI: Early table checksum verification disabled\r\n[    0.004778] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )\r\n[    0.004781] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004785] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004788] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004790] ACPI: FACS 0x0000000007FE0000 000040\r\n[    0.004792] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004794] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004795] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004797] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)\r\n[    0.004802] ACPI: Local APIC address 0xfee00000\r\n[    0.010519] No NUMA configuration found\r\n[    0.010521] Faking a node at [mem 0x0000000000000000-0x0000000007fdcfff]\r\n[    0.010528] NODE_DATA(0) allocated [mem 0x07963000-0x0798dfff]\r\n[    0.010681] Zone ranges:\r\n[    0.010682]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]\r\n[    0.010683]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]\r\n[    0.010683]   Normal   empty\r\n[    0.010684]   Device   empty\r\n[    0.010685] Movable zone start for each node\r\n[    0.010688] Early memory node ranges\r\n[    0.010689]   node   0: [mem 0x0000000000001000-0x000000000009efff]\r\n[    0.010689]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]\r\n[    0.011713] Zeroed struct page in unavailable ranges: 98 pages\r\n[    0.011715] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]\r\n[    0.011718] On node 0 totalpages: 32635\r\n[    0.011719]   DMA zone: 64 pages used for memmap\r\n[    0.011720]   DMA zone: 21 pages reserved\r\n[    0.011720]   DMA zone: 3998 pages, LIFO batch:0\r\n[    0.011753]   DMA32 zone: 448 pages used for memmap\r\n[    0.011754]   DMA32 zone: 28637 pages, LIFO batch:7\r\n[    0.030250] ACPI: PM-Timer IO Port: 0x608\r\n[    0.030254] ACPI: Local APIC address 0xfee00000\r\n[    0.030262] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\r\n[    0.032018] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23\r\n[    0.032020] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)\r\n[    0.032022] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\r\n[    0.032022] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\r\n[    0.032023] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\r\n[    0.032024] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\r\n[    0.032025] ACPI: IRQ0 used by override.\r\n[    0.032026] ACPI: IRQ5 used by override.\r\n[    0.032026] ACPI: IRQ9 used by override.\r\n[    0.032026] ACPI: IRQ10 used by override.\r\n[    0.032027] ACPI: IRQ11 used by override.\r\n[    0.032028] Using ACPI (MADT) for SMP configuration information\r\n[    0.032030] ACPI: HPET id: 0x8086a201 base: 0xfed00000\r\n[    0.032033] smpboot: Allowing 4 CPUs, 3 hotplug CPUs\r\n[    0.032041] PM: Registered nosave memory: [mem 0x00000000-0x00000fff]\r\n[    0.032042] PM: Registered nosave memory: [mem 0x0009f000-0x0009ffff]\r\n[    0.032042] PM: Registered nosave memory: [mem 0x000a0000-0x000effff]\r\n[    0.032043] PM: Registered nosave memory: [mem 0x000f0000-0x000fffff]\r\n[    0.032044] [mem 0x08000000-0xafffffff] available for PCI devices\r\n[    0.032045] Booting paravirtualized kernel on bare hardware\r\n[    0.032048] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645519600211568 ns\r\n[    0.032051] setup_percpu: NR_CPUS:8192 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1\r\n[    0.032771] percpu: Embedded 54 pages/cpu s184320 r8192 d28672 u524288\r\n[    0.032776] pcpu-alloc: s184320 r8192 d28672 u524288 alloc=1*2097152\r\n[    0.032776] pcpu-alloc: [0] 0 1 2 3 \r\n[    0.032788] Hyper-V: PV spinlocks enabled\r\n[    0.032790] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    0.032793] Built 1 zonelists, mobility grouping on.  Total pages: 32102\r\n[    0.032794] Policy zone: DMA32\r\n[    0.032795] Kernel command line: LABEL=cirros-rootfs ro console=tty1 console=ttyS0\r\n[    0.032826] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r\n[    0.032832] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r\n[    0.032875] mem auto-init: stack:off, heap alloc:on, heap free:off\r\n[    0.032878] Calgary: detecting Calgary via BIOS EBDA area\r\n[    0.032879] Calgary: Unable to locate Rio Grande table in EBDA - bailing!\r\n[    0.033093] Memory: 87908K/130540K available (14339K kernel code, 2370K rwdata, 4668K rodata, 2660K init, 5076K bss, 42632K reserved, 0K cma-reserved)\r\n[    0.033168] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1\r\n[    0.033177] ftrace: allocating 42927 entries in 168 pages\r\n[    0.048856] rcu: Hierarchical RCU implementation.\r\n[    0.048858] rcu: \tRCU restricting CPUs from NR_CPUS=8192 to nr_cpu_ids=4.\r\n[    0.048859] \tTasks RCU enabled.\r\n[    0.048860] rcu: RCU calculated value of scheduler-enlistment delay is 25 jiffies.\r\n[    0.048861] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4\r\n[    0.051062] NR_IRQS: 524544, nr_irqs: 456, preallocated irqs: 16\r\n[    0.058275] random: crng done (trusting CPU's manufacturer)\r\n[    0.059854] Console: colour *CGA 80x25\r\n[    0.149532] printk: console [tty1] enabled\r\n[    0.890239] printk: console [ttyS0] enabled\r\n[    0.895949] ACPI: Core revision 20190703\r\n[    0.903912] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns\r\n[    0.916556] APIC: Switch to symmetric I/O mode setup\r\n[    0.938387] x2apic enabled\r\n[    0.942570] Switched APIC routing to physical x2apic.\r\n[    0.948618] Hyper-V: Using IPI hypercalls\r\n[    0.953648] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r\n[    1.034221] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1\r\n[    1.042741] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=9199996)\r\n[    1.046743] pid_max: default: 32768 minimum: 301\r\n[    1.050765] LSM: Security Framework initializing\r\n[    1.054746] Yama: becoming mindful.\r\n[    1.058766] AppArmor: AppArmor initialized\r\n[    1.062764] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    1.066742] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r\n[    1.070851] *** VALIDATE proc ***\r\n[    1.074779] *** VALIDATE cgroup1 ***\r\n[    1.078740] *** VALIDATE cgroup2 ***\r\n[    1.082828] x86/cpu: User Mode Instruction Prevention (UMIP) activated\r\n[    1.086757] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0\r\n[    1.090739] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0\r\n[    1.094742] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization\r\n[    1.098740] Spectre V2 : Mitigation: Full generic retpoline\r\n[    1.102739] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch\r\n[    1.106740] Speculative Store Bypass: Vulnerable\r\n[    1.117463] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)\r\n[    1.118828] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.\r\n[    1.122765] rcu: Hierarchical SRCU implementation.\r\n[    1.126896] NMI watchdog: Perf NMI watchdog permanently disabled\r\n[    1.130797] smp: Bringing up secondary CPUs ...\r\n[    1.134741] smp: Brought up 1 node, 1 CPU\r\n[    1.138739] smpboot: Max logical packages: 4\r\n[    1.142739] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)\r\n[    1.146849] devtmpfs: initialized\r\n[    1.150820] x86/mm: Memory block size: 128MB\r\n[    1.154865] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns\r\n[    1.158750] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)\r\n[    1.162789] pinctrl core: initialized pinctrl subsystem\r\n[    1.167542] PM: RTC time: 23:32:49, date: 2025-11-07\r\n[    1.170814] NET: Registered protocol family 16\r\n[    1.174781] audit: initializing netlink subsys (disabled)\r\n[    1.178831] EISA bus registered\r\n[    1.182741] audit: type=2000 audit(1762558368.136:1): state=initialized audit_enabled=0 res=1\r\n[    1.186740] cpuidle: using governor ladder\r\n[    1.190742] cpuidle: using governor menu\r\n[    1.194768] ACPI: bus type PCI registered\r\n[    1.198739] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5\r\n[    1.203439] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)\r\n[    1.206740] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved in E820\r\n[    1.210746] PCI: Using configuration type 1 for base access\r\n[    1.215631] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages\r\n[    1.218741] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages\r\n[    1.223723] ACPI: Added _OSI(Module Device)\r\n[    1.226743] ACPI: Added _OSI(Processor Device)\r\n[    1.230740] ACPI: Added _OSI(3.0 _SCP Extensions)\r\n[    1.234740] ACPI: Added _OSI(Processor Aggregator Device)\r\n[    1.238755] ACPI: Added _OSI(Linux-Dell-Video)\r\n[    1.242849] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)\r\n[    1.246745] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)\r\n[    1.255743] ACPI: 1 ACPI AML tables successfully acquired and loaded\r\n[    1.263853] ACPI: Interpreter enabled\r\n[    1.266748] ACPI: (supports S0 S3 S4 S5)\r\n[    1.270739] ACPI: Using IOAPIC for interrupt routing\r\n[    1.274762] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\r\n[    1.278948] ACPI: Enabled 2 GPEs in block 00 to 3F\r\n[    1.287885] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\r\n[    1.290745] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]\r\n[    1.294832] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]\r\n[    1.298817] acpi PNP0A08:00: _OSC: OS now controls [SHPCHotplug PME AER PCIeCapability]\r\n[    1.304019] PCI host bridge to bus 0000:00\r\n[    1.306741] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]\r\n[    1.310741] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]\r\n[    1.314742] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]\r\n[    1.318739] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]\r\n[    1.322741] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]\r\n[    1.326740] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]\r\n[    1.330741] pci_bus 0000:00: root bus resource [bus 00-ff]\r\n[    1.335090] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000\r\n[    1.351040] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400\r\n[    1.362626] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]\r\n[    1.368756] pci 0000:00:01.0: enabling Extended Tags\r\n[    1.378985] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400\r\n[    1.387312] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]\r\n[    1.396403] pci 0000:00:01.1: enabling Extended Tags\r\n[    1.406935] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400\r\n[    1.416685] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]\r\n[    1.425932] pci 0000:00:01.2: enabling Extended Tags\r\n[    1.436352] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400\r\n[    1.441905] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]\r\n[    1.450822] pci 0000:00:01.3: enabling Extended Tags\r\n[    1.465426] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400\r\n[    1.472157] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]\r\n[    1.480476] pci 0000:00:01.4: enabling Extended Tags\r\n[    1.491154] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400\r\n[    1.501203] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]\r\n[    1.509370] pci 0000:00:01.5: enabling Extended Tags\r\n[    1.520090] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400\r\n[    1.532092] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]\r\n[    1.560400] pci 0000:00:01.6: enabling Extended Tags\r\n[    1.574610] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400\r\n[    1.580552] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]\r\n[    1.589137] pci 0000:00:01.7: enabling Extended Tags\r\n[    1.600179] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400\r\n[    1.608972] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]\r\n[    1.616858] pci 0000:00:02.0: enabling Extended Tags\r\n[    1.628922] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400\r\n[    1.635149] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]\r\n[    1.644353] pci 0000:00:02.1: enabling Extended Tags\r\n[    1.666218] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100\r\n[    1.674438] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO\r\n[    1.676586] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601\r\n[    1.689617] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]\r\n[    1.691931] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]\r\n[    1.702536] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500\r\n[    1.711658] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]\r\n[    1.723868] acpiphp: Slot [0] registered\r\n[    1.728565] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000\r\n[    1.737640] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]\r\n[    1.744934] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]\r\n[    1.751919] pci 0000:01:00.0: enabling Extended Tags\r\n[    1.774766] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    1.779067] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    1.783081] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    1.792003] acpiphp: Slot [0-2] registered\r\n[    1.803026] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    1.807097] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    1.811061] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    1.821097] acpiphp: Slot [0-3] registered\r\n[    1.832235] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    1.835074] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    1.839096] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    1.845248] acpiphp: Slot [0-4] registered\r\n[    1.852839] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    1.858923] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    1.863080] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    1.869196] acpiphp: Slot [0-5] registered\r\n[    1.872105] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000\r\n[    1.879398] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]\r\n[    1.887191] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]\r\n[    1.892637] pci 0000:05:00.0: enabling Extended Tags\r\n[    1.914840] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    1.919086] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    1.923089] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    1.932150] acpiphp: Slot [0-6] registered\r\n[    1.938739] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000\r\n[    1.949752] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]\r\n[    1.957581] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]\r\n[    1.964033] pci 0000:06:00.0: enabling Extended Tags\r\n[    1.983730] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    1.987089] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    1.991090] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    2.000881] acpiphp: Slot [0-7] registered\r\n[    2.007407] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000\r\n[    2.031828] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]\r\n[    2.060875] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]\r\n[    2.073062] pci 0000:07:00.0: enabling Extended Tags\r\n[    2.092279] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    2.095065] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    2.099072] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    2.105239] acpiphp: Slot [0-8] registered\r\n[    2.108126] pci 0000:08:00.0: [1af4:1042] type 00 class 0x010000\r\n[    2.115338] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]\r\n[    2.127137] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]\r\n[    2.132609] pci 0000:08:00.0: enabling Extended Tags\r\n[    2.166289] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    2.167052] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    2.171070] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    2.180442] acpiphp: Slot [0-9] registered\r\n[    2.187088] pci 0000:09:00.0: [1af4:1045] type 00 class 0x00ff00\r\n[    2.198740] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]\r\n[    2.207900] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]\r\n[    2.212867] pci 0000:09:00.0: enabling Extended Tags\r\n[    2.233961] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    2.235085] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    2.239091] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    2.247134] acpiphp: Slot [0-10] registered\r\n[    2.258352] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    2.259096] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    2.263084] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    2.279584] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11)\r\n[    2.283091] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11)\r\n[    2.287099] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11)\r\n[    2.291115] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11)\r\n[    2.295096] ACPI: PCI Interrupt Link [LNKE] (IRQs 5 *10 11)\r\n[    2.302752] ACPI: PCI Interrupt Link [LNKF] (IRQs 5 *10 11)\r\n[    2.307120] ACPI: PCI Interrupt Link [LNKG] (IRQs 5 10 *11)\r\n[    2.311103] ACPI: PCI Interrupt Link [LNKH] (IRQs 5 10 *11)\r\n[    2.314908] ACPI: PCI Interrupt Link [GSIA] (IRQs *16)\r\n[    2.318750] ACPI: PCI Interrupt Link [GSIB] (IRQs *17)\r\n[    2.322745] ACPI: PCI Interrupt Link [GSIC] (IRQs *18)\r\n[    2.326752] ACPI: PCI Interrupt Link [GSID] (IRQs *19)\r\n[    2.330746] ACPI: PCI Interrupt Link [GSIE] (IRQs *20)\r\n[    2.334746] ACPI: PCI Interrupt Link [GSIF] (IRQs *21)\r\n[    2.338745] ACPI: PCI Interrupt Link [GSIG] (IRQs *22)\r\n[    2.342745] ACPI: PCI Interrupt Link [GSIH] (IRQs *23)\r\n[    2.347692] SCSI subsystem initialized\r\n[    2.350759] libata version 3.00 loaded.\r\n[    2.350782] vgaarb: loaded\r\n[    2.354751] ACPI: bus type USB registered\r\n[    2.358750] usbcore: registered new interface driver usbfs\r\n[    2.362745] usbcore: registered new interface driver hub\r\n[    2.366747] usbcore: registered new device driver usb\r\n[    2.370767] pps_core: LinuxPPS API ver. 1 registered\r\n[    2.374739] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;\r\n[    2.378740] PTP clock support registered\r\n[    2.382774] EDAC MC: Ver: 3.0.0\r\n[    2.394633] PCI: Using ACPI for IRQ routing\r\n[    3.126061] PCI: pci_cache_line_size set to 64 bytes\r\n[    3.129522] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]\r\n[    3.129524] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]\r\n[    3.129614] NetLabel: Initializing\r\n[    3.130740] NetLabel:  domain hash size = 128\r\n[    3.134739] NetLabel:  protocols = UNLABELED CIPSOv4 CALIPSO\r\n[    3.138754] NetLabel:  unlabeled traffic allowed by default\r\n[    3.142827] hpet: 3 channels of 0 reserved for per-cpu timers\r\n[    3.146952] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0\r\n[    3.150739] hpet0: 3 comparators, 64-bit 100.000000 MHz counter\r\n[    3.158750] clocksource: Switched to clocksource hyperv_clocksource_tsc_page\r\n[    3.174220] VFS: Disk quotas dquot_6.6.0\r\n[    3.179228] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\r\n[    3.187246] *** VALIDATE hugetlbfs ***\r\n[    3.192026] AppArmor: AppArmor Filesystem Enabled\r\n[    3.219047] pnp: PnP ACPI init\r\n[    3.223717] pnp 00:00: Plug and Play ACPI device, IDs PNP0501 (active)\r\n[    3.223730] pnp 00:01: Plug and Play ACPI device, IDs PNP0303 (active)\r\n[    3.223740] pnp 00:02: Plug and Play ACPI device, IDs PNP0f13 (active)\r\n[    3.223752] pnp 00:03: Plug and Play ACPI device, IDs PNP0b00 (active)\r\n[    3.223776] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved\r\n[    3.231967] system 00:04: Plug and Play ACPI device, IDs PNP0c01 (active)\r\n[    3.233085] pnp: PnP ACPI: found 5 devices\r\n[    3.239216] thermal_sys: Registered thermal governor 'fair_share'\r\n[    3.239216] thermal_sys: Registered thermal governor 'bang_bang'\r\n[    3.246465] thermal_sys: Registered thermal governor 'step_wise'\r\n[    3.253466] thermal_sys: Registered thermal governor 'user_space'\r\n[    3.260288] thermal_sys: Registered thermal governor 'power_allocator'\r\n[    3.272588] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns\r\n[    3.290125] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000\r\n[    3.299199] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000\r\n[    3.310529] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000\r\n[    3.319817] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000\r\n[    3.329332] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000\r\n[    3.338947] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000\r\n[    3.348656] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000\r\n[    3.358086] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000\r\n[    3.367529] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000\r\n[    3.377195] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000\r\n[    3.386434] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]\r\n[    3.393467] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]\r\n[    3.400839] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]\r\n[    3.407848] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]\r\n[    3.414812] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]\r\n[    3.422389] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]\r\n[    3.429309] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]\r\n[    3.436428] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]\r\n[    3.443479] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]\r\n[    3.460804] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]\r\n[    3.468378] pci 0000:00:01.0: PCI bridge to [bus 01]\r\n[    3.474319] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]\r\n[    3.483078] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]\r\n[    3.493353] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    3.503326] pci 0000:00:01.1: PCI bridge to [bus 02]\r\n[    3.509930] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]\r\n[    3.518615] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]\r\n[    3.528686] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    3.539461] pci 0000:00:01.2: PCI bridge to [bus 03]\r\n[    3.547144] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]\r\n[    3.558878] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]\r\n[    3.568182] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    3.579741] pci 0000:00:01.3: PCI bridge to [bus 04]\r\n[    3.585666] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]\r\n[    3.594155] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]\r\n[    3.602830] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    3.613430] pci 0000:00:01.4: PCI bridge to [bus 05]\r\n[    3.619769] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]\r\n[    3.628125] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]\r\n[    3.636681] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    3.646996] pci 0000:00:01.5: PCI bridge to [bus 06]\r\n[    3.653274] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]\r\n[    3.661233] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]\r\n[    3.670173] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    3.680220] pci 0000:00:01.6: PCI bridge to [bus 07]\r\n[    3.686488] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]\r\n[    3.694663] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]\r\n[    3.703240] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    3.713267] pci 0000:00:01.7: PCI bridge to [bus 08]\r\n[    3.719215] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]\r\n[    3.727401] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]\r\n[    3.736152] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    3.746803] pci 0000:00:02.0: PCI bridge to [bus 09]\r\n[    3.753114] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]\r\n[    3.760882] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]\r\n[    3.769529] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    3.781525] pci 0000:00:02.1: PCI bridge to [bus 0a]\r\n[    3.787782] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]\r\n[    3.795692] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]\r\n[    3.804438] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    3.814817] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]\r\n[    3.821920] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]\r\n[    3.829417] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]\r\n[    3.837336] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]\r\n[    3.845299] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]\r\n[    3.853042] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]\r\n[    3.861053] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]\r\n[    3.867426] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]\r\n[    3.874881] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]\r\n[    3.882877] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]\r\n[    3.890160] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]\r\n[    3.897861] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]\r\n[    3.906097] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]\r\n[    3.912607] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]\r\n[    3.919997] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]\r\n[    3.928305] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]\r\n[    3.934978] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]\r\n[    3.942377] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]\r\n[    3.950379] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]\r\n[    3.957050] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]\r\n[    3.964279] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]\r\n[    3.972602] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]\r\n[    3.979143] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]\r\n[    3.986664] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]\r\n[    3.994727] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]\r\n[    4.001328] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]\r\n[    4.008564] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]\r\n[    4.017124] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]\r\n[    4.023517] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]\r\n[    4.030528] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]\r\n[    4.042384] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]\r\n[    4.048884] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]\r\n[    4.056027] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]\r\n[    4.064155] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]\r\n[    4.070574] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]\r\n[    4.077802] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]\r\n[    4.086329] NET: Registered protocol family 2\r\n[    4.091775] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)\r\n[    4.101112] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r\n[    4.109449] TCP bind hash table entries: 1024 (order: 2, 16384 bytes, linear)\r\n[    4.117450] TCP: Hash tables configured (established 1024 bind 1024)\r\n[    4.124820] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    4.132179] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)\r\n[    4.139970] NET: Registered protocol family 1\r\n[    4.145287] NET: Registered protocol family 44\r\n[    4.152404] PCI: CLS 0 bytes, default 64\r\n[    4.157442] Trying to unpack rootfs image as initramfs...\r\n[    4.247510] Freeing initrd memory: 6396K\r\n[    4.255920] check: Scanning for low memory corruption every 60 seconds\r\n[    4.264234] Initialise system trusted keyrings\r\n[    4.269882] Key type blacklist registered\r\n[    4.274886] workingset: timestamp_bits=36 max_order=15 bucket_order=0\r\n[    4.282990] zbud: loaded\r\n[    4.286782] squashfs: version 4.0 (2009/01/31) Phillip Lougher\r\n[    4.293788] fuse: init (API version 7.31)\r\n[    4.298856] Platform Keyring initialized\r\n[    4.307164] Key type asymmetric registered\r\n[    4.312160] Asymmetric key parser 'x509' registered\r\n[    4.317992] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 244)\r\n[    4.326243] io scheduler mq-deadline registered\r\n[    4.332012] PCI Interrupt Link [GSIF] enabled at IRQ 21\r\n[    4.343931] pcieport 0000:00:01.0: PME: Signaling with IRQ 24\r\n[    4.352995] pcieport 0000:00:01.0: AER: enabled with IRQ 24\r\n[    4.368964] pcieport 0000:00:01.1: PME: Signaling with IRQ 25\r\n[    4.377813] pcieport 0000:00:01.1: AER: enabled with IRQ 25\r\n[    4.394346] pcieport 0000:00:01.2: PME: Signaling with IRQ 26\r\n[    4.402636] pcieport 0000:00:01.2: AER: enabled with IRQ 26\r\n[    4.419432] pcieport 0000:00:01.3: PME: Signaling with IRQ 27\r\n[    4.428544] pcieport 0000:00:01.3: AER: enabled with IRQ 27\r\n[    4.451508] pcieport 0000:00:01.4: PME: Signaling with IRQ 28\r\n[    4.465609] pcieport 0000:00:01.4: AER: enabled with IRQ 28\r\n[    4.481355] pcieport 0000:00:01.5: PME: Signaling with IRQ 29\r\n[    4.490292] pcieport 0000:00:01.5: AER: enabled with IRQ 29\r\n[    4.506496] pcieport 0000:00:01.6: PME: Signaling with IRQ 30\r\n[    4.515198] pcieport 0000:00:01.6: AER: enabled with IRQ 30\r\n[    4.531949] pcieport 0000:00:01.7: PME: Signaling with IRQ 31\r\n[    4.541370] pcieport 0000:00:01.7: AER: enabled with IRQ 31\r\n[    4.551728] PCI Interrupt Link [GSIG] enabled at IRQ 22\r\n[    4.564212] pcieport 0000:00:02.0: PME: Signaling with IRQ 32\r\n[    4.574483] pcieport 0000:00:02.0: AER: enabled with IRQ 32\r\n[    4.590979] pcieport 0000:00:02.1: PME: Signaling with IRQ 33\r\n[    4.599834] pcieport 0000:00:02.1: AER: enabled with IRQ 33\r\n[    4.610300] shpchp: Standard Hot Plug PCI Controller Driver version: 0.4\r\n[    4.617828] intel_idle: does not run on family 6 model 207\r\n[    4.617873] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0\r\n[    4.626289] ACPI: Power Button [PWRF]\r\n[    4.775399] Serial: 8250/16550 driver, 32 ports, IRQ sharing enabled\r\n[    4.828058] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\r\n[    5.113742] Linux agpgart interface v0.103\r\n[    5.123381] loop: module loaded\r\n[    5.127809] libphy: Fixed MDIO Bus: probed\r\n[    5.132796] tun: Universal TUN/TAP device driver, 1.6\r\n[    5.138740] PPP generic driver version 2.4.2\r\n[    5.143983] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver\r\n[    5.151330] ehci-pci: EHCI PCI platform driver\r\n[    5.156600] ehci-platform: EHCI generic platform driver\r\n[    5.162725] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver\r\n[    5.169801] ohci-pci: OHCI PCI platform driver\r\n[    5.175248] ohci-platform: OHCI generic platform driver\r\n[    5.181288] uhci_hcd: USB Universal Host Controller Interface driver\r\n[    5.188672] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\r\n[    5.208670] serio: i8042 KBD port at 0x60,0x64 irq 1\r\n[    5.214564] serio: i8042 AUX port at 0x60,0x64 irq 12\r\n[    5.220593] mousedev: PS/2 mouse device common for all mice\r\n[    5.228628] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1\r\n[    5.238336] rtc_cmos 00:03: RTC can wake from S4\r\n[    5.250466] rtc_cmos 00:03: registered as rtc0\r\n[    5.255937] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs\r\n[    5.265136] i2c /dev entries driver\r\n[    5.269612] device-mapper: uevent: version 1.0.3\r\n[    5.275186] device-mapper: ioctl: 4.40.0-ioctl (2019-01-18) initialised: dm-devel@redhat.com\r\n[    5.284969] platform eisa.0: Probing EISA bus 0\r\n[    5.290503] platform eisa.0: EISA: Cannot allocate resource for mainboard\r\n[    5.298184] platform eisa.0: Cannot allocate resource for EISA slot 1\r\n[    5.305623] platform eisa.0: Cannot allocate resource for EISA slot 2\r\n[    5.312919] platform eisa.0: Cannot allocate resource for EISA slot 3\r\n[    5.320451] platform eisa.0: Cannot allocate resource for EISA slot 4\r\n[    5.327747] platform eisa.0: Cannot allocate resource for EISA slot 5\r\n[    5.335077] platform eisa.0: Cannot allocate resource for EISA slot 6\r\n[    5.342315] platform eisa.0: Cannot allocate resource for EISA slot 7\r\n[    5.349603] platform eisa.0: Cannot allocate resource for EISA slot 8\r\n[    5.356792] platform eisa.0: EISA: Detected 0 cards\r\n[    5.362544] intel_pstate: CPU model not supported\r\n[    5.368285] ledtrig-cpu: registered to indicate activity on CPUs\r\n[    5.375270] NET: Registered protocol family 10\r\n[    5.383613] Segment Routing with IPv6\r\n[    5.388214] NET: Registered protocol family 17\r\n[    5.393707] Key type dns_resolver registered\r\n[    5.399296] RAS: Correctable Errors collector initialized.\r\n[    5.405646] registered taskstats version 1\r\n[    5.411102] Loading compiled-in X.509 certificates\r\n[    5.417754] Loaded X.509 cert 'Build time autogenerated kernel key: 8098f9b3401d48cb244b138af0c5bac131caef8a'\r\n[    5.428832] zswap: loaded using pool lzo/zbud\r\n[    5.436792] Key type big_key registered\r\n[    5.443458] Key type encrypted registered\r\n[    5.448344] AppArmor: AppArmor sha1 policy hashing enabled\r\n[    5.454690] ima: No TPM chip found, activating TPM-bypass!\r\n[    5.465021] ima: Allocated hash algorithm: sha1\r\n[    5.471181] No architecture policies found\r\n[    5.476343] evm: Initialising EVM extended attributes:\r\n[    5.482416] evm: security.selinux\r\n[    5.486636] evm: security.SMACK64\r\n[    5.490967] evm: security.SMACK64EXEC\r\n[    5.495585] evm: security.SMACK64TRANSMUTE\r\n[    5.500609] evm: security.SMACK64MMAP\r\n[    5.506682] evm: security.apparmor\r\n[    5.511176] evm: security.ima\r\n[    5.515108] evm: security.capability\r\n[    5.519628] evm: HMAC attrs: 0x1\r\n[    5.525304] PM:   Magic number: 1:476:554\r\n[    5.530243] acpi PNP0C0F:05: hash matches\r\n[    5.535231] acpi PNP0C01:00: hash matches\r\n[    5.541115] rtc_cmos 00:03: setting system clock to 2025-11-07T23:32:54 UTC (1762558374)\r\n[    5.550123] Unstable clock detected, switching default tracing clock to \"global\"\r\n               If you want to keep using the local clock, then add:\r\n                 \"trace_clock=local\"\r\n               on the kernel command line\r\n[    5.581609] Freeing unused decrypted memory: 2040K\r\n[    5.588031] Freeing unused kernel image memory: 2660K\r\n[    5.594122] Write protecting the kernel read-only data: 22528k\r\n[    5.602238] Freeing unused kernel image memory: 2008K\r\n[    5.608412] Freeing unused kernel image memory: 1476K\r\n[    5.619736] x86/mm: Checked W+X mappings: passed, no W+X pages found.\r\n[    5.627091] Run /init as init process\r\n[    5.648471] e1000: Intel(R) PRO/1000 Network Driver - version 7.3.21-k8-NAPI\r\n[    5.648472] e1000: Copyright (c) 1999-2006 Intel Corporation.\r\n[    5.650353] ne2k-pci.c:v1.03 9/22/2003 D. Becker/P. Gortmaker\r\n[    5.653866] pcnet32: pcnet32.c:v1.35 21.Apr.2008 tsbogend@alpha.franken.de\r\n[    5.656260] 9pnet: Installing 9P2000 support\r\n[    5.767539] virtio_blk virtio3: [vda] 229376 512-byte logical blocks (117 MB/112 MiB)\r\n[    5.781915]  vda: vda1 vda15\r\n[    5.800889] virtio_blk virtio4: [vdb] 2048 512-byte logical blocks (1.05 MB/1.00 MiB)\r\n[    5.872277] scsi host0: Virtio SCSI HBA\r\n[    5.909275] hidraw: raw HID events driver (C) Jiri Kosina\r\n[    5.910108] usbcore: registered new interface driver usbhid\r\n[    5.910109] usbhid: USB HID core driver\r\n[    5.919941] ahci 0000:00:1f.2: version 3.0\r\n[    5.920502] PCI Interrupt Link [GSIA] enabled at IRQ 16\r\n[    5.932220] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode\r\n[    5.932221] ahci 0000:00:1f.2: flags: 64bit ncq only \r\n[    5.944900] scsi host1: ahci\r\n[    5.944946] scsi host2: ahci\r\n[    5.944984] scsi host3: ahci\r\n[    5.945016] scsi host4: ahci\r\n[    5.945051] scsi host5: ahci\r\n[    5.945085] scsi host6: ahci\r\n[    5.945254] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 49\r\n[    5.945393] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 49\r\n[    5.945558] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 49\r\n[    5.945699] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 49\r\n[    5.945830] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 49\r\n[    5.945964] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 49\r\n[    6.262477] ata2: SATA link down (SStatus 0 SControl 300)\r\n[    6.266434] ata1: SATA link down (SStatus 0 SControl 300)\r\n[    6.270321] ata3: SATA link down (SStatus 0 SControl 300)\r\n[    6.274383] ata4: SATA link down (SStatus 0 SControl 300)\r\n[    6.278151] ata5: SATA link down (SStatus 0 SControl 300)\r\n[    6.282013] ata6: SATA link down (SStatus 0 SControl 300)\r\n[    6.329634] EXT4-fs (vda1): mounting ext3 file system using the ext4 subsystem\r\n[    6.332577] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)\r\n[    6.334781] EXT4-fs (vda1): mounting ext3 file system using the ext4 subsystem\r\n[    6.349983] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)\r\n[    6.484299] EXT4-fs (vda1): re-mounted. Opts: (null)\r\n[    6.504463] EXT4-fs (vda1): re-mounted. Opts: (null)\r\n[    6.590429] ISO 9660 Extensions: Microsoft Joliet Level 3\r\n[    6.591050] ISO 9660 Extensions: RRIP_1991A\r\n[    6.866747] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready\r\n[    6.954983] EXT4-fs (vda1): resizing filesystem from 25600 to 26363 blocks\r\n[    6.954992] EXT4-fs (vda1): resized filesystem to 26363\r\n" "" "$ "] Buffer: dmesg
[    0.000000] Linux version 5.3.0-26-generic (buildd@lgw01-amd64-039) (gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1)) #28~18.04.1-Ubuntu SMP Wed Dec 18 16:40:14 UTC 2019 (Ubuntu 5.3.0-26.28~18.04.1-generic 5.3.13)
[    0.000000] Command line: LABEL=cirros-rootfs ro console=tty1 console=ttyS0
[    0.000000] KERNEL supported cpus:
[    0.000000]   Intel GenuineIntel
[    0.000000]   AMD AuthenticAMD
[    0.000000]   Hygon HygonGenuine
[    0.000000]   Centaur CentaurHauls
[    0.000000]   zhaoxin   Shanghai  
[    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format.
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007fdcfff] usable
[    0.000000] BIOS-e820: [mem 0x0000000007fdd000-0x0000000007ffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved
[    0.000000] BIOS-e820: [mem 0x000000fd00000000-0x000000ffffffffff] reserved
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] SMBIOS 2.8 present.
[    0.000000] DMI: KubeVirt None, BIOS rel-1.17.0-0-gb52ca86e094d-prebuilt.qemu.org 04/01/2014
[    0.000000] Hypervisor detected: Microsoft Hyper-V
[    0.000000] Hyper-V: features 0xe7e, hints 0x60624
[    0.000000] Hyper-V Host Build:26100-10.0-1-0.1381
[    0.000000] Hyper-V: LAPIC Timer Frequency: 0xc3500
[    0.000000] tsc: Marking TSC unstable due to running on Hyper-V
[    0.000000] Hyper-V: Using hypercall for remote TLB flush
[    0.000000] tsc: Detected 2299.999 MHz processor
[    0.000713] e820: update [mem 0x00000000-0x00000fff] usable ==&gt; reserved
[    0.000714] e820: remove [mem 0x000a0000-0x000fffff] usable
[    0.000716] last_pfn = 0x7fdd max_arch_pfn = 0x400000000
[    0.000741] MTRR default type: write-back
[    0.000742] MTRR fixed ranges enabled:
[    0.000742]   00000-9FFFF write-back
[    0.000743]   A0000-BFFFF uncachable
[    0.000744]   C0000-FFFFF write-protect
[    0.000744] MTRR variable ranges enabled:
[    0.000745]   0 base 0000C0000000 mask FFFFC0000000 uncachable
[    0.000745]   1 disabled
[    0.000746]   2 disabled
[    0.000746]   3 disabled
[    0.000746]   4 disabled
[    0.000747]   5 disabled
[    0.000747]   6 disabled
[    0.000747]   7 disabled
[    0.000754] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  
[    0.003905] found SMP MP-table at [mem 0x000f5470-0x000f547f]
[    0.003961] check: Scanning 1 areas for low memory corruption
[    0.004456] Using GB pages for direct mapping
[    0.004461] BRK [0x05e01000, 0x05e01fff] PGTABLE
[    0.004462] BRK [0x05e02000, 0x05e02fff] PGTABLE
[    0.004463] BRK [0x05e03000, 0x05e03fff] PGTABLE
[    0.004494] BRK [0x05e04000, 0x05e04fff] PGTABLE
[    0.004592] BRK [0x05e05000, 0x05e05fff] PGTABLE
[    0.004622] RAMDISK: [mem 0x0798e000-0x07fccfff]
[    0.004775] ACPI: Early table checksum verification disabled
[    0.004778] ACPI: RSDP 0x00000000000F51E0 000014 (v00 BOCHS )
[    0.004781] ACPI: RSDT 0x0000000007FE2B67 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004785] ACPI: FACP 0x0000000007FE2947 0000F4 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004788] ACPI: DSDT 0x0000000007FE0040 002907 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004790] ACPI: FACS 0x0000000007FE0000 000040
[    0.004792] ACPI: APIC 0x0000000007FE2A3B 000090 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004794] ACPI: HPET 0x0000000007FE2ACB 000038 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004795] ACPI: MCFG 0x0000000007FE2B03 00003C (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004797] ACPI: WAET 0x0000000007FE2B3F 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.004802] ACPI: Local APIC address 0xfee00000
[    0.010519] No NUMA configuration found
[    0.010521] Faking a node at [mem 0x0000000000000000-0x0000000007fdcfff]
[    0.010528] NODE_DATA(0) allocated [mem 0x07963000-0x0798dfff]
[    0.010681] Zone ranges:
[    0.010682]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.010683]   DMA32    [mem 0x0000000001000000-0x0000000007fdcfff]
[    0.010683]   Normal   empty
[    0.010684]   Device   empty
[    0.010685] Movable zone start for each node
[    0.010688] Early memory node ranges
[    0.010689]   node   0: [mem 0x0000000000001000-0x000000000009efff]
[    0.010689]   node   0: [mem 0x0000000000100000-0x0000000007fdcfff]
[    0.011713] Zeroed struct page in unavailable ranges: 98 pages
[    0.011715] Initmem setup node 0 [mem 0x0000000000001000-0x0000000007fdcfff]
[    0.011718] On node 0 totalpages: 32635
[    0.011719]   DMA zone: 64 pages used for memmap
[    0.011720]   DMA zone: 21 pages reserved
[    0.011720]   DMA zone: 3998 pages, LIFO batch:0
[    0.011753]   DMA32 zone: 448 pages used for memmap
[    0.011754]   DMA32 zone: 28637 pages, LIFO batch:7
[    0.030250] ACPI: PM-Timer IO Port: 0x608
[    0.030254] ACPI: Local APIC address 0xfee00000
[    0.030262] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])
[    0.032018] IOAPIC[0]: apic_id 0, version 32, address 0xfec00000, GSI 0-23
[    0.032020] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
[    0.032022] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)
[    0.032022] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.032023] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)
[    0.032024] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)
[    0.032025] ACPI: IRQ0 used by override.
[    0.032026] ACPI: IRQ5 used by override.
[    0.032026] ACPI: IRQ9 used by override.
[    0.032026] ACPI: IRQ10 used by override.
[    0.032027] ACPI: IRQ11 used by override.
[    0.032028] Using ACPI (MADT) for SMP configuration information
[    0.032030] ACPI: HPET id: 0x8086a201 base: 0xfed00000
[    0.032033] smpboot: Allowing 4 CPUs, 3 hotplug CPUs
[    0.032041] PM: Registered nosave memory: [mem 0x00000000-0x00000fff]
[    0.032042] PM: Registered nosave memory: [mem 0x0009f000-0x0009ffff]
[    0.032042] PM: Registered nosave memory: [mem 0x000a0000-0x000effff]
[    0.032043] PM: Registered nosave memory: [mem 0x000f0000-0x000fffff]
[    0.032044] [mem 0x08000000-0xafffffff] available for PCI devices
[    0.032045] Booting paravirtualized kernel on bare hardware
[    0.032048] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645519600211568 ns
[    0.032051] setup_percpu: NR_CPUS:8192 nr_cpumask_bits:4 nr_cpu_ids:4 nr_node_ids:1
[    0.032771] percpu: Embedded 54 pages/cpu s184320 r8192 d28672 u524288
[    0.032776] pcpu-alloc: s184320 r8192 d28672 u524288 alloc=1*2097152
[    0.032776] pcpu-alloc: [0] 0 1 2 3 
[    0.032788] Hyper-V: PV spinlocks enabled
[    0.032790] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)
[    0.032793] Built 1 zonelists, mobility grouping on.  Total pages: 32102
[    0.032794] Policy zone: DMA32
[    0.032795] Kernel command line: LABEL=cirros-rootfs ro console=tty1 console=ttyS0
[    0.032826] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)
[    0.032832] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)
[    0.032875] mem auto-init: stack:off, heap alloc:on, heap free:off
[    0.032878] Calgary: detecting Calgary via BIOS EBDA area
[    0.032879] Calgary: Unable to locate Rio Grande table in EBDA - bailing!
[    0.033093] Memory: 87908K/130540K available (14339K kernel code, 2370K rwdata, 4668K rodata, 2660K init, 5076K bss, 42632K reserved, 0K cma-reserved)
[    0.033168] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1
[    0.033177] ftrace: allocating 42927 entries in 168 pages
[    0.048856] rcu: Hierarchical RCU implementation.
[    0.048858] rcu: 	RCU restricting CPUs from NR_CPUS=8192 to nr_cpu_ids=4.
[    0.048859] 	Tasks RCU enabled.
[    0.048860] rcu: RCU calculated value of scheduler-enlistment delay is 25 jiffies.
[    0.048861] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4
[    0.051062] NR_IRQS: 524544, nr_irqs: 456, preallocated irqs: 16
[    0.058275] random: crng done (trusting CPU's manufacturer)
[    0.059854] Console: colour *CGA 80x25
[    0.149532] printk: console [tty1] enabled
[    0.890239] printk: console [ttyS0] enabled
[    0.895949] ACPI: Core revision 20190703
[    0.903912] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns
[    0.916556] APIC: Switch to symmetric I/O mode setup
[    0.938387] x2apic enabled
[    0.942570] Switched APIC routing to physical x2apic.
[    0.948618] Hyper-V: Using IPI hypercalls
[    0.953648] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    1.034221] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
[    1.042741] Calibrating delay loop (skipped), value calculated using timer frequency.. 4599.99 BogoMIPS (lpj=9199996)
[    1.046743] pid_max: default: 32768 minimum: 301
[    1.050765] LSM: Security Framework initializing
[    1.054746] Yama: becoming mindful.
[    1.058766] AppArmor: AppArmor initialized
[    1.062764] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[    1.066742] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[    1.070851] *** VALIDATE proc ***
[    1.074779] *** VALIDATE cgroup1 ***
[    1.078740] *** VALIDATE cgroup2 ***
[    1.082828] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    1.086757] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
[    1.090739] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
[    1.094742] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
[    1.098740] Spectre V2 : Mitigation: Full generic retpoline
[    1.102739] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
[    1.106740] Speculative Store Bypass: Vulnerable
[    1.117463] smpboot: CPU0: Intel INTEL(R) XEON(R) PLATINUM 8573C (family: 0x6, model: 0xcf, stepping: 0x2)
[    1.118828] Performance Events: unsupported p6 CPU model 207 no PMU driver, software events only.
[    1.122765] rcu: Hierarchical SRCU implementation.
[    1.126896] NMI watchdog: Perf NMI watchdog permanently disabled
[    1.130797] smp: Bringing up secondary CPUs ...
[    1.134741] smp: Brought up 1 node, 1 CPU
[    1.138739] smpboot: Max logical packages: 4
[    1.142739] smpboot: Total of 1 processors activated (4599.99 BogoMIPS)
[    1.146849] devtmpfs: initialized
[    1.150820] x86/mm: Memory block size: 128MB
[    1.154865] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns
[    1.158750] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)
[    1.162789] pinctrl core: initialized pinctrl subsystem
[    1.167542] PM: RTC time: 23:32:49, date: 2025-11-07
[    1.170814] NET: Registered protocol family 16
[    1.174781] audit: initializing netlink subsys (disabled)
[    1.178831] EISA bus registered
[    1.182741] audit: type=2000 audit(1762558368.136:1): state=initialized audit_enabled=0 res=1
[    1.186740] cpuidle: using governor ladder
[    1.190742] cpuidle: using governor menu
[    1.194768] ACPI: bus type PCI registered
[    1.198739] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
[    1.203439] PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0xb0000000-0xbfffffff] (base 0xb0000000)
[    1.206740] PCI: MMCONFIG at [mem 0xb0000000-0xbfffffff] reserved in E820
[    1.210746] PCI: Using configuration type 1 for base access
[    1.215631] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
[    1.218741] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
[    1.223723] ACPI: Added _OSI(Module Device)
[    1.226743] ACPI: Added _OSI(Processor Device)
[    1.230740] ACPI: Added _OSI(3.0 _SCP Extensions)
[    1.234740] ACPI: Added _OSI(Processor Aggregator Device)
[    1.238755] ACPI: Added _OSI(Linux-Dell-Video)
[    1.242849] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
[    1.246745] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
[    1.255743] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    1.263853] ACPI: Interpreter enabled
[    1.266748] ACPI: (supports S0 S3 S4 S5)
[    1.270739] ACPI: Using IOAPIC for interrupt routing
[    1.274762] PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
[    1.278948] ACPI: Enabled 2 GPEs in block 00 to 3F
[    1.287885] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])
[    1.290745] acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI HPX-Type3]
[    1.294832] acpi PNP0A08:00: _OSC: platform does not support [PCIeHotplug LTR]
[    1.298817] acpi PNP0A08:00: _OSC: OS now controls [SHPCHotplug PME AER PCIeCapability]
[    1.304019] PCI host bridge to bus 0000:00
[    1.306741] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]
[    1.310741] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]
[    1.314742] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]
[    1.318739] pci_bus 0000:00: root bus resource [mem 0x08000000-0xafffffff window]
[    1.322741] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window]
[    1.326740] pci_bus 0000:00: root bus resource [mem 0x100000000-0x8ffffffff window]
[    1.330741] pci_bus 0000:00: root bus resource [bus 00-ff]
[    1.335090] pci 0000:00:00.0: [8086:29c0] type 00 class 0x060000
[    1.351040] pci 0000:00:01.0: [1b36:000c] type 01 class 0x060400
[    1.362626] pci 0000:00:01.0: reg 0x10: [mem 0xfd600000-0xfd600fff]
[    1.368756] pci 0000:00:01.0: enabling Extended Tags
[    1.378985] pci 0000:00:01.1: [1b36:000c] type 01 class 0x060400
[    1.387312] pci 0000:00:01.1: reg 0x10: [mem 0xfd601000-0xfd601fff]
[    1.396403] pci 0000:00:01.1: enabling Extended Tags
[    1.406935] pci 0000:00:01.2: [1b36:000c] type 01 class 0x060400
[    1.416685] pci 0000:00:01.2: reg 0x10: [mem 0xfd602000-0xfd602fff]
[    1.425932] pci 0000:00:01.2: enabling Extended Tags
[    1.436352] pci 0000:00:01.3: [1b36:000c] type 01 class 0x060400
[    1.441905] pci 0000:00:01.3: reg 0x10: [mem 0xfd603000-0xfd603fff]
[    1.450822] pci 0000:00:01.3: enabling Extended Tags
[    1.465426] pci 0000:00:01.4: [1b36:000c] type 01 class 0x060400
[    1.472157] pci 0000:00:01.4: reg 0x10: [mem 0xfd604000-0xfd604fff]
[    1.480476] pci 0000:00:01.4: enabling Extended Tags
[    1.491154] pci 0000:00:01.5: [1b36:000c] type 01 class 0x060400
[    1.501203] pci 0000:00:01.5: reg 0x10: [mem 0xfd605000-0xfd605fff]
[    1.509370] pci 0000:00:01.5: enabling Extended Tags
[    1.520090] pci 0000:00:01.6: [1b36:000c] type 01 class 0x060400
[    1.532092] pci 0000:00:01.6: reg 0x10: [mem 0xfd606000-0xfd606fff]
[    1.560400] pci 0000:00:01.6: enabling Extended Tags
[    1.574610] pci 0000:00:01.7: [1b36:000c] type 01 class 0x060400
[    1.580552] pci 0000:00:01.7: reg 0x10: [mem 0xfd607000-0xfd607fff]
[    1.589137] pci 0000:00:01.7: enabling Extended Tags
[    1.600179] pci 0000:00:02.0: [1b36:000c] type 01 class 0x060400
[    1.608972] pci 0000:00:02.0: reg 0x10: [mem 0xfd608000-0xfd608fff]
[    1.616858] pci 0000:00:02.0: enabling Extended Tags
[    1.628922] pci 0000:00:02.1: [1b36:000c] type 01 class 0x060400
[    1.635149] pci 0000:00:02.1: reg 0x10: [mem 0xfd609000-0xfd609fff]
[    1.644353] pci 0000:00:02.1: enabling Extended Tags
[    1.666218] pci 0000:00:1f.0: [8086:2918] type 00 class 0x060100
[    1.674438] pci 0000:00:1f.0: quirk: [io  0x0600-0x067f] claimed by ICH6 ACPI/GPIO/TCO
[    1.676586] pci 0000:00:1f.2: [8086:2922] type 00 class 0x010601
[    1.689617] pci 0000:00:1f.2: reg 0x20: [io  0xc040-0xc05f]
[    1.691931] pci 0000:00:1f.2: reg 0x24: [mem 0xfd60a000-0xfd60afff]
[    1.702536] pci 0000:00:1f.3: [8086:2930] type 00 class 0x0c0500
[    1.711658] pci 0000:00:1f.3: reg 0x20: [io  0x0700-0x073f]
[    1.723868] acpiphp: Slot [0] registered
[    1.728565] pci 0000:01:00.0: [1af4:1041] type 00 class 0x020000
[    1.737640] pci 0000:01:00.0: reg 0x14: [mem 0xfd400000-0xfd400fff]
[    1.744934] pci 0000:01:00.0: reg 0x20: [mem 0xfea00000-0xfea03fff 64bit pref]
[    1.751919] pci 0000:01:00.0: enabling Extended Tags
[    1.774766] pci 0000:00:01.0: PCI bridge to [bus 01]
[    1.779067] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    1.783081] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    1.792003] acpiphp: Slot [0-2] registered
[    1.803026] pci 0000:00:01.1: PCI bridge to [bus 02]
[    1.807097] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    1.811061] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    1.821097] acpiphp: Slot [0-3] registered
[    1.832235] pci 0000:00:01.2: PCI bridge to [bus 03]
[    1.835074] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    1.839096] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    1.845248] acpiphp: Slot [0-4] registered
[    1.852839] pci 0000:00:01.3: PCI bridge to [bus 04]
[    1.858923] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    1.863080] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    1.869196] acpiphp: Slot [0-5] registered
[    1.872105] pci 0000:05:00.0: [1af4:1048] type 00 class 0x010000
[    1.879398] pci 0000:05:00.0: reg 0x14: [mem 0xfcc00000-0xfcc00fff]
[    1.887191] pci 0000:05:00.0: reg 0x20: [mem 0xfe200000-0xfe203fff 64bit pref]
[    1.892637] pci 0000:05:00.0: enabling Extended Tags
[    1.914840] pci 0000:00:01.4: PCI bridge to [bus 05]
[    1.919086] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    1.923089] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    1.932150] acpiphp: Slot [0-6] registered
[    1.938739] pci 0000:06:00.0: [1af4:1043] type 00 class 0x078000
[    1.949752] pci 0000:06:00.0: reg 0x14: [mem 0xfca00000-0xfca00fff]
[    1.957581] pci 0000:06:00.0: reg 0x20: [mem 0xfe000000-0xfe003fff 64bit pref]
[    1.964033] pci 0000:06:00.0: enabling Extended Tags
[    1.983730] pci 0000:00:01.5: PCI bridge to [bus 06]
[    1.987089] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    1.991090] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    2.000881] acpiphp: Slot [0-7] registered
[    2.007407] pci 0000:07:00.0: [1af4:1042] type 00 class 0x010000
[    2.031828] pci 0000:07:00.0: reg 0x14: [mem 0xfc800000-0xfc800fff]
[    2.060875] pci 0000:07:00.0: reg 0x20: [mem 0xfde00000-0xfde03fff 64bit pref]
[    2.073062] pci 0000:07:00.0: enabling Extended Tags
[    2.092279] pci 0000:00:01.6: PCI bridge to [bus 07]
[    2.095065] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    2.099072] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    2.105239] acpiphp: Slot [0-8] registered
[    2.108126] pci 0000:08:00.0: [1af4:1042] type 00 class 0x010000
[    2.115338] pci 0000:08:00.0: reg 0x14: [mem 0xfc600000-0xfc600fff]
[    2.127137] pci 0000:08:00.0: reg 0x20: [mem 0xfdc00000-0xfdc03fff 64bit pref]
[    2.132609] pci 0000:08:00.0: enabling Extended Tags
[    2.166289] pci 0000:00:01.7: PCI bridge to [bus 08]
[    2.167052] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    2.171070] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    2.180442] acpiphp: Slot [0-9] registered
[    2.187088] pci 0000:09:00.0: [1af4:1045] type 00 class 0x00ff00
[    2.198740] pci 0000:09:00.0: reg 0x14: [mem 0xfc400000-0xfc400fff]
[    2.207900] pci 0000:09:00.0: reg 0x20: [mem 0xfda00000-0xfda03fff 64bit pref]
[    2.212867] pci 0000:09:00.0: enabling Extended Tags
[    2.233961] pci 0000:00:02.0: PCI bridge to [bus 09]
[    2.235085] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    2.239091] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    2.247134] acpiphp: Slot [0-10] registered
[    2.258352] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    2.259096] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    2.263084] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    2.279584] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11)
[    2.283091] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11)
[    2.287099] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11)
[    2.291115] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11)
[    2.295096] ACPI: PCI Interrupt Link [LNKE] (IRQs 5 *10 11)
[    2.302752] ACPI: PCI Interrupt Link [LNKF] (IRQs 5 *10 11)
[    2.307120] ACPI: PCI Interrupt Link [LNKG] (IRQs 5 10 *11)
[    2.311103] ACPI: PCI Interrupt Link [LNKH] (IRQs 5 10 *11)
[    2.314908] ACPI: PCI Interrupt Link [GSIA] (IRQs *16)
[    2.318750] ACPI: PCI Interrupt Link [GSIB] (IRQs *17)
[    2.322745] ACPI: PCI Interrupt Link [GSIC] (IRQs *18)
[    2.326752] ACPI: PCI Interrupt Link [GSID] (IRQs *19)
[    2.330746] ACPI: PCI Interrupt Link [GSIE] (IRQs *20)
[    2.334746] ACPI: PCI Interrupt Link [GSIF] (IRQs *21)
[    2.338745] ACPI: PCI Interrupt Link [GSIG] (IRQs *22)
[    2.342745] ACPI: PCI Interrupt Link [GSIH] (IRQs *23)
[    2.347692] SCSI subsystem initialized
[    2.350759] libata version 3.00 loaded.
[    2.350782] vgaarb: loaded
[    2.354751] ACPI: bus type USB registered
[    2.358750] usbcore: registered new interface driver usbfs
[    2.362745] usbcore: registered new interface driver hub
[    2.366747] usbcore: registered new device driver usb
[    2.370767] pps_core: LinuxPPS API ver. 1 registered
[    2.374739] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti &lt;giometti@linux.it&gt;
[    2.378740] PTP clock support registered
[    2.382774] EDAC MC: Ver: 3.0.0
[    2.394633] PCI: Using ACPI for IRQ routing
[    3.126061] PCI: pci_cache_line_size set to 64 bytes
[    3.129522] e820: reserve RAM buffer [mem 0x0009fc00-0x0009ffff]
[    3.129524] e820: reserve RAM buffer [mem 0x07fdd000-0x07ffffff]
[    3.129614] NetLabel: Initializing
[    3.130740] NetLabel:  domain hash size = 128
[    3.134739] NetLabel:  protocols = UNLABELED CIPSOv4 CALIPSO
[    3.138754] NetLabel:  unlabeled traffic allowed by default
[    3.142827] hpet: 3 channels of 0 reserved for per-cpu timers
[    3.146952] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0
[    3.150739] hpet0: 3 comparators, 64-bit 100.000000 MHz counter
[    3.158750] clocksource: Switched to clocksource hyperv_clocksource_tsc_page
[    3.174220] VFS: Disk quotas dquot_6.6.0
[    3.179228] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    3.187246] *** VALIDATE hugetlbfs ***
[    3.192026] AppArmor: AppArmor Filesystem Enabled
[    3.219047] pnp: PnP ACPI init
[    3.223717] pnp 00:00: Plug and Play ACPI device, IDs PNP0501 (active)
[    3.223730] pnp 00:01: Plug and Play ACPI device, IDs PNP0303 (active)
[    3.223740] pnp 00:02: Plug and Play ACPI device, IDs PNP0f13 (active)
[    3.223752] pnp 00:03: Plug and Play ACPI device, IDs PNP0b00 (active)
[    3.223776] system 00:04: [mem 0xb0000000-0xbfffffff window] has been reserved
[    3.231967] system 00:04: Plug and Play ACPI device, IDs PNP0c01 (active)
[    3.233085] pnp: PnP ACPI: found 5 devices
[    3.239216] thermal_sys: Registered thermal governor 'fair_share'
[    3.239216] thermal_sys: Registered thermal governor 'bang_bang'
[    3.246465] thermal_sys: Registered thermal governor 'step_wise'
[    3.253466] thermal_sys: Registered thermal governor 'user_space'
[    3.260288] thermal_sys: Registered thermal governor 'power_allocator'
[    3.272588] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns
[    3.290125] pci 0000:00:01.0: bridge window [io  0x1000-0x0fff] to [bus 01] add_size 1000
[    3.299199] pci 0000:00:01.1: bridge window [io  0x1000-0x0fff] to [bus 02] add_size 1000
[    3.310529] pci 0000:00:01.2: bridge window [io  0x1000-0x0fff] to [bus 03] add_size 1000
[    3.319817] pci 0000:00:01.3: bridge window [io  0x1000-0x0fff] to [bus 04] add_size 1000
[    3.329332] pci 0000:00:01.4: bridge window [io  0x1000-0x0fff] to [bus 05] add_size 1000
[    3.338947] pci 0000:00:01.5: bridge window [io  0x1000-0x0fff] to [bus 06] add_size 1000
[    3.348656] pci 0000:00:01.6: bridge window [io  0x1000-0x0fff] to [bus 07] add_size 1000
[    3.358086] pci 0000:00:01.7: bridge window [io  0x1000-0x0fff] to [bus 08] add_size 1000
[    3.367529] pci 0000:00:02.0: bridge window [io  0x1000-0x0fff] to [bus 09] add_size 1000
[    3.377195] pci 0000:00:02.1: bridge window [io  0x1000-0x0fff] to [bus 0a] add_size 1000
[    3.386434] pci 0000:00:01.0: BAR 13: assigned [io  0x1000-0x1fff]
[    3.393467] pci 0000:00:01.1: BAR 13: assigned [io  0x2000-0x2fff]
[    3.400839] pci 0000:00:01.2: BAR 13: assigned [io  0x3000-0x3fff]
[    3.407848] pci 0000:00:01.3: BAR 13: assigned [io  0x4000-0x4fff]
[    3.414812] pci 0000:00:01.4: BAR 13: assigned [io  0x5000-0x5fff]
[    3.422389] pci 0000:00:01.5: BAR 13: assigned [io  0x6000-0x6fff]
[    3.429309] pci 0000:00:01.6: BAR 13: assigned [io  0x7000-0x7fff]
[    3.436428] pci 0000:00:01.7: BAR 13: assigned [io  0x8000-0x8fff]
[    3.443479] pci 0000:00:02.0: BAR 13: assigned [io  0x9000-0x9fff]
[    3.460804] pci 0000:00:02.1: BAR 13: assigned [io  0xa000-0xafff]
[    3.468378] pci 0000:00:01.0: PCI bridge to [bus 01]
[    3.474319] pci 0000:00:01.0:   bridge window [io  0x1000-0x1fff]
[    3.483078] pci 0000:00:01.0:   bridge window [mem 0xfd400000-0xfd5fffff]
[    3.493353] pci 0000:00:01.0:   bridge window [mem 0xfea00000-0xfebfffff 64bit pref]
[    3.503326] pci 0000:00:01.1: PCI bridge to [bus 02]
[    3.509930] pci 0000:00:01.1:   bridge window [io  0x2000-0x2fff]
[    3.518615] pci 0000:00:01.1:   bridge window [mem 0xfd200000-0xfd3fffff]
[    3.528686] pci 0000:00:01.1:   bridge window [mem 0xfe800000-0xfe9fffff 64bit pref]
[    3.539461] pci 0000:00:01.2: PCI bridge to [bus 03]
[    3.547144] pci 0000:00:01.2:   bridge window [io  0x3000-0x3fff]
[    3.558878] pci 0000:00:01.2:   bridge window [mem 0xfd000000-0xfd1fffff]
[    3.568182] pci 0000:00:01.2:   bridge window [mem 0xfe600000-0xfe7fffff 64bit pref]
[    3.579741] pci 0000:00:01.3: PCI bridge to [bus 04]
[    3.585666] pci 0000:00:01.3:   bridge window [io  0x4000-0x4fff]
[    3.594155] pci 0000:00:01.3:   bridge window [mem 0xfce00000-0xfcffffff]
[    3.602830] pci 0000:00:01.3:   bridge window [mem 0xfe400000-0xfe5fffff 64bit pref]
[    3.613430] pci 0000:00:01.4: PCI bridge to [bus 05]
[    3.619769] pci 0000:00:01.4:   bridge window [io  0x5000-0x5fff]
[    3.628125] pci 0000:00:01.4:   bridge window [mem 0xfcc00000-0xfcdfffff]
[    3.636681] pci 0000:00:01.4:   bridge window [mem 0xfe200000-0xfe3fffff 64bit pref]
[    3.646996] pci 0000:00:01.5: PCI bridge to [bus 06]
[    3.653274] pci 0000:00:01.5:   bridge window [io  0x6000-0x6fff]
[    3.661233] pci 0000:00:01.5:   bridge window [mem 0xfca00000-0xfcbfffff]
[    3.670173] pci 0000:00:01.5:   bridge window [mem 0xfe000000-0xfe1fffff 64bit pref]
[    3.680220] pci 0000:00:01.6: PCI bridge to [bus 07]
[    3.686488] pci 0000:00:01.6:   bridge window [io  0x7000-0x7fff]
[    3.694663] pci 0000:00:01.6:   bridge window [mem 0xfc800000-0xfc9fffff]
[    3.703240] pci 0000:00:01.6:   bridge window [mem 0xfde00000-0xfdffffff 64bit pref]
[    3.713267] pci 0000:00:01.7: PCI bridge to [bus 08]
[    3.719215] pci 0000:00:01.7:   bridge window [io  0x8000-0x8fff]
[    3.727401] pci 0000:00:01.7:   bridge window [mem 0xfc600000-0xfc7fffff]
[    3.736152] pci 0000:00:01.7:   bridge window [mem 0xfdc00000-0xfddfffff 64bit pref]
[    3.746803] pci 0000:00:02.0: PCI bridge to [bus 09]
[    3.753114] pci 0000:00:02.0:   bridge window [io  0x9000-0x9fff]
[    3.760882] pci 0000:00:02.0:   bridge window [mem 0xfc400000-0xfc5fffff]
[    3.769529] pci 0000:00:02.0:   bridge window [mem 0xfda00000-0xfdbfffff 64bit pref]
[    3.781525] pci 0000:00:02.1: PCI bridge to [bus 0a]
[    3.787782] pci 0000:00:02.1:   bridge window [io  0xa000-0xafff]
[    3.795692] pci 0000:00:02.1:   bridge window [mem 0xfc200000-0xfc3fffff]
[    3.804438] pci 0000:00:02.1:   bridge window [mem 0xfd800000-0xfd9fffff 64bit pref]
[    3.814817] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]
[    3.821920] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]
[    3.829417] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]
[    3.837336] pci_bus 0000:00: resource 7 [mem 0x08000000-0xafffffff window]
[    3.845299] pci_bus 0000:00: resource 8 [mem 0xc0000000-0xfebfffff window]
[    3.853042] pci_bus 0000:00: resource 9 [mem 0x100000000-0x8ffffffff window]
[    3.861053] pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]
[    3.867426] pci_bus 0000:01: resource 1 [mem 0xfd400000-0xfd5fffff]
[    3.874881] pci_bus 0000:01: resource 2 [mem 0xfea00000-0xfebfffff 64bit pref]
[    3.882877] pci_bus 0000:02: resource 0 [io  0x2000-0x2fff]
[    3.890160] pci_bus 0000:02: resource 1 [mem 0xfd200000-0xfd3fffff]
[    3.897861] pci_bus 0000:02: resource 2 [mem 0xfe800000-0xfe9fffff 64bit pref]
[    3.906097] pci_bus 0000:03: resource 0 [io  0x3000-0x3fff]
[    3.912607] pci_bus 0000:03: resource 1 [mem 0xfd000000-0xfd1fffff]
[    3.919997] pci_bus 0000:03: resource 2 [mem 0xfe600000-0xfe7fffff 64bit pref]
[    3.928305] pci_bus 0000:04: resource 0 [io  0x4000-0x4fff]
[    3.934978] pci_bus 0000:04: resource 1 [mem 0xfce00000-0xfcffffff]
[    3.942377] pci_bus 0000:04: resource 2 [mem 0xfe400000-0xfe5fffff 64bit pref]
[    3.950379] pci_bus 0000:05: resource 0 [io  0x5000-0x5fff]
[    3.957050] pci_bus 0000:05: resource 1 [mem 0xfcc00000-0xfcdfffff]
[    3.964279] pci_bus 0000:05: resource 2 [mem 0xfe200000-0xfe3fffff 64bit pref]
[    3.972602] pci_bus 0000:06: resource 0 [io  0x6000-0x6fff]
[    3.979143] pci_bus 0000:06: resource 1 [mem 0xfca00000-0xfcbfffff]
[    3.986664] pci_bus 0000:06: resource 2 [mem 0xfe000000-0xfe1fffff 64bit pref]
[    3.994727] pci_bus 0000:07: resource 0 [io  0x7000-0x7fff]
[    4.001328] pci_bus 0000:07: resource 1 [mem 0xfc800000-0xfc9fffff]
[    4.008564] pci_bus 0000:07: resource 2 [mem 0xfde00000-0xfdffffff 64bit pref]
[    4.017124] pci_bus 0000:08: resource 0 [io  0x8000-0x8fff]
[    4.023517] pci_bus 0000:08: resource 1 [mem 0xfc600000-0xfc7fffff]
[    4.030528] pci_bus 0000:08: resource 2 [mem 0xfdc00000-0xfddfffff 64bit pref]
[    4.042384] pci_bus 0000:09: resource 0 [io  0x9000-0x9fff]
[    4.048884] pci_bus 0000:09: resource 1 [mem 0xfc400000-0xfc5fffff]
[    4.056027] pci_bus 0000:09: resource 2 [mem 0xfda00000-0xfdbfffff 64bit pref]
[    4.064155] pci_bus 0000:0a: resource 0 [io  0xa000-0xafff]
[    4.070574] pci_bus 0000:0a: resource 1 [mem 0xfc200000-0xfc3fffff]
[    4.077802] pci_bus 0000:0a: resource 2 [mem 0xfd800000-0xfd9fffff 64bit pref]
[    4.086329] NET: Registered protocol family 2
[    4.091775] tcp_listen_portaddr_hash hash table entries: 256 (order: 0, 4096 bytes, linear)
[    4.101112] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)
[    4.109449] TCP bind hash table entries: 1024 (order: 2, 16384 bytes, linear)
[    4.117450] TCP: Hash tables configured (established 1024 bind 1024)
[    4.124820] UDP hash table entries: 256 (order: 1, 8192 bytes, linear)
[    4.132179] UDP-Lite hash table entries: 256 (order: 1, 8192 bytes, linear)
[    4.139970] NET: Registered protocol family 1
[    4.145287] NET: Registered protocol family 44
[    4.152404] PCI: CLS 0 bytes, default 64
[    4.157442] Trying to unpack rootfs image as initramfs...
[    4.247510] Freeing initrd memory: 6396K
[    4.255920] check: Scanning for low memory corruption every 60 seconds
[    4.264234] Initialise system trusted keyrings
[    4.269882] Key type blacklist registered
[    4.274886] workingset: timestamp_bits=36 max_order=15 bucket_order=0
[    4.282990] zbud: loaded
[    4.286782] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    4.293788] fuse: init (API version 7.31)
[    4.298856] Platform Keyring initialized
[    4.307164] Key type asymmetric registered
[    4.312160] Asymmetric key parser 'x509' registered
[    4.317992] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 244)
[    4.326243] io scheduler mq-deadline registered
[    4.332012] PCI Interrupt Link [GSIF] enabled at IRQ 21
[    4.343931] pcieport 0000:00:01.0: PME: Signaling with IRQ 24
[    4.352995] pcieport 0000:00:01.0: AER: enabled with IRQ 24
[    4.368964] pcieport 0000:00:01.1: PME: Signaling with IRQ 25
[    4.377813] pcieport 0000:00:01.1: AER: enabled with IRQ 25
[    4.394346] pcieport 0000:00:01.2: PME: Signaling with IRQ 26
[    4.402636] pcieport 0000:00:01.2: AER: enabled with IRQ 26
[    4.419432] pcieport 0000:00:01.3: PME: Signaling with IRQ 27
[    4.428544] pcieport 0000:00:01.3: AER: enabled with IRQ 27
[    4.451508] pcieport 0000:00:01.4: PME: Signaling with IRQ 28
[    4.465609] pcieport 0000:00:01.4: AER: enabled with IRQ 28
[    4.481355] pcieport 0000:00:01.5: PME: Signaling with IRQ 29
[    4.490292] pcieport 0000:00:01.5: AER: enabled with IRQ 29
[    4.506496] pcieport 0000:00:01.6: PME: Signaling with IRQ 30
[    4.515198] pcieport 0000:00:01.6: AER: enabled with IRQ 30
[    4.531949] pcieport 0000:00:01.7: PME: Signaling with IRQ 31
[    4.541370] pcieport 0000:00:01.7: AER: enabled with IRQ 31
[    4.551728] PCI Interrupt Link [GSIG] enabled at IRQ 22
[    4.564212] pcieport 0000:00:02.0: PME: Signaling with IRQ 32
[    4.574483] pcieport 0000:00:02.0: AER: enabled with IRQ 32
[    4.590979] pcieport 0000:00:02.1: PME: Signaling with IRQ 33
[    4.599834] pcieport 0000:00:02.1: AER: enabled with IRQ 33
[    4.610300] shpchp: Standard Hot Plug PCI Controller Driver version: 0.4
[    4.617828] intel_idle: does not run on family 6 model 207
[    4.617873] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0
[    4.626289] ACPI: Power Button [PWRF]
[    4.775399] Serial: 8250/16550 driver, 32 ports, IRQ sharing enabled
[    4.828058] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
[    5.113742] Linux agpgart interface v0.103
[    5.123381] loop: module loaded
[    5.127809] libphy: Fixed MDIO Bus: probed
[    5.132796] tun: Universal TUN/TAP device driver, 1.6
[    5.138740] PPP generic driver version 2.4.2
[    5.143983] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver
[    5.151330] ehci-pci: EHCI PCI platform driver
[    5.156600] ehci-platform: EHCI generic platform driver
[    5.162725] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver
[    5.169801] ohci-pci: OHCI PCI platform driver
[    5.175248] ohci-platform: OHCI generic platform driver
[    5.181288] uhci_hcd: USB Universal Host Controller Interface driver
[    5.188672] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12
[    5.208670] serio: i8042 KBD port at 0x60,0x64 irq 1
[    5.214564] serio: i8042 AUX port at 0x60,0x64 irq 12
[    5.220593] mousedev: PS/2 mouse device common for all mice
[    5.228628] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1
[    5.238336] rtc_cmos 00:03: RTC can wake from S4
[    5.250466] rtc_cmos 00:03: registered as rtc0
[    5.255937] rtc_cmos 00:03: alarms up to one day, y3k, 242 bytes nvram, hpet irqs
[    5.265136] i2c /dev entries driver
[    5.269612] device-mapper: uevent: version 1.0.3
[    5.275186] device-mapper: ioctl: 4.40.0-ioctl (2019-01-18) initialised: dm-devel@redhat.com
[    5.284969] platform eisa.0: Probing EISA bus 0
[    5.290503] platform eisa.0: EISA: Cannot allocate resource for mainboard
[    5.298184] platform eisa.0: Cannot allocate resource for EISA slot 1
[    5.305623] platform eisa.0: Cannot allocate resource for EISA slot 2
[    5.312919] platform eisa.0: Cannot allocate resource for EISA slot 3
[    5.320451] platform eisa.0: Cannot allocate resource for EISA slot 4
[    5.327747] platform eisa.0: Cannot allocate resource for EISA slot 5
[    5.335077] platform eisa.0: Cannot allocate resource for EISA slot 6
[    5.342315] platform eisa.0: Cannot allocate resource for EISA slot 7
[    5.349603] platform eisa.0: Cannot allocate resource for EISA slot 8
[    5.356792] platform eisa.0: EISA: Detected 0 cards
[    5.362544] intel_pstate: CPU model not supported
[    5.368285] ledtrig-cpu: registered to indicate activity on CPUs
[    5.375270] NET: Registered protocol family 10
[    5.383613] Segment Routing with IPv6
[    5.388214] NET: Registered protocol family 17
[    5.393707] Key type dns_resolver registered
[    5.399296] RAS: Correctable Errors collector initialized.
[    5.405646] registered taskstats version 1
[    5.411102] Loading compiled-in X.509 certificates
[    5.417754] Loaded X.509 cert 'Build time autogenerated kernel key: 8098f9b3401d48cb244b138af0c5bac131caef8a'
[    5.428832] zswap: loaded using pool lzo/zbud
[    5.436792] Key type big_key registered
[    5.443458] Key type encrypted registered
[    5.448344] AppArmor: AppArmor sha1 policy hashing enabled
[    5.454690] ima: No TPM chip found, activating TPM-bypass!
[    5.465021] ima: Allocated hash algorithm: sha1
[    5.471181] No architecture policies found
[    5.476343] evm: Initialising EVM extended attributes:
[    5.482416] evm: security.selinux
[    5.486636] evm: security.SMACK64
[    5.490967] evm: security.SMACK64EXEC
[    5.495585] evm: security.SMACK64TRANSMUTE
[    5.500609] evm: security.SMACK64MMAP
[    5.506682] evm: security.apparmor
[    5.511176] evm: security.ima
[    5.515108] evm: security.capability
[    5.519628] evm: HMAC attrs: 0x1
[    5.525304] PM:   Magic number: 1:476:554
[    5.530243] acpi PNP0C0F:05: hash matches
[    5.535231] acpi PNP0C01:00: hash matches
[    5.541115] rtc_cmos 00:03: setting system clock to 2025-11-07T23:32:54 UTC (1762558374)
[    5.550123] Unstable clock detected, switching default tracing clock to "global"
               If you want to keep using the local clock, then add:
                 "trace_clock=local"
               on the kernel command line
[    5.581609] Freeing unused decrypted memory: 2040K
[    5.588031] Freeing unused kernel image memory: 2660K
[    5.594122] Write protecting the kernel read-only data: 22528k
[    5.602238] Freeing unused kernel image memory: 2008K
[    5.608412] Freeing unused kernel image memory: 1476K
[    5.619736] x86/mm: Checked W+X mappings: passed, no W+X pages found.
[    5.627091] Run /init as init process
[    5.648471] e1000: Intel(R) PRO/1000 Network Driver - version 7.3.21-k8-NAPI
[    5.648472] e1000: Copyright (c) 1999-2006 Intel Corporation.
[    5.650353] ne2k-pci.c:v1.03 9/22/2003 D. Becker/P. Gortmaker
[    5.653866] pcnet32: pcnet32.c:v1.35 21.Apr.2008 tsbogend@alpha.franken.de
[    5.656260] 9pnet: Installing 9P2000 support
[    5.767539] virtio_blk virtio3: [vda] 229376 512-byte logical blocks (117 MB/112 MiB)
[    5.781915]  vda: vda1 vda15
[    5.800889] virtio_blk virtio4: [vdb] 2048 512-byte logical blocks (1.05 MB/1.00 MiB)
[    5.872277] scsi host0: Virtio SCSI HBA
[    5.909275] hidraw: raw HID events driver (C) Jiri Kosina
[    5.910108] usbcore: registered new interface driver usbhid
[    5.910109] usbhid: USB HID core driver
[    5.919941] ahci 0000:00:1f.2: version 3.0
[    5.920502] PCI Interrupt Link [GSIA] enabled at IRQ 16
[    5.932220] ahci 0000:00:1f.2: AHCI 0001.0000 32 slots 6 ports 1.5 Gbps 0x3f impl SATA mode
[    5.932221] ahci 0000:00:1f.2: flags: 64bit ncq only 
[    5.944900] scsi host1: ahci
[    5.944946] scsi host2: ahci
[    5.944984] scsi host3: ahci
[    5.945016] scsi host4: ahci
[    5.945051] scsi host5: ahci
[    5.945085] scsi host6: ahci
[    5.945254] ata1: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a100 irq 49
[    5.945393] ata2: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a180 irq 49
[    5.945558] ata3: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a200 irq 49
[    5.945699] ata4: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a280 irq 49
[    5.945830] ata5: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a300 irq 49
[    5.945964] ata6: SATA max UDMA/133 abar m4096@0xfd60a000 port 0xfd60a380 irq 49
[    6.262477] ata2: SATA link down (SStatus 0 SControl 300)
[    6.266434] ata1: SATA link down (SStatus 0 SControl 300)
[    6.270321] ata3: SATA link down (SStatus 0 SControl 300)
[    6.274383] ata4: SATA link down (SStatus 0 SControl 300)
[    6.278151] ata5: SATA link down (SStatus 0 SControl 300)
[    6.282013] ata6: SATA link down (SStatus 0 SControl 300)
[    6.329634] EXT4-fs (vda1): mounting ext3 file system using the ext4 subsystem
[    6.332577] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)
[    6.334781] EXT4-fs (vda1): mounting ext3 file system using the ext4 subsystem
[    6.349983] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)
[    6.484299] EXT4-fs (vda1): re-mounted. Opts: (null)
[    6.504463] EXT4-fs (vda1): re-mounted. Opts: (null)
[    6.590429] ISO 9660 Extensions: Microsoft Joliet Level 3
[    6.591050] ISO 9660 Extensions: RRIP_1991A
[    6.866747] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
[    6.954983] EXT4-fs (vda1): resizing filesystem from 25600 to 26363 blocks
[    6.954992] EXT4-fs (vda1): resized filesystem to 26363
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\n$ " "\r" "" "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "lspci\n"
&#65533;[32mMatch for RE:&#65533;[39m "lspci((?s).*)((?s).*)(\\$ |\\# )" found: ["lspci\r\n00:1f.2 Class 0106: 8086:2922\r\n09:00.0 Class 00ff: 1af4:1045\r\n00:01.2 Class 0604: 1b36:000c\r\n00:1f.0 Class 0601: 8086:2918\r\n00:01.0 Class 0604: 1b36:000c\r\n08:00.0 Class 0100: 1af4:1042\r\n01:00.0 Class 0200: 1af4:1041\r\n00:02.1 Class 0604: 1b36:000c\r\n00:01.7 Class 0604: 1b36:000c\r\n07:00.0 Class 0100: 1af4:1042\r\n00:01.5 Class 0604: 1b36:000c\r\n00:1f.3 Class 0c05: 8086:2930\r\n00:00.0 Class 0600: 8086:29c0\r\n00:01.3 Class 0604: 1b36:000c\r\n06:00.0 Class 0780: 1af4:1043\r\n00:01.1 Class 0604: 1b36:000c\r\n05:00.0 Class 0100: 1af4:1048\r\n00:02.0 Class 0604: 1b36:000c\r\n00:01.6 Class 0604: 1b36:000c\r\n00:01.4 Class 0604: 1b36:000c\r\n$ " "\r\n00:1f.2 Class 0106: 8086:2922\r\n09:00.0 Class 00ff: 1af4:1045\r\n00:01.2 Class 0604: 1b36:000c\r\n00:1f.0 Class 0601: 8086:2918\r\n00:01.0 Class 0604: 1b36:000c\r\n08:00.0 Class 0100: 1af4:1042\r\n01:00.0 Class 0200: 1af4:1041\r\n00:02.1 Class 0604: 1b36:000c\r\n00:01.7 Class 0604: 1b36:000c\r\n07:00.0 Class 0100: 1af4:1042\r\n00:01.5 Class 0604: 1b36:000c\r\n00:1f.3 Class 0c05: 8086:2930\r\n00:00.0 Class 0600: 8086:29c0\r\n00:01.3 Class 0604: 1b36:000c\r\n06:00.0 Class 0780: 1af4:1043\r\n00:01.1 Class 0604: 1b36:000c\r\n05:00.0 Class 0100: 1af4:1048\r\n00:02.0 Class 0604: 1b36:000c\r\n00:01.6 Class 0604: 1b36:000c\r\n00:01.4 Class 0604: 1b36:000c\r\n" "" "$ "] Buffer: lspci
00:1f.2 Class 0106: 8086:2922
09:00.0 Class 00ff: 1af4:1045
00:01.2 Class 0604: 1b36:000c
00:1f.0 Class 0601: 8086:2918
00:01.0 Class 0604: 1b36:000c
08:00.0 Class 0100: 1af4:1042
01:00.0 Class 0200: 1af4:1041
00:02.1 Class 0604: 1b36:000c
00:01.7 Class 0604: 1b36:000c
07:00.0 Class 0100: 1af4:1042
00:01.5 Class 0604: 1b36:000c
00:1f.3 Class 0c05: 8086:2930
00:00.0 Class 0600: 8086:29c0
00:01.3 Class 0604: 1b36:000c
06:00.0 Class 0780: 1af4:1043
00:01.1 Class 0604: 1b36:000c
05:00.0 Class 0100: 1af4:1048
00:02.0 Class 0604: 1b36:000c
00:01.6 Class 0604: 1b36:000c
00:01.4 Class 0604: 1b36:000c
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\n$ " "\r" "" "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "arp\n"
&#65533;[32mMatch for RE:&#65533;[39m "arp((?s).*)((?s).*)(\\$ |\\# )" found: ["arp\r\n10-42-0-221.kube-prometheus-stack-coredns.kube-system.svc.cluster.local (10.42.0.221) at ca:f1:f7:a3:f6:de [ether]  on eth0\r\n? (10.42.0.1) at ba:fb:ee:39:8f:35 [ether]  on eth0\r\n$ " "\r\n10-42-0-221.kube-prometheus-stack-coredns.kube-system.svc.cluster.local (10.42.0.221) at ca:f1:f7:a3:f6:de [ether]  on eth0\r\n? (10.42.0.1) at ba:fb:ee:39:8f:35 [ether]  on eth0\r\n" "" "$ "] Buffer: arp
10-42-0-221.kube-prometheus-stack-coredns.kube-system.svc.cluster.local (10.42.0.221) at ca:f1:f7:a3:f6:de [ether]  on eth0
? (10.42.0.1) at ba:fb:ee:39:8f:35 [ether]  on eth0
$ 
&#65533;[34mSent:&#65533;[39m "echo $?\n"
&#65533;[32mMatch for RE:&#65533;[39m "echo \\$\\?((?s).*)\n0\r\n((?s).*)(\\$ |\\# )" found: ["echo $?\r\n0\r\n$ " "\r" "" "$ "] Buffer: echo $?
0
$ 
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[32mMatch for RE:&#65533;[39m "\\$" found: ["$"] Buffer: 
$
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Delete a VirtualMachineInstance's Pod (API) [test_id:1650]should result in the VirtualMachineInstance moving to a finalized state" classname="KubeVirt Tests Suite" time="86.681283486" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Delete a VirtualMachineInstance with an active pod. [test_id:1651]should result in pod being terminated" classname="KubeVirt Tests Suite" time="87.223890557">
          <failure type="Failure">tests/vmi_lifecycle_test.go:1587
Timed out after 60.004s.
The matcher passed to Eventually returned the following error:
    &lt;*errors.errorString | 0xc007e57b20&gt;: 
    Expected an error, got nil
    {
        s: "Expected an error, got nil",
    }
tests/vmi_lifecycle_test.go:1602</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/9_*
Skipping volume snapshot log collection
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Delete a VirtualMachineInstance with ACPI and some grace period seconds [rfe_id:273][crit:medium][vendor:cnv-qe@redhat.com][level:component]should result in vmi status succeeded [test_id:1653]with set grace period seconds" classname="KubeVirt Tests Suite" time="42.005047678" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Delete a VirtualMachineInstance with ACPI and some grace period seconds [rfe_id:273][crit:medium][vendor:cnv-qe@redhat.com][level:component]should result in vmi status succeeded [test_id:1654]with default grace period seconds" classname="KubeVirt Tests Suite" time="48.388733587" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Delete a VirtualMachineInstance with grace period greater than 0 [test_id:1655]should run graceful shutdown" classname="KubeVirt Tests Suite" time="40.368153868" />
      <testcase name="[rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIlifecycle [rfe_id:273][crit:high][vendor:cnv-qe@redhat.com][level:component]Killed VirtualMachineInstance [test_id:1656]should be in Failed phase" classname="KubeVirt Tests Suite" time="79.0110834" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:9840]VM with random name and default settings" classname="KubeVirt Tests Suite" time="7.437270171" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11647]Example with volume-import flag and PVC type" classname="KubeVirt Tests Suite" time="7.777984618" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11648]Example with volume-import flag and Registry type" classname="KubeVirt Tests Suite" time="7.422677367" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11649]Example with volume-import flag and Blank type" classname="KubeVirt Tests Suite" time="7.423537333" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:9841]Complex example" classname="KubeVirt Tests Suite" time="7.910975265" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:9842]Complex example with inferred instancetype and preference" classname="KubeVirt Tests Suite" time="7.886032939" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11650]Complex example with memory" classname="KubeVirt Tests Suite" time="7.543160203" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11651]Complex example with sysprep volume" classname="KubeVirt Tests Suite" time="7.49873401" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11652]Complex example with generated cloud-init config" classname="KubeVirt Tests Suite" time="48.262374966" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11653]Complex example with access credentials" classname="KubeVirt Tests Suite" time="100.279550492" />
      <testcase name="[virtctl] [sig-compute]create vm [test_id:11654]Failure of implicit inference does not fail the VM creation" classname="KubeVirt Tests Suite" time="7.504832311" />
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM and no snapshot should wait for snapshot to exist and be ready" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM and good snapshot exists [test_id:5256]should successfully restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM and good snapshot exists [test_id:5258]should reject restore if another in progress" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM and good snapshot exists should fail restoring to a different VM that already exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM and good snapshot exists restore to a new VM that does not exist with changed name and MAC address" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM with instancetype and preferences should use existing ControllerRevisions for an existing VM restore with a running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM with instancetype and preferences should use existing ControllerRevisions for an existing VM restore with a stopped VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM with instancetype and preferences should create new ControllerRevisions for newly restored VM with a running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests With simple VM with instancetype and preferences should create new ControllerRevisions for newly restored VM with a stopped VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM [test_id:5259]should restore a vm multiple from the same snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM restore should allow grace period for the target to be ready" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM restore should stop target if targetReadinessPolicy is StopTarget" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm with restore size bigger then PVC size to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm with restore size bigger then PVC size to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a datavolumetemplate [test_id:5260] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a datavolumetemplate to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a datavolume (not template) [test_id:5261] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a datavolume (not template) to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a PVC [test_id:5262] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a PVC to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm that boots from a PVC to a new VM, pvc not owned by VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm with containerdisk and blank datavolume [test_id:5263] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm with containerdisk and blank datavolume to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM Should restore a vm with backend storage with offline snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM Should restore a vm with backend storage with online snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should reject vm start if restore in progress and allow it to start after completion" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should reject vm start if restore in progress and allow it to start after vmrestore deletion" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm from an online snapshot [test_id:6053] to the same VM, stop VM after create restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm from an online snapshot to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm from an online snapshot with guest agent [test_id:6766] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore a vm from an online snapshot with guest agent to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore an online vm snapshot that boots from a datavolumetemplate with guest agent [test_id:6836] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore an online vm snapshot that boots from a datavolumetemplate with guest agent to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore vm spec at startup without new changes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore an already cloned virtual machine" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore vm with hot plug disks [test_id:7425] to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore vm with hot plug disks to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore vm with hot plug disks to the same VM with ephemeral" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should override VM during restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore with volume restore policy InPlace and DV template as disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore with volume restore policy InPlace and DV (not template) as disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM should restore with volume restore policy InPlace and PVC as disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM standalone PVC should have no owner with volumeOwnershipPolicyNone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with run strategy and snapshot should successfully restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with memory dump should not restore memory dump volume [test_id:8923]to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with memory dump should not restore memory dump volume [test_id:8924]to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolumetemplate to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolumetemplate to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolumetemplate to the same VM, no source pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolumetemplate to a new VM, no source pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolumetemplate to the same VM, no source namespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolumetemplate to a new VM, no source namespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolume (not template) to the same VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolume (not template) to a new VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolume (not template) to the same VM, no source pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] VirtualMachineRestore Tests [storage-req] With a more complicated VM with cross namespace clone ability should restore a vm that boots from a network cloned datavolume (not template) to a new VM, no source pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [test_id:1746]should have created and available condition" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator should reconcile components checking updating resource is reverted to original state for  [test_id:6254] deployments" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator should reconcile components checking updating resource is reverted to original state for  [test_id:6255] customresourcedefinitions" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator should reconcile components checking updating resource is reverted to original state for  [test_id:6256] poddisruptionbudgets" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator should reconcile components checking updating resource is reverted to original state for  [test_id:6308] daemonsets" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator should reconcile components [test_id:6309] checking updating service is reverted to original state" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [test_id:6987]should apply component configuration test VirtualMachineInstancesPerNode" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [test_id:4744]should apply component customization test applying and removing a patch" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator imagePullSecrets should not be present if not specified on the KubeVirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator imagePullSecrets should be propagated if applied on the KubeVirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]should update kubevirt [release-blocker][test_id:3145]from previous release to target tested release by patching KubeVirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]should update kubevirt [release-blocker][test_id:3145]from previous release to target tested release by updating virt-operator" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:3146]should be able to delete and re-create kubevirt install" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [rfe_id:3578][crit:high][vendor:cnv-qe@redhat.com][level:component] deleting with BlockUninstallIfWorkloadsExist [test_id:3683]should be blocked if a workload exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:3148]should be able to create kubevirt install with custom image tag" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:3149]should be able to create kubevirt install with image prefix" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:3150]should be able to update kubevirt install with custom image tag" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:3151]should be able to update kubevirt install when operator updates if no custom image tag is set" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:3152]should fail if KV object already exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:4612]should create non-namespaces resources without owner references" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [test_id:4613]should remove owner references on non-namespaces resources when updating a resource" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2291][crit:high][vendor:cnv-qe@redhat.com][level:component]infrastructure management [rfe_id:2897][crit:medium][vendor:cnv-qe@redhat.com][level:component]With OpenShift cluster [test_id:2910]Should have kubevirt SCCs created" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2897][crit:medium][vendor:cnv-qe@redhat.com][level:component]With ServiceMonitor Disabled [test_id:3154]Should not create RBAC Role or RoleBinding for ServiceMonitor" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator With PrometheusRule Enabled [test_id:4614]Checks if the kubevirt PrometheusRule cr exists and verify it's spec" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator With PrometheusRule Disabled [test_id:4615]Checks that we do not deploy a PrometheusRule cr when not needed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2937][crit:medium][vendor:cnv-qe@redhat.com][level:component]With ServiceMonitor Enabled [test_id:2936]Should allow Prometheus to scrape KubeVirt endpoints" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:2937][crit:medium][vendor:cnv-qe@redhat.com][level:component]With ServiceMonitor Enabled [test_id:4616]Should patch our namespace labels with openshift.io/cluster-monitoring=true" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [test_id:4617]should adopt previously unmanaged entities by updating its metadata" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:4356]Node Placement [test_id:4927]should dynamically update infra config" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:4356]Node Placement [test_id:4928]should dynamically update workloads config" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:4356]Node Placement should reject infra placement configuration with incorrect toleration operator" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:4356]Node Placement should reject workload placement configuration with incorrect toleraion operator" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator [rfe_id:4356]Node Placement [test_id:8235]should check if kubevirt components have linux node selector" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Replicas should fail to set replicas to 0" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Replicas should dynamically adjust virt- pod count and PDBs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Replicas should update new single-replica CRs with a finalizer and be stable" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Certificate Rotation [test_id:6257]should accept valid cert rotation parameters" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Certificate Rotation [test_id:6258]should reject combining deprecated and new cert rotation parameters" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Certificate Rotation [test_id:6259]should reject CA expires before rotation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Certificate Rotation [test_id:6260]should reject Cert expires before rotation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator Certificate Rotation [test_id:6261]should reject Cert rotates after CA expires" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator with VMExport feature gate toggled should delete and recreate virt-exportproxy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Seccomp configuration Kubevirt profile should install Kubevirt policy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Seccomp configuration Kubevirt profile should not install Kubevirt policy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Seccomp configuration VirtualMachineInstance Profile with VirtualMachineInstance Profile set to default should not set profile" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Seccomp configuration VirtualMachineInstance Profile with VirtualMachineInstance Profile set to custom should use localhost" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Deployment of common-instancetypes Should deploy common-instancetypes according to KubeVirt configurable" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Deployment of common-instancetypes Should take ownership of instancetypes and preferences" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Deployment of common-instancetypes Should delete resources not in install strategy with instancetypes and preferences" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator  Deployment of common-instancetypes Should revert changes to instancetypes and preferences" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator external CA should create a blank configmap" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]Operator external CA should properly manage adding entries to the configmap" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set [test_id:3242]should block the eviction api and migrate" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set [sig-compute][test_id:7680]should delete PDBs created by an old virt-controller" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set [test_id:3244]should block the eviction api while a slow migration is in progress" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set  with node tainted during node drain [test_id:6982]should migrate a VMI only one time" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set  with node tainted during node drain [test_id:2221] should migrate a VMI under load to another node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set  with node tainted during node drain [test_id:2222] should migrate a VMI when custom taint key is configured" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set [ref_id:2293] with a VMI running with an eviction strategy set  with node tainted during node drain [test_id:2224] should handle mixture of VMs with different eviction strategies." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with a live-migrate eviction strategy set with multiple VMIs with eviction policies set [release-blocker][test_id:3245]should not migrate more than two VMIs at the same time from a node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration  with a cluster-wide live-migrate eviction strategy set with a VMI running with no eviction strategy set [test_id:10155]should block the eviction api and migrate" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration  with a cluster-wide live-migrate eviction strategy set with a VMI running with eviction strategy set to 'None' [test_id:10156]The VMI should get evicted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Version Check that version parameters where loaded by ldflags in build time [test_id:555]Should return a good version information struct" classname="KubeVirt Tests Suite" time="7.431312373" />
      <testcase name="[sig-storage] virtiofs VirtIO-FS with multiple PVCs [Serial] should be successfully started and accessible" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] virtiofs VirtIO-FS with an empty PVC [Serial] should be successfully started and virtiofs could be accessed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] virtiofs Run a VMI with VirtIO-FS and a datavolume [Serial] should be successfully started and virtiofs could be accessed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Dual stack cluster network configuration when dual stack cluster configuration is enabled the cluster must be dual stack" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-performance] Control Plane Performance Density Testing Density test [small] create a batch of 100 VMIs should successfully create all VMIS" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-performance] Control Plane Performance Density Testing Density test [small] create a batch of 100 running VMs should successfully create all VMS" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-performance] Control Plane Performance Density Testing Density test [small] create a batch of 100 running VMs using a single instancetype and preference should successfully create all VMS with instancetype and preference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Post Copy Live Migration with datavolume [test_id:5004] should be migrated successfully, using guest agent on VM with post-copy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Post Copy Live Migration should migrate using post-copy [test_id:4747] using a migration policy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Post Copy Live Migration should migrate using post-copy [test_id:4747] using the Kubevirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Post Copy Live Migration should migrate using post-copy and fail and make sure VMs restart after failure" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype validation [test_id:CNV-9082] should allow valid instancetype" classname="KubeVirt Tests Suite" time="7.426363977" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype validation [test_id:CNV-9083] should reject invalid instancetype without CPU defined" classname="KubeVirt Tests Suite" time="7.422336469" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype validation [test_id:CNV-9083] should reject invalid instancetype without CPU.Guest defined" classname="KubeVirt Tests Suite" time="7.420807878" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype validation [test_id:CNV-9083] should reject invalid instancetype without Memory defined" classname="KubeVirt Tests Suite" time="7.417503814" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype validation [test_id:CNV-9083] should reject invalid instancetype without Memory.Guest defined" classname="KubeVirt Tests Suite" time="7.419150956" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Preference validation [test_id:CNV-9084] should allow valid preference" classname="KubeVirt Tests Suite" time="7.431324714" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences A VirtualMachine referencing a non-existent [test_id:CNV-9086] cluster instance type should still be created and eventually start when missing resource created" classname="KubeVirt Tests Suite" time="12.041393988" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences A VirtualMachine referencing a non-existent [test_id:CNV-9089] instance type should still be created and eventually start when missing resource created" classname="KubeVirt Tests Suite" time="11.996969594" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences A VirtualMachine referencing a non-existent [test_id:CNV-9091] cluster preference should still be created and eventually start when missing resource created" classname="KubeVirt Tests Suite" time="12.041267739" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences A VirtualMachine referencing a non-existent [test_id:CNV-9090] preference should still be created and eventually start when missing resource created" classname="KubeVirt Tests Suite" time="11.995478186" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with cluster memory overcommit being applied should apply memory overcommit instancetype to VMI even with cluster overcommit set" classname="KubeVirt Tests Suite" time="87.816192777" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9094] should find and apply cluster instancetype and preferences when kind isn't provided" classname="KubeVirt Tests Suite" time="13.132096653" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9095] should apply instancetype and preferences to VMI" classname="KubeVirt Tests Suite" time="13.130288603" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application should apply memory overcommit instancetype to VMI" classname="KubeVirt Tests Suite" time="16.169286578" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9096] should fail if instancetype and VM define CPU" classname="KubeVirt Tests Suite" time="7.497494242" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9301] should fail if the VirtualMachine has  CPU resource requests" classname="KubeVirt Tests Suite" time="7.498150751" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9301] should fail if the VirtualMachine has  CPU resource limits" classname="KubeVirt Tests Suite" time="7.491860719" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9301] should fail if the VirtualMachine has  Memory resource requests" classname="KubeVirt Tests Suite" time="7.521156214" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9301] should fail if the VirtualMachine has  Memory resource limits" classname="KubeVirt Tests Suite" time="7.495238059" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9302] should apply preferences to default network interface" classname="KubeVirt Tests Suite" time="12.044947309" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9303] should apply preferences to default volume disks" classname="KubeVirt Tests Suite" time="11.994437021" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9098] should store and use ControllerRevisions of VirtualMachineInstancetypeSpec and VirtualMachinePreferenceSpec" classname="KubeVirt Tests Suite" time="61.171293793" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences Instancetype and preference application [test_id:CNV-9304] should fail if stored ControllerRevisions are different" classname="KubeVirt Tests Suite" time="21.5401993" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should infer defaults from PersistentVolumeClaimVolumeSource" classname="KubeVirt Tests Suite" time="36.008969927" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should infer defaults from existing DataVolume with labels" classname="KubeVirt Tests Suite" time="20.479297121" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should infer defaults from DataVolumeTemplates and DataVolumeSourcePVC" classname="KubeVirt Tests Suite" time="46.403998156" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should infer defaults from DataVolumeTemplates , DataVolumeSourceRef and DataSource" classname="KubeVirt Tests Suite" time="38.131265808" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should infer defaults from DataVolumeTemplates , DataVolumeSourceRef and DataSource with labels" classname="KubeVirt Tests Suite" time="35.099331704" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should ignore failure when trying to infer defaults from DataVolumeSpec with unsupported DataVolumeSource when policy is set" classname="KubeVirt Tests Suite" time="17.048207978" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should reject VM creation when inference was successful but memory and RejectInferFromVolumeFailure were set with explicitly setting RejectInferFromVolumeFailure" classname="KubeVirt Tests Suite" time="17.039353085" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences with inferFromVolume should reject VM creation when inference was successful but memory and RejectInferFromVolumeFailure were set with implicitly setting RejectInferFromVolumeFailure (default)" classname="KubeVirt Tests Suite" time="17.067550024" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences instance type with dedicatedCPUPlacement enabled should be accepted and result in running VirtualMachineInstance" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachineInstancetype meets CPU requirements" classname="KubeVirt Tests Suite" time="7.654344161" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachineInstancetype meets Memory requirements" classname="KubeVirt Tests Suite" time="7.634222275" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachine meets CPU (preferSockets default) requirements" classname="KubeVirt Tests Suite" time="7.508359391" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachine meets CPU (preferCores) requirements" classname="KubeVirt Tests Suite" time="7.541652365" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachine meets 1 vCPU requirement through defaults - bug #10047" classname="KubeVirt Tests Suite" time="7.506809" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachine meets CPU (preferThreads) requirements" classname="KubeVirt Tests Suite" time="7.507579645" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachine meets CPU (preferAny) requirements" classname="KubeVirt Tests Suite" time="7.513918301" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be accepted when VirtualMachine meets Memory requirements" classname="KubeVirt Tests Suite" time="7.543818833" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachineInstancetype does not meet CPU requirements" classname="KubeVirt Tests Suite" time="7.610798816" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachineInstancetype does not meet Memory requirements" classname="KubeVirt Tests Suite" time="7.640025766" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachine does not meet CPU (preferSockets default) requirements" classname="KubeVirt Tests Suite" time="7.530196491" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachine does not meet CPU (preferCores) requirements" classname="KubeVirt Tests Suite" time="7.502393311" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachine does not meet CPU (preferThreads) requirements" classname="KubeVirt Tests Suite" time="7.532207366" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachine does not meet CPU (preferAny) requirements" classname="KubeVirt Tests Suite" time="7.562857965" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachine does not meet Memory requirements" classname="KubeVirt Tests Suite" time="7.511117239" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instancetype and Preferences VirtualMachine using preference resource requirements should be rejected when VirtualMachine does not meet Memory requirements or provide any guest visible memory - bug #14551" classname="KubeVirt Tests Suite" time="7.500345429" />
      <testcase name="[sig-network] SRIOV VMI connected to single SRIOV network should have cloud-init meta_data with tagged interface and aligned cpus to sriov interface numa node for VMIs with dedicatedCPUs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to single SRIOV network [test_id:1754]should create a virtual machine with sriov interface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to single SRIOV network [test_id:1754]should create a virtual machine with sriov interface with all pci devices on the root bus" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to single SRIOV network [test_id:3959]should create a virtual machine with sriov interface and dedicatedCPUs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to single SRIOV network [test_id:3985]should create a virtual machine with sriov interface with custom MAC address" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to single SRIOV network migration should be successful with a running VMI on the target" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to two SRIOV networks [test_id:1755]should create a virtual machine with two sriov interfaces referring the same resource" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV Connected to multiple SRIOV networks should correctly plug all the interfaces based on the specified MAC and (guest) PCI addresses" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to link-enabled SRIOV network [test_id:3956]should connect to another machine with sriov interface over IP" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to link-enabled SRIOV network With VLAN should be able to ping between two VMIs with the same VLAN over SRIOV network" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] SRIOV VMI connected to link-enabled SRIOV network With VLAN should NOT be able to ping between Vlaned VMI and a non Vlaned VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]SwapTest Migration to/from memory overcommitted nodes Postcopy Migration of vmi that is dirtying(stress-ng) more memory than the source node's memory" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]SwapTest Migration to/from memory overcommitted nodes Migration of vmi to memory overcommited node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] VMIDefaults Disk defaults [test_id:4115]Should be applied to VMIs" classname="KubeVirt Tests Suite" time="7.7088545029999995" />
      <testcase name="[sig-compute] VMIDefaults MemBalloon defaults [test_id:4556]Should be present in domain" classname="KubeVirt Tests Suite" time="12.233796503" />
      <testcase name="[sig-compute] VMIDefaults MemBalloon defaults Should override period in domain if present in virt-config  [test_id:4557]with period 12" classname="KubeVirt Tests Suite" time="82.837318188" />
      <testcase name="[sig-compute] VMIDefaults MemBalloon defaults Should override period in domain if present in virt-config  [test_id:4558]with period 0" classname="KubeVirt Tests Suite" time="83.791696726" />
      <testcase name="[sig-compute] VMIDefaults MemBalloon defaults [test_id:4559]Should not be present in domain " classname="KubeVirt Tests Suite" time="12.260637528" />
      <testcase name="[sig-compute] VMIDefaults Input defaults [test_id:TODO]Should be applied to a device added by AutoattachInputDevice" classname="KubeVirt Tests Suite" time="7.704465325" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachineInstancetype from v1beta1 without labels to latest" classname="KubeVirt Tests Suite" time="7.892896746" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachineInstancetype from v1beta1 with labels to latest" classname="KubeVirt Tests Suite" time="8.894962568" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachineClusterInstancetype from v1beta1 without labels to latest" classname="KubeVirt Tests Suite" time="7.95552487" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachineClusterInstancetype from v1beta1 with labels to latest" classname="KubeVirt Tests Suite" time="7.922889018" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachinePreference from v1beta1 without labels to latest" classname="KubeVirt Tests Suite" time="7.905712119" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachinePreference from v1beta1 with labels to latest" classname="KubeVirt Tests Suite" time="7.906138269" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachineClusterPreference from v1beta1 without labels to latest" classname="KubeVirt Tests Suite" time="8.996044819" />
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Instance type and preference ControllerRevision Upgrades should upgrade VirtualMachineClusterPreference from v1beta1 with labels to latest" classname="KubeVirt Tests Suite" time="8.996951176" />
      <testcase name="[HyperVLayered] HyperVLayered integration tests VMI created with HyperVLayered should request 'devices.kubevirt.io/mshv' instead of 'devices.kubevirt.io/kvm' in virt-launcher pod spec" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[HyperVLayered] HyperVLayered integration tests VMI created with HyperVLayered should generate libvirt domain xml with hyperv domain type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]CPU Hotplug with requests without topology should be able to start" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]CPU Hotplug with Kubevirt CR declaring MaxCpuSockets should be able to start" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]CPU Hotplug A VM with cpu.maxSockets set higher than cpu.sockets [test_id:10811]should successfully plug vCPUs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]CPU Hotplug A VM with cpu.maxSockets set higher than cpu.sockets [test_id:10822]should successfully plug guaranteed vCPUs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]CPU Hotplug Abort CPU change should cancel the automated workload update" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] Sound [crit:medium][vendor:cnv-qe@redhat.com][level:component] A VirtualMachineInstance with default sound support should create an ich9 sound device on empty model" classname="KubeVirt Tests Suite" time="64.979730053" />
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migrate A Paused VMI Starting a VirtualMachineInstance  paused vmi during migration should migrate paused when acceptable time exceeded and post-copy is forbidden should pause the VMI and  migrate successfully (migration policy)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migrate A Paused VMI Starting a VirtualMachineInstance  paused vmi during migration should migrate paused when acceptable time exceeded and post-copy is forbidden should pause the VMI and  migrate successfully (CR change)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VSOCK VM creation should expose a VSOCK device Use virtio transitional" classname="KubeVirt Tests Suite" time="115.249170048" />
      <testcase name="[sig-compute]VSOCK VM creation should expose a VSOCK device Use virtio non-transitional" classname="KubeVirt Tests Suite" time="119.243020902" />
      <testcase name="[sig-compute]VSOCK Live migration should retain the CID for migration target" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VSOCK communicating with VMI via VSOCK should succeed with TLS on both sides" classname="KubeVirt Tests Suite" time="154.812533204" />
      <testcase name="[sig-compute]VSOCK communicating with VMI via VSOCK should succeed without TLS on both sides" classname="KubeVirt Tests Suite" time="124.177577586" />
      <testcase name="[sig-compute]VSOCK should return err if the port is invalid" classname="KubeVirt Tests Suite" time="87.588131808" />
      <testcase name="[sig-compute]VSOCK should return err if no app listerns on the port" classname="KubeVirt Tests Suite" time="93.867075148" />
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Live Migration All containers should complete in source virt-launcher pod after migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface SSH traffic With VMI having explicit ports specified should ssh to VMI with Istio proxy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface SSH traffic With VMI having no explicit ports specified should ssh to VMI with Istio proxy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With VMI having explicit ports specified request to VMI should reach HTTP server on service declared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With VMI having explicit ports specified request to VMI should reach HTTP server on service undeclared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With VMI having no explicit ports specified request to VMI should reach HTTP server on service declared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With VMI having no explicit ports specified request to VMI should reach HTTP server on service undeclared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With VMI having no explicit ports specified Should not be able to reach service running on Istio restricted port" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having explicit ports specified client outside mesh should NOT reach VMI HTTP server on service declared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having explicit ports specified client outside mesh should NOT reach VMI HTTP server on service undeclared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having no explicit ports specified client outside mesh should NOT reach VMI HTTP server on service declared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having no explicit ports specified client outside mesh should NOT reach VMI HTTP server on service undeclared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Outbound traffic VMI with explicit ports Should be able to reach http server outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Outbound traffic VMI with no explicit ports Should be able to reach http server outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Outbound traffic With Sidecar allowing only registered external services VMI with explicit ports Should not be able to reach http service outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with passt binding Virtual Machine with istio supported interface Outbound traffic With Sidecar allowing only registered external services VMI with no explicit ports Should not be able to reach http service outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] SCSI persistent reservation Use LUN disk with persistent reservation Should successfully start a VM with persistent reservation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] SCSI persistent reservation Use LUN disk with persistent reservation Should successfully start 2 VMs with persistent reservation on the same LUN" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] SCSI persistent reservation with PersistentReservation feature gate toggled should delete and recreate virt-handler" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] SCSI persistent reservation with PersistentReservation feature gate toggled With multipath ensure multipath socket is bind mounted and available to the pr-helper daemon" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure virt-handler should enable/disable ksm and add/remove annotation on all the nodes when the selector is empty" classname="KubeVirt Tests Suite" time="82.107878939" />
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV re-enlightenment enabled when TSC frequency is exposed on the cluster should be able to migrate" classname="KubeVirt Tests Suite" time="13.851940505">
          <failure type="Failure">tests/hyperv_test.go:58
TSC frequency is not exposed on the cluster
tests/hyperv_test.go:60</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/10_*
Skipping volume snapshot log collection
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV re-enlightenment enabled when  TSC frequency is not exposed on the cluster Should start successfully and be marked as non-migratable" classname="KubeVirt Tests Suite" time="32.13657317" />
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV re-enlightenment enabled the vmi with HyperV feature matching a nfd label on a node should be scheduled" classname="KubeVirt Tests Suite" time="7.454173315" />
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV re-enlightenment enabled  the vmi with EVMCS HyperV feature should have correct HyperV and cpu features auto filled hyperv and cpu features should be auto filled when EVMCS is enabled" classname="KubeVirt Tests Suite" time="171.873708576">
          <failure type="Failure">tests/hyperv_test.go:203
Timed out after 90.000s.
Timed out waiting for VMI testvmi-9hxc7 to enter [Running] phase(s)
Expected
    &lt;v1.VirtualMachineInstancePhase&gt;: Scheduling
to be an element of
    &lt;[]v1.VirtualMachineInstancePhase | len:1, cap:1&gt;: ["Running"]
tests/libwait/wait.go:76</failure>
          <system-out>Forwarding from 127.0.0.1:9774 -&gt; 8443
Forwarding from [::1]:9774 -&gt; 8443
Handling connection for 9774
Forwarding from 127.0.0.1:7846 -&gt; 8443
Forwarding from [::1]:7846 -&gt; 8443
Handling connection for 7846
Forwarding from 127.0.0.1:5432 -&gt; 8443
Forwarding from [::1]:5432 -&gt; 8443
Handling connection for 5432
Forwarding from 127.0.0.1:5406 -&gt; 8443
Forwarding from [::1]:5406 -&gt; 8443
Handling connection for 5406
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/11_*
Skipping volume snapshot log collection
Global test cleanup started.
Forwarding from 127.0.0.1:6821 -&gt; 8443
Forwarding from [::1]:6821 -&gt; 8443
Handling connection for 6821
Forwarding from 127.0.0.1:9840 -&gt; 8443
Forwarding from [::1]:9840 -&gt; 8443
Handling connection for 9840
Forwarding from 127.0.0.1:6061 -&gt; 8443
Forwarding from [::1]:6061 -&gt; 8443
Handling connection for 6061
Forwarding from 127.0.0.1:10037 -&gt; 8443
Forwarding from [::1]:10037 -&gt; 8443
Handling connection for 10037
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV re-enlightenment enabled  the vmi with EVMCS HyperV feature should have correct HyperV and cpu features auto filled EVMCS should be enabled when vmi.Spec.Domain.Features.Hyperv.EVMCS is set but the EVMCS.Enabled field is nil " classname="KubeVirt Tests Suite" time="167.006267929">
          <failure type="Failure">tests/hyperv_test.go:204
Timed out after 90.000s.
Timed out waiting for VMI testvmi-gv8wg to enter [Running] phase(s)
Expected
    &lt;v1.VirtualMachineInstancePhase&gt;: Scheduling
to be an element of
    &lt;[]v1.VirtualMachineInstancePhase | len:1, cap:1&gt;: ["Running"]
tests/libwait/wait.go:76</failure>
          <system-out>Forwarding from 127.0.0.1:6811 -&gt; 8443
Forwarding from [::1]:6811 -&gt; 8443
Handling connection for 6811
Forwarding from 127.0.0.1:7923 -&gt; 8443
Forwarding from [::1]:7923 -&gt; 8443
Handling connection for 7923
Forwarding from 127.0.0.1:7129 -&gt; 8443
Forwarding from [::1]:7129 -&gt; 8443
Handling connection for 7129
Forwarding from 127.0.0.1:6927 -&gt; 8443
Forwarding from [::1]:6927 -&gt; 8443
Handling connection for 6927
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:6164 -&gt; 8443
Forwarding from [::1]:6164 -&gt; 8443
Handling connection for 6164
Forwarding from 127.0.0.1:4786 -&gt; 8443
Forwarding from [::1]:4786 -&gt; 8443
Handling connection for 4786
Forwarding from 127.0.0.1:4851 -&gt; 8443
Forwarding from [::1]:4851 -&gt; 8443
Handling connection for 4851
Forwarding from 127.0.0.1:8954 -&gt; 8443
Forwarding from [::1]:8954 -&gt; 8443
Handling connection for 8954
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV re-enlightenment enabled  the vmi with EVMCS HyperV feature should have correct HyperV and cpu features auto filled Verify that features aren't applied when enabled is false" classname="KubeVirt Tests Suite" time="89.785387508" />
      <testcase name="[sig-compute] Hyper-V enlightenments VMI with HyperV passthrough should be usable and non-migratable" classname="KubeVirt Tests Suite" time="16.001659829" />
      <testcase name="[virtctl] [sig-storage]Memory dump Should be able to get and remove memory dump [test_id:9034] when creating a PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Memory dump Should be able to get and remove memory dump [test_id:11664]with an existing PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Memory dump [test_id:9035]Run multiple memory dumps" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Memory dump [test_id:9036]Run memory dump to creates a pvc, remove and run memory dump to create a different pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Memory dump [test_id:9344]should create memory dump and download it" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Memory dump [test_id:9343]should download existing memory dump" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]IgnitionData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with IgnitionData annotation with injected data [test_id:1616]should have injected data under firmware directory" classname="KubeVirt Tests Suite" time="42.387820165" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitNoCloud [test_id:1618]should take user-data from k8s secret" classname="KubeVirt Tests Suite" time="26.15207692" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitNoCloud [test_id:1615]should have cloud-init data from userDataBase64 source" classname="KubeVirt Tests Suite" time="28.550888953" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitNoCloud with injected ssh-key [test_id:1616]should have ssh-key under authorized keys" classname="KubeVirt Tests Suite" time="41.885531131" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive [test_id:3178]should have cloud-init data from userDataBase64 source" classname="KubeVirt Tests Suite" time="26.805232437" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive with injected ssh-key [test_id:3178]should have ssh-key under authorized keys" classname="KubeVirt Tests Suite" time="46.895510639" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive cloud-init instance-id should be stable" classname="KubeVirt Tests Suite" time="89.137558622" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitNoCloud networkData [test_id:3181]should have cloud-init network-config with NetworkData source" classname="KubeVirt Tests Suite" time="26.850250859" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitNoCloud networkData [test_id:3182]should have cloud-init network-config with NetworkDataBase64 source" classname="KubeVirt Tests Suite" time="28.836120692" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitNoCloud networkData [test_id:3183]should have cloud-init network-config from k8s secret" classname="KubeVirt Tests Suite" time="26.081193011" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive networkData [test_id:3184]should have cloud-init network-config with NetworkData source" classname="KubeVirt Tests Suite" time="26.272971771" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive networkData [test_id:4622]should have cloud-init meta_data with tagged devices" classname="KubeVirt Tests Suite" time="27.22228086" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive networkData [test_id:3185]should have cloud-init network-config with NetworkDataBase64 source" classname="KubeVirt Tests Suite" time="26.928111066" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive networkData [test_id:3186]should have cloud-init network-config from k8s secret" classname="KubeVirt Tests Suite" time="27.288390469" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive networkData [test_id:3187]should have cloud-init userdata and network-config from separate k8s secrets with lowercase labels" classname="KubeVirt Tests Suite" time="27.352084492" />
      <testcase name="[rfe_id:151][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]CloudInit UserData [rfe_id:151][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with cloudInitConfigDrive networkData [test_id:3187]should have cloud-init userdata and network-config from separate k8s secrets with camelCase labels" classname="KubeVirt Tests Suite" time="26.798808933" />
      <testcase name="[sig-storage]ObjectGraph with VM should return object graph for VM with PVC and Secret" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage]ObjectGraph with VM should filter dependencies using label selector" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage]ObjectGraph with VMI should return object graph for running VMI with launcher pod" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage]ObjectGraph with optional resources should exclude optional resources when IncludeOptionalNodes is false" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]IOThreads IOThreads Policies [test_id:4122]Should honor shared ioThreadsPolicy for single disk" classname="KubeVirt Tests Suite" time="16.426591493" />
      <testcase name="[sig-compute]IOThreads IOThreads Policies [test_id:864][ref_id:2065] Should honor a mix of shared and dedicated ioThreadsPolicy" classname="KubeVirt Tests Suite" time="22.642095254" />
      <testcase name="[sig-compute]IOThreads IOThreads Policies [ref_id:2065] should honor auto ioThreadPolicy [test_id:3097]for one CPU" classname="KubeVirt Tests Suite" time="33.030625703" />
      <testcase name="[sig-compute]IOThreads IOThreads Policies [ref_id:2065] should honor auto ioThreadPolicy [test_id:856] for two CPUs" classname="KubeVirt Tests Suite" time="33.024283036" />
      <testcase name="[sig-compute]IOThreads IOThreads Policies [ref_id:2065] should honor auto ioThreadPolicy [test_id:3095] for three CPUs" classname="KubeVirt Tests Suite" time="31.969847195" />
      <testcase name="[sig-compute]IOThreads IOThreads Policies [ref_id:2065] should honor auto ioThreadPolicy [test_id:3096]for four CPUs" classname="KubeVirt Tests Suite" time="32.005496844" />
      <testcase name="[sig-compute]IOThreads IOThreads Policies [test_id:4025]Should place io and emulator threads on the same pcpu with auto ioThreadsPolicy" classname="KubeVirt Tests Suite" time="367.462285349">
          <failure type="Failure">tests/vmi_iothreads_test.go:216
Timed out after 360.001s.
Timed out waiting for VMI testvmi-vrbmx to enter [Running] phase(s)
Expected
    &lt;v1.VirtualMachineInstancePhase&gt;: Scheduling
to be an element of
    &lt;[]v1.VirtualMachineInstancePhase | len:1, cap:1&gt;: ["Running"]
tests/libwait/wait.go:76</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]CloudInitHookSidecars VMI definition with CloudInit hook sidecar [test_id:3167]should successfully start with hook sidecar annotation" classname="KubeVirt Tests Suite" time="7.586154813" />
      <testcase name="[sig-compute]CloudInitHookSidecars VMI definition with CloudInit hook sidecar [test_id:3168]should call Collect and PreCloudInitIso on the hook sidecar" classname="KubeVirt Tests Suite" time="22.357667815" />
      <testcase name="[sig-compute]CloudInitHookSidecars VMI definition with CloudInit hook sidecar [test_id:3169]should have cloud-init user-data from sidecar" classname="KubeVirt Tests Suite" time="28.052417383" />
      <testcase name="[sig-compute] [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]Console [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with a serial console [test_id:1588]should return OS login" classname="KubeVirt Tests Suite" time="26.139703959" />
      <testcase name="[sig-compute] [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]Console [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with a serial console [test_id:1590]should be able to reconnect to console multiple times" classname="KubeVirt Tests Suite" time="22.283986071" />
      <testcase name="[sig-compute] [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]Console [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with a serial console [test_id:1591]should close console connection when new console connection is opened" classname="KubeVirt Tests Suite" time="136.121507086">
          <failure type="Failure">tests/compute/console.go:74
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 120 seconds
    120000000000
tests/compute/console.go:76</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute] [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]Console [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with a serial console [test_id:1592]should wait until the virtual machine is in running state and return a stream interface" classname="KubeVirt Tests Suite" time="15.561428408" />
      <testcase name="[sig-compute] [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]Console [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with a serial console [test_id:1593]should not be connected if scheduled to non-existing host" classname="KubeVirt Tests Suite" time="37.54393139" />
      <testcase name="[sig-compute] [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]Console [rfe_id:127][posneg:negative][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance without a serial console [test_id:4118]should run but not be connectable via the serial console" classname="KubeVirt Tests Suite" time="15.075745054" />
      <testcase name="[sig-compute] 64-Bit PCI hole should not exceed maximum size when annotation was set to true" classname="KubeVirt Tests Suite" time="24.946467315" />
      <testcase name="[sig-network] Infosource VMI with 3 interfaces should have the expected entries in vmi status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with Headless service should remain to able resolve the VM IP" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with bandwidth limitations [test_id:6968]should apply them and result in different migration durations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:6969]should be successfully migrate with a tablet device" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk should be successfully migrate with a WriteBack disk cache" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:6970]should migrate vmi with cdroms on various bus types" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk should migrate vmi with LiveMigrateIfPossible eviction strategy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk should migrate vmi and use Live Migration method with read-only disks" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk should migrate with a downwardMetrics [test_id:6971]disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk should migrate with a downwardMetrics [QUARANTINE] channel" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:6842]should migrate with TSC frequency set" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:4113]should be successfully migrate with cloud-init disk with devices on the root bus" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:9795]should migrate vmi with a usb disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:1783]should be successfully migrated multiple times with cloud-init disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:4746]should migrate even if virtqemud has restarted at some point." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:6972]should migrate to a persistent (non-transient) libvirt domain." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Alpine disk [test_id:6973]should be able to successfully migrate with a paused vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with an pending target pod should automatically cancel unschedulable migration after a timeout period" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with an pending target pod should automatically cancel pending target pod after a catch all timeout period" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   with auto converge enabled [test_id:3237]should complete a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with setting guest time [test_id:4114]should set an updated time after a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with an Alpine DataVolume [test_id:3239]should reject a migration of a vmi with a non-shared data volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with an Alpine DataVolume [test_id:1479][storage-req] should migrate a vmi with a shared block disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with an Alpine DataVolume [test_id:6974]should reject additional migrations on the same VMI if the first one is not finished" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  [storage-req]with an Alpine shared block volume PVC [test_id:1854]should migrate a VMI with shared and non-shared disks" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  [storage-req]with an Alpine shared block volume PVC [release-blocker][test_id:1377]should be successfully migrated multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  [storage-req]with an Alpine shared block volume PVC [test_id:3240]should be successfully with a cloud init" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Fedora shared NFS PVC (using nfs ipv4 address), cloud init and service account [test_id:2653] should be migrated successfully, using guest agent on VM with default migration configuration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with a Fedora shared NFS PVC (using nfs ipv4 address), cloud init and service account [test_id:6975] should have guest agent functional after migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to nonroot should migrate root implementation to nonroot [test_id:8609] with simple VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to nonroot should migrate root implementation to nonroot [test_id:8610] with DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to nonroot should migrate root implementation to nonroot [test_id:8611] with CD + CloudInit + SA + ConfigMap + Secret + DownwardAPI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to nonroot should migrate root implementation to nonroot [test_id:8612] with PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to root should migrate nonroot implementation to root with simple VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to root should migrate nonroot implementation to root with DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to root should migrate nonroot implementation to root with CD + CloudInit + SA + ConfigMap + Secret + DownwardAPI + Kernel Boot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration to root should migrate nonroot implementation to root with PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  migration security  with TLS disabled [test_id:6976] should be successfully migrated" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  migration security  with TLS disabled [test_id:6977]should not secure migrations with TLS" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  migration security with TLS enabled [test_id:2303][posneg:negative] should secure migrations with TLS" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration monitor without progress [test_id:2227] should abort a vmi migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration monitor [test_id:6978] Should detect a failed migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration monitor old finalized migrations should get garbage collected" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration monitor [test_id:6979]Target pod should exit after failed migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration monitor [test_id:6980]Migration should fail if target pod fails during target preparation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   migration monitor Migration should generate empty isos of the right size on the target" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  [storage-req]with an Alpine non-shared block volume PVC [test_id:1862][posneg:negative]should reject migrations for a non-migratable vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  live migration cancellation should be able to cancel a migration [sig-storage][test_id:2226] with ContainerDisk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  live migration cancellation should be able to cancel a migration [sig-storage][storage-req][test_id:2731] with RWX block disk from block volume PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  live migration cancellation [sig-compute][test_id:3241]Immediate migration cancellation after migration starts running cancel a migration by deleting vmim object" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  live migration cancellation [sig-compute][test_id:8584]Immediate migration cancellation before migration starts running cancel a migration by deleting vmim object" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  live migration cancellation when target pod cannot be scheduled and is stuck in Pending phase should be able to properly abort migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   with migration policies migration policy should override cluster-wide policy if defined" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   with migration policies migration policy should not affect cluster-wide policy if not defined" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance   with freePageReporting should be able to migrate" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Starting a VirtualMachineInstance  with unsupported machine type should prevent migration scheduling" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with sata disks [test_id:1853]VM with containerDisk + CloudInit + ServiceAccount + ConfigMap + Secret + DownwardAPI + External Kernel Boot + USB Disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration [test_id:8482] Migration Metrics exposed to prometheus during VM migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration  With Huge Pages should consume hugepages  [test_id:6983]hugepages-2Mi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration  With Huge Pages should consume hugepages  [test_id:6984]hugepages-1Gi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration  with CPU pinning and huge pages should not make migrations fail" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration  with CPU pinning and huge pages and NUMA passthrough should not make migrations fail" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with dedicated CPUs should successfully update a VMI's CPU set on migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with a dedicated migration network Should migrate over that network" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration should update MigrationState's MigrationConfiguration of VMI status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with a live-migration in flight there should always be a single active migration per VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration topology hints needs to be set when invtsc feature exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration topology hints needs to be set when HyperV reenlightenment is enabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration ResourceQuota rejection Should contain condition when migrating with quota that doesn't have resources for both source and target" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Virtiofs should migrate with a shared ConfigMap" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Virtiofs should migrate with a shared DV" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration VMI deletion during migration [sig-compute]should fail the migration and not prevent future migrations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Configurations when requesting virtio-transitional models [test_id:6957]should start and run the guest" classname="KubeVirt Tests Suite" time="26.349845985" />
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]for CPU and memory limits should [test_id:3110]lead to get the burstable QOS class assigned when limit and requests differ" classname="KubeVirt Tests Suite" time="7.728981806" />
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]for CPU and memory limits should [test_id:3111]lead to get the guaranteed QOS class assigned when limit and requests are identical" classname="KubeVirt Tests Suite" time="7.721117729" />
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]for CPU and memory limits should [test_id:3112]lead to get the guaranteed QOS class assigned when only limits are set" classname="KubeVirt Tests Suite" time="7.748715572" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2065][crit:medium][vendor:cnv-qe@redhat.com][level:component]with 3 CPU cores [test_id:1659]should report 3 cpu cores under guest OS" classname="KubeVirt Tests Suite" time="28.17115114" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2065][crit:medium][vendor:cnv-qe@redhat.com][level:component]with 3 CPU cores [test_id:1660]should report 3 sockets under guest OS" classname="KubeVirt Tests Suite" time="202.663702529">
          <failure type="Failure">tests/vmi_configuration_test.go:248
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/vmi_configuration_test.go:260</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:6350 -&gt; 8443
Forwarding from [::1]:6350 -&gt; 8443
Handling connection for 6350
Forwarding from 127.0.0.1:9746 -&gt; 8443
Forwarding from [::1]:9746 -&gt; 8443
Handling connection for 9746
Forwarding from 127.0.0.1:6305 -&gt; 8443
Forwarding from [::1]:6305 -&gt; 8443
Handling connection for 6305
Forwarding from 127.0.0.1:6415 -&gt; 8443
Forwarding from [::1]:6415 -&gt; 8443
Handling connection for 6415
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2065][crit:medium][vendor:cnv-qe@redhat.com][level:component]with 3 CPU cores [test_id:1661]should report 2 sockets from spec.domain.resources.requests under guest OS " classname="KubeVirt Tests Suite" time="202.711270638">
          <failure type="Failure">tests/vmi_configuration_test.go:269
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/vmi_configuration_test.go:282</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:7324 -&gt; 8443
Forwarding from [::1]:7324 -&gt; 8443
Handling connection for 7324
Forwarding from 127.0.0.1:10269 -&gt; 8443
Forwarding from [::1]:10269 -&gt; 8443
Handling connection for 10269
Forwarding from 127.0.0.1:5290 -&gt; 8443
Forwarding from [::1]:5290 -&gt; 8443
Handling connection for 5290
Forwarding from 127.0.0.1:10154 -&gt; 8443
Forwarding from [::1]:10154 -&gt; 8443
Handling connection for 10154
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2065][crit:medium][vendor:cnv-qe@redhat.com][level:component]with 3 CPU cores [test_id:1662]should report 2 sockets from spec.domain.resources.limits under guest OS " classname="KubeVirt Tests Suite" time="202.658356547">
          <failure type="Failure">tests/vmi_configuration_test.go:291
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/vmi_configuration_test.go:304</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:4446 -&gt; 8443
Forwarding from [::1]:4446 -&gt; 8443
Handling connection for 4446
Forwarding from 127.0.0.1:5626 -&gt; 8443
Forwarding from [::1]:5626 -&gt; 8443
Handling connection for 5626
Forwarding from 127.0.0.1:9632 -&gt; 8443
Forwarding from [::1]:9632 -&gt; 8443
Handling connection for 9632
Forwarding from 127.0.0.1:5571 -&gt; 8443
Forwarding from [::1]:5571 -&gt; 8443
Handling connection for 5571
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2065][crit:medium][vendor:cnv-qe@redhat.com][level:component]with 3 CPU cores [test_id:1663]should report 4 vCPUs under guest OS" classname="KubeVirt Tests Suite" time="203.671658064">
          <failure type="Failure">tests/vmi_configuration_test.go:313
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/vmi_configuration_test.go:325</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:8644 -&gt; 8443
Forwarding from [::1]:8644 -&gt; 8443
Handling connection for 8644
Forwarding from 127.0.0.1:5406 -&gt; 8443
Forwarding from [::1]:5406 -&gt; 8443
Handling connection for 5406
Forwarding from 127.0.0.1:5599 -&gt; 8443
Forwarding from [::1]:5599 -&gt; 8443
Handling connection for 5599
Forwarding from 127.0.0.1:7907 -&gt; 8443
Forwarding from [::1]:7907 -&gt; 8443
Handling connection for 7907
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2065][crit:medium][vendor:cnv-qe@redhat.com][level:component]with 3 CPU cores [test_id:1665]should map cores to virtio net queues" classname="KubeVirt Tests Suite" time="203.681355643">
          <failure type="Failure">tests/vmi_configuration_test.go:334
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/vmi_configuration_test.go:354</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:4637 -&gt; 8443
Forwarding from [::1]:4637 -&gt; 8443
Handling connection for 4637
Forwarding from 127.0.0.1:9411 -&gt; 8443
Forwarding from [::1]:9411 -&gt; 8443
Handling connection for 9411
Forwarding from 127.0.0.1:8937 -&gt; 8443
Forwarding from [::1]:8937 -&gt; 8443
Handling connection for 8937
Forwarding from 127.0.0.1:8426 -&gt; 8443
Forwarding from [::1]:8426 -&gt; 8443
Handling connection for 8426
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with no memory requested [test_id:3113]should failed to the VMI creation" classname="KubeVirt Tests Suite" time="7.42627339" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with BIOS bootloader method and no disk [test_id:5265]should find no bootable device by default" classname="KubeVirt Tests Suite" time="42.228165447" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with BIOS bootloader method and no disk [test_id:5266]should boot to NIC rom if a boot order was set on a network interface" classname="KubeVirt Tests Suite" time="42.235289894">
          <failure type="Failure">tests/vmi_configuration_test.go:413
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 30 seconds
    30000000000
tests/vmi_configuration_test.go:432</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with ACPI table Should configure guest ACPI SLIC with Secret file" classname="KubeVirt Tests Suite" time="23.734838262" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with ACPI table Should configure guest ACPI MSDM with Secret file" classname="KubeVirt Tests Suite" time="25.166243792" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2262][crit:medium][vendor:cnv-qe@redhat.com][level:component]with EFI bootloader method [test_id:1668]should use EFI without secure boot" classname="KubeVirt Tests Suite" time="202.65889738">
          <failure type="Failure">tests/vmi_configuration_test.go:558
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/libwait/wait.go:199</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:7483 -&gt; 8443
Forwarding from [::1]:7483 -&gt; 8443
Handling connection for 7483
Forwarding from 127.0.0.1:4787 -&gt; 8443
Forwarding from [::1]:4787 -&gt; 8443
Handling connection for 4787
Forwarding from 127.0.0.1:7312 -&gt; 8443
Forwarding from [::1]:7312 -&gt; 8443
Handling connection for 7312
Forwarding from 127.0.0.1:6091 -&gt; 8443
Forwarding from [::1]:6091 -&gt; 8443
Handling connection for 6091
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:2262][crit:medium][vendor:cnv-qe@redhat.com][level:component]with EFI bootloader method [test_id:4437]should enable EFI secure boot" classname="KubeVirt Tests Suite" time="189.091041312">
          <failure type="Failure">tests/vmi_configuration_test.go:559
Timed out after 180.000s.
Timed out waiting for VMI testvmi-8bt2d to enter [Running Failed] phase(s)
Expected
    &lt;v1.VirtualMachineInstancePhase&gt;: Scheduled
to be an element of
    &lt;[]v1.VirtualMachineInstancePhase | len:2, cap:2&gt;: ["Running", "Failed"]
tests/libwait/wait.go:76</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:6487 -&gt; 8443
Forwarding from [::1]:6487 -&gt; 8443
Handling connection for 6487
Forwarding from 127.0.0.1:6228 -&gt; 8443
Forwarding from [::1]:6228 -&gt; 8443
Handling connection for 6228
Forwarding from 127.0.0.1:7629 -&gt; 8443
Forwarding from [::1]:7629 -&gt; 8443
Handling connection for 7629
Forwarding from 127.0.0.1:9778 -&gt; 8443
Forwarding from [::1]:9778 -&gt; 8443
Handling connection for 9778
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:989]test cpu_allocation_ratio virt-launchers pod cpu requests should be proportional to the number of vCPUs" classname="KubeVirt Tests Suite" time="16.04784356" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component]Support memory over commitment test [test_id:732]Check Free memory on the VMI" classname="KubeVirt Tests Suite" time="25.421534677" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3078][crit:medium][vendor:cnv-qe@redhat.com][level:component]with usb controller [test_id:3117]should start the VMI with usb controller when usb device is present" classname="KubeVirt Tests Suite" time="23.656025334" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3078][crit:medium][vendor:cnv-qe@redhat.com][level:component]with usb controller [test_id:3117]should start the VMI with usb controller when input device doesn't have bus" classname="KubeVirt Tests Suite" time="25.657706644" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3078][crit:medium][vendor:cnv-qe@redhat.com][level:component]with usb controller [test_id:3118]should start the VMI without usb controller" classname="KubeVirt Tests Suite" time="23.20579593" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3077][crit:medium][vendor:cnv-qe@redhat.com][level:component]with input devices [test_id:2642]should failed to start the VMI with wrong type of input device" classname="KubeVirt Tests Suite" time="7.438547065" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3077][crit:medium][vendor:cnv-qe@redhat.com][level:component]with input devices [test_id:3074]should failed to start the VMI with wrong bus of input device" classname="KubeVirt Tests Suite" time="7.433660485" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3077][crit:medium][vendor:cnv-qe@redhat.com][level:component]with input devices [test_id:3072]should start the VMI with tablet input device with virtio bus" classname="KubeVirt Tests Suite" time="26.4810618" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:3077][crit:medium][vendor:cnv-qe@redhat.com][level:component]with input devices [test_id:3073]should start the VMI with tablet input device with usb bus" classname="KubeVirt Tests Suite" time="29.876662608" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with namespace different from provided should fail admission" classname="KubeVirt Tests Suite" time="37.470950087" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with hugepages should consume hugepages  [test_id:1671]hugepages-2Mi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with hugepages should consume hugepages  [test_id:1672]hugepages-1Gi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with hugepages should consume hugepages  [test_id:1672]hugepages-2Mi with guest memory set explicitly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with hugepages with unsupported page size [test_id:1673]should failed to schedule the pod" classname="KubeVirt Tests Suite" time="8.513360303" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:893][crit:medium][vendor:cnv-qe@redhat.com][level:component]with rng [test_id:1674]should have the virtio rng device present when present" classname="KubeVirt Tests Suite" time="23.453448037" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:893][crit:medium][vendor:cnv-qe@redhat.com][level:component]with rng [test_id:1675]should not have the virtio rng device when not present" classname="KubeVirt Tests Suite" time="22.544380724" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:1676]should have attached a guest agent channel by default" classname="KubeVirt Tests Suite" time="17.428961701" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:1677]VMI condition should signal agent presence" classname="KubeVirt Tests Suite" time="41.593126293" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:4625]should remove condition when agent is off" classname="KubeVirt Tests Suite" time="52.504958678" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent with cluster config changes [test_id:5267]VMI condition should signal unsupported agent presence" classname="KubeVirt Tests Suite" time="115.190544849" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent with cluster config changes [test_id:6958]VMI condition should not signal unsupported agent presence for optional commands" classname="KubeVirt Tests Suite" time="114.309590411" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:4626]should have guestosinfo in status when agent is present" classname="KubeVirt Tests Suite" time="41.603201963" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:4627]should return the whole data when agent is present" classname="KubeVirt Tests Suite" time="42.617803872" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:4628]should not return the whole data when agent is not present" classname="KubeVirt Tests Suite" time="46.542525002" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:4629]should return user list" classname="KubeVirt Tests Suite" time="54.475925743" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with guestAgent [test_id:4630]should return filesystem list" classname="KubeVirt Tests Suite" time="42.650489753" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with serial-number [test_id:3121]should have serial-number set when present" classname="KubeVirt Tests Suite" time="24.226155823" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with TSC timer [test_id:6843]should set a TSC frequency and have the CPU flag available in the guest" classname="KubeVirt Tests Suite" time="7.466726207">
          <failure type="Failure">tests/vmi_configuration_test.go:1170
To run this test at least one node should support invtsc feature
Expected
    &lt;bool&gt;: false
to be true
tests/vmi_configuration_test.go:1172</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with Clock and timezone [sig-compute][test_id:5268]guest should see timezone" classname="KubeVirt Tests Suite" time="26.064968709" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition using defaultRuntimeClass configuration should apply runtimeClassName to pod when set" classname="KubeVirt Tests Suite" time="77.38309344" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition should not apply runtimeClassName to pod when not set" classname="KubeVirt Tests Suite" time="11.911233406000001" />
      <testcase name="[sig-compute]Configurations VirtualMachineInstance definition with geust-to-request memory  should add guest-to-memory headroom" classname="KubeVirt Tests Suite" time="75.675028755" />
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU spec [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]when CPU model defined [test_id:1678]should report defined CPU model" classname="KubeVirt Tests Suite" time="367.643376544">
          <failure type="Failure">tests/vmi_configuration_test.go:1395
Unexpected Warning event received: testvmi-ws97x,fbb59a01-acce-4f81-a962-a57c41a3a84c: server error. command SyncVMI failed: "LibvirtError(Code=1, Domain=10, Message='internal error: QEMU unexpectedly closed the monitor (vm='kubevirt-test-default1_testvmi-ws97x'): 2025-11-08T01:31:24.941384Z qemu-system-x86_64: -device {\"driver\":\"pcie-root-port\",\"port\":8,\"chassis\":1,\"id\":\"pci.1\",\"bus\":\"pcie.0\",\"multifunction\":true,\"addr\":\"0x1\"}: MSI-X is not supported by interrupt controller')"
Expected
    &lt;string&gt;: Warning
not to equal
    &lt;string&gt;: Warning
tests/watcher/watcher.go:195</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU spec [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]when CPU model equals to passthrough [test_id:1679]should report exactly the same model as node CPU" classname="KubeVirt Tests Suite" time="201.458236075">
          <failure type="Failure">tests/vmi_configuration_test.go:1419
Expected success, but got an error:
    &lt;expect.TimeoutError&gt;: 
    expect: timer expired after 180 seconds
    180000000000
tests/vmi_configuration_test.go:1433</failure>
          <system-out>&#65533;[34mSent:&#65533;[39m "\n"
&#65533;[34mSent:&#65533;[39m "\n"
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU spec [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]when CPU model not defined [test_id:1680]should report CPU model from libvirt capabilities" classname="KubeVirt Tests Suite" time="27.790110042" />
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU spec when CPU features defined [test_id:3123]should start a Virtual Machine with matching features" classname="KubeVirt Tests Suite" time="28.223908209" />
      <testcase name="[sig-compute]Configurations [rfe_id:2869][crit:medium][vendor:cnv-qe@redhat.com][level:component]with machine type settings [test_id:3124]should set status.machine to the resolved QEMU machine type after VMI start" classname="KubeVirt Tests Suite" time="82.352272444" />
      <testcase name="[sig-compute]Configurations [rfe_id:2869][crit:medium][vendor:cnv-qe@redhat.com][level:component]with machine type settings [test_id:3125]should allow creating VM without Machine defined" classname="KubeVirt Tests Suite" time="83.76146524" />
      <testcase name="[sig-compute]Configurations [rfe_id:2869][crit:medium][vendor:cnv-qe@redhat.com][level:component]with machine type settings [test_id:6964]should allow creating VM defined with Machine with an empty Type" classname="KubeVirt Tests Suite" time="84.773483064" />
      <testcase name="[sig-compute]Configurations [rfe_id:2869][crit:medium][vendor:cnv-qe@redhat.com][level:component]with machine type settings [test_id:3126]should set machine type from kubevirt-config" classname="KubeVirt Tests Suite" time="119.554435171" />
      <testcase name="[sig-compute]Configurations with a custom scheduler [test_id:4631]should set the custom scheduler on the pod" classname="KubeVirt Tests Suite" time="7.537421868" />
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU request settings [test_id:3127]should set CPU request from VMI spec" classname="KubeVirt Tests Suite" time="7.737348207" />
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU request settings [test_id:3128]should set CPU request when it is not provided" classname="KubeVirt Tests Suite" time="7.804931061" />
      <testcase name="[sig-compute]Configurations [rfe_id:140][crit:medium][vendor:cnv-qe@redhat.com][level:component]with CPU request settings [test_id:3129]should set CPU request from kubevirt-config" classname="KubeVirt Tests Suite" time="83.50191677" />
      <testcase name="[sig-compute]Configurations with automatic CPU limit configured in the CR should not set a CPU limit if the namespace doesn't match the selector" classname="KubeVirt Tests Suite" time="81.491804412" />
      <testcase name="[sig-compute]Configurations with automatic CPU limit configured in the CR should set a CPU limit if the namespace matches the selector" classname="KubeVirt Tests Suite" time="77.322375396" />
      <testcase name="[sig-compute]Configurations using automatic resource limits when there is no ResourceQuota with memory and cpu limits associated with the creation namespace [test_id:11215]should not automatically set memory limits in the virt-launcher pod" classname="KubeVirt Tests Suite" time="7.7452011469999995" />
      <testcase name="[sig-compute]Configurations using automatic resource limits when a ResourceQuota with memory and cpu limits is associated to the creation namespace [test_id:11214]should set cpu and memory limit in the virt-launcher pod" classname="KubeVirt Tests Suite" time="8.043913887" />
      <testcase name="[sig-compute]Configurations [rfe_id:898][crit:medium][vendor:cnv-qe@redhat.com][level:component]New VirtualMachineInstance with all supported drives [test_id:1682]should have all the device nodes" classname="KubeVirt Tests Suite" time="29.865987668" />
      <testcase name="[sig-compute]Configurations [rfe_id:898][crit:medium][vendor:cnv-qe@redhat.com][level:component]New VirtualMachineInstance with all supported drives [test_id:3906]should configure custom Pci address" classname="KubeVirt Tests Suite" time="28.686330475" />
      <testcase name="[sig-compute]Configurations [rfe_id:898][crit:medium][vendor:cnv-qe@redhat.com][level:component]New VirtualMachineInstance with all supported drives [test_id:1020]should not create the VM with wrong PCI address" classname="KubeVirt Tests Suite" time="19.138679126" />
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:1685]non master node should have a cpumanager label" classname="KubeVirt Tests Suite" time="8.867454862">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:5708 -&gt; 8443
Forwarding from [::1]:5708 -&gt; 8443
Handling connection for 5708
Forwarding from 127.0.0.1:6114 -&gt; 8443
Forwarding from [::1]:6114 -&gt; 8443
Handling connection for 6114
Forwarding from 127.0.0.1:9902 -&gt; 8443
Forwarding from [::1]:9902 -&gt; 8443
Handling connection for 9902
Forwarding from 127.0.0.1:4888 -&gt; 8443
Forwarding from [::1]:4888 -&gt; 8443
Handling connection for 4888
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:991]should be scheduled on a node with running cpu manager" classname="KubeVirt Tests Suite" time="8.864612287">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:9306 -&gt; 8443
Forwarding from [::1]:9306 -&gt; 8443
Handling connection for 9306
Forwarding from 127.0.0.1:8176 -&gt; 8443
Forwarding from [::1]:8176 -&gt; 8443
Handling connection for 8176
Forwarding from 127.0.0.1:6883 -&gt; 8443
Forwarding from [::1]:6883 -&gt; 8443
Handling connection for 6883
Forwarding from 127.0.0.1:8601 -&gt; 8443
Forwarding from [::1]:8601 -&gt; 8443
Handling connection for 8601
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:4632]should be able to start a vm with guest memory different from requested and keep guaranteed qos" classname="KubeVirt Tests Suite" time="8.868502807">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:7741 -&gt; 8443
Forwarding from [::1]:7741 -&gt; 8443
Handling connection for 7741
Forwarding from 127.0.0.1:5328 -&gt; 8443
Forwarding from [::1]:5328 -&gt; 8443
Handling connection for 5328
Forwarding from 127.0.0.1:10276 -&gt; 8443
Forwarding from [::1]:10276 -&gt; 8443
Handling connection for 10276
Forwarding from 127.0.0.1:9123 -&gt; 8443
Forwarding from [::1]:9123 -&gt; 8443
Handling connection for 9123
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:4023]should start a vmi with dedicated cpus and isolated emulator thread  with explicit resources set" classname="KubeVirt Tests Suite" time="8.933520055">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:4641 -&gt; 8443
Forwarding from [::1]:4641 -&gt; 8443
Handling connection for 4641
Forwarding from 127.0.0.1:6413 -&gt; 8443
Forwarding from [::1]:6413 -&gt; 8443
Handling connection for 6413
Forwarding from 127.0.0.1:7014 -&gt; 8443
Forwarding from [::1]:7014 -&gt; 8443
Handling connection for 7014
Forwarding from 127.0.0.1:9702 -&gt; 8443
Forwarding from [::1]:9702 -&gt; 8443
Handling connection for 9702
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:4023]should start a vmi with dedicated cpus and isolated emulator thread without resource requirements set" classname="KubeVirt Tests Suite" time="8.875677046">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:5099 -&gt; 8443
Forwarding from [::1]:5099 -&gt; 8443
Handling connection for 5099
Forwarding from 127.0.0.1:5498 -&gt; 8443
Forwarding from [::1]:5498 -&gt; 8443
Handling connection for 5498
Forwarding from 127.0.0.1:9085 -&gt; 8443
Forwarding from [::1]:9085 -&gt; 8443
Handling connection for 9085
Forwarding from 127.0.0.1:6046 -&gt; 8443
Forwarding from [::1]:6046 -&gt; 8443
Handling connection for 6046
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:4024]should fail the vmi creation if IsolateEmulatorThread requested without dedicated cpus" classname="KubeVirt Tests Suite" time="8.86709824">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:5186 -&gt; 8443
Forwarding from [::1]:5186 -&gt; 8443
Handling connection for 5186
Forwarding from 127.0.0.1:9853 -&gt; 8443
Forwarding from [::1]:9853 -&gt; 8443
Handling connection for 9853
Forwarding from 127.0.0.1:7492 -&gt; 8443
Forwarding from [::1]:7492 -&gt; 8443
Handling connection for 7492
Forwarding from 127.0.0.1:6867 -&gt; 8443
Forwarding from [::1]:6867 -&gt; 8443
Handling connection for 6867
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:802]should configure correct number of vcpus with requests.cpus" classname="KubeVirt Tests Suite" time="8.871186527">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:7126 -&gt; 8443
Forwarding from [::1]:7126 -&gt; 8443
Handling connection for 7126
Forwarding from 127.0.0.1:4711 -&gt; 8443
Forwarding from [::1]:4711 -&gt; 8443
Handling connection for 4711
Forwarding from 127.0.0.1:4805 -&gt; 8443
Forwarding from [::1]:4805 -&gt; 8443
Handling connection for 4805
Forwarding from 127.0.0.1:8229 -&gt; 8443
Forwarding from [::1]:8229 -&gt; 8443
Handling connection for 8229
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:1688]should fail the vmi creation if the requested resources are inconsistent" classname="KubeVirt Tests Suite" time="8.969793362">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:7813 -&gt; 8443
Forwarding from [::1]:7813 -&gt; 8443
Handling connection for 7813
Forwarding from 127.0.0.1:5073 -&gt; 8443
Forwarding from [::1]:5073 -&gt; 8443
Handling connection for 5073
Forwarding from 127.0.0.1:6003 -&gt; 8443
Forwarding from [::1]:6003 -&gt; 8443
Handling connection for 6003
Forwarding from 127.0.0.1:9786 -&gt; 8443
Forwarding from [::1]:9786 -&gt; 8443
Handling connection for 9786
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:1689]should fail the vmi creation if cpu is not an integer" classname="KubeVirt Tests Suite" time="8.977848215">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:9061 -&gt; 8443
Forwarding from [::1]:9061 -&gt; 8443
Handling connection for 9061
Forwarding from 127.0.0.1:10173 -&gt; 8443
Forwarding from [::1]:10173 -&gt; 8443
Handling connection for 10173
Forwarding from 127.0.0.1:5216 -&gt; 8443
Forwarding from [::1]:5216 -&gt; 8443
Handling connection for 5216
Forwarding from 127.0.0.1:6125 -&gt; 8443
Forwarding from [::1]:6125 -&gt; 8443
Handling connection for 6125
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:1690]should fail the vmi creation if Guaranteed QOS cannot be set" classname="KubeVirt Tests Suite" time="8.879640688">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:4802 -&gt; 8443
Forwarding from [::1]:4802 -&gt; 8443
Handling connection for 4802
Forwarding from 127.0.0.1:5477 -&gt; 8443
Forwarding from [::1]:5477 -&gt; 8443
Handling connection for 5477
Forwarding from 127.0.0.1:6197 -&gt; 8443
Forwarding from [::1]:6197 -&gt; 8443
Handling connection for 6197
Forwarding from 127.0.0.1:7154 -&gt; 8443
Forwarding from [::1]:7154 -&gt; 8443
Handling connection for 7154
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning with cpu pinning enabled [test_id:830]should start a vm with no cpu pinning after a vm with cpu pinning on same node" classname="KubeVirt Tests Suite" time="8.86598069">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:9957 -&gt; 8443
Forwarding from [::1]:9957 -&gt; 8443
Handling connection for 9957
Forwarding from 127.0.0.1:6309 -&gt; 8443
Forwarding from [::1]:6309 -&gt; 8443
Handling connection for 6309
Forwarding from 127.0.0.1:6981 -&gt; 8443
Forwarding from [::1]:6981 -&gt; 8443
Handling connection for 6981
Forwarding from 127.0.0.1:6376 -&gt; 8443
Forwarding from [::1]:6376 -&gt; 8443
Handling connection for 6376
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning cpu pinning with fedora images, dedicated and non dedicated cpu should be possible on same node via spec.domain.cpu.cores [test_id:829]should start a vm with no cpu pinning after a vm with cpu pinning on same node" classname="KubeVirt Tests Suite" time="8.868470153">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:5158 -&gt; 8443
Forwarding from [::1]:5158 -&gt; 8443
Handling connection for 5158
Forwarding from 127.0.0.1:9372 -&gt; 8443
Forwarding from [::1]:9372 -&gt; 8443
Handling connection for 9372
Forwarding from 127.0.0.1:8170 -&gt; 8443
Forwarding from [::1]:8170 -&gt; 8443
Handling connection for 8170
Forwarding from 127.0.0.1:7776 -&gt; 8443
Forwarding from [::1]:7776 -&gt; 8443
Handling connection for 7776
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:897][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance with CPU pinning cpu pinning with fedora images, dedicated and non dedicated cpu should be possible on same node via spec.domain.cpu.cores [test_id:832]should start a vm with cpu pinning after a vm with no cpu pinning on same node" classname="KubeVirt Tests Suite" time="8.870048777000001">
          <failure type="Failure">tests/vmi_configuration_test.go:1832
CPU pinning test that requires multiple nodes when only one node is present. You can filter by "requires-two-worker-nodes-with-cpu-manager" label
tests/vmi_configuration_test.go:1836</failure>
          <system-out>On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:5806 -&gt; 8443
Forwarding from [::1]:5806 -&gt; 8443
Handling connection for 5806
Forwarding from 127.0.0.1:8793 -&gt; 8443
Forwarding from [::1]:8793 -&gt; 8443
Handling connection for 8793
Forwarding from 127.0.0.1:8685 -&gt; 8443
Forwarding from [::1]:8685 -&gt; 8443
Handling connection for 8685
Forwarding from 127.0.0.1:5960 -&gt; 8443
Forwarding from [::1]:5960 -&gt; 8443
Handling connection for 5960
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]Configurations [rfe_id:2926][crit:medium][vendor:cnv-qe@redhat.com][level:component]Check Chassis value [test_id:2927]Test Chassis value in a newly created VM" classname="KubeVirt Tests Suite" time="46.06218586" />
      <testcase name="[sig-compute]Configurations [rfe_id:2926][crit:medium][vendor:cnv-qe@redhat.com][level:component]Check SMBios with default and custom values [test_id:2751]test default SMBios" classname="KubeVirt Tests Suite" time="37.417853353" />
      <testcase name="[sig-compute]Configurations Custom PCI Addresses configuration should configure custom pci address [test_id:5269]across all available PCI root bus slots" classname="KubeVirt Tests Suite" time="122.663908335" />
      <testcase name="[sig-compute]Configurations Custom PCI Addresses configuration should configure custom pci address [test_id:5270]across all available PCI functions of a single slot" classname="KubeVirt Tests Suite" time="45.839708028" />
      <testcase name="[sig-compute]Configurations Check KVM CPUID advertisement [test_id:5271]test cpuid hidden" classname="KubeVirt Tests Suite" time="38.811985802" />
      <testcase name="[sig-compute]Configurations virt-launcher processes memory usage should be lower than allocated size" classname="KubeVirt Tests Suite" time="42.072344331" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are provided [test_id:3170]should allow access to vm subresource endpoint" classname="KubeVirt Tests Suite" time="7.859639452" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are provided [test_id:3172]should allow access to version subresource endpoint" classname="KubeVirt Tests Suite" time="7.488871051" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are provided should allow access to guestfs subresource endpoint" classname="KubeVirt Tests Suite" time="7.484152346" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are provided should allow access to expand-vm-spec subresource" classname="KubeVirt Tests Suite" time="7.486573659" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are not provided [test_id:3171]should block access to vm subresource endpoint" classname="KubeVirt Tests Suite" time="7.564864329" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are not provided [test_id:3173]should allow access to version subresource endpoint" classname="KubeVirt Tests Suite" time="7.487574386" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are not provided should allow access to guestfs subresource endpoint" classname="KubeVirt Tests Suite" time="7.488685601" />
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] Rbac authorization when correct permissions are not provided should block access to expand-vm-spec subresource" classname="KubeVirt Tests Suite" time="7.489051697" />
      <testcase name="[sig-compute]VM Affinity Updating VMs node affinity [test_id:11208]should successfully update node selector" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM Affinity Updating VMs node affinity [test_id:11209]should successfully update node affinity" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates [test_id:4099] should be rotated when a new CA is created" classname="KubeVirt Tests Suite" time="27.369052364" />
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates [sig-compute][test_id:4100] should be valid during the whole rotation process" classname="KubeVirt Tests Suite" time="95.222707394" />
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates should be rotated when deleted for  [test_id:4101] virt-operator" classname="KubeVirt Tests Suite" time="11.007445435" />
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates should be rotated when deleted for  [test_id:4103] virt-api" classname="KubeVirt Tests Suite" time="9.975220164" />
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates should be rotated when deleted for  [test_id:4104] virt-controller" classname="KubeVirt Tests Suite" time="9.918219683" />
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates should be rotated when deleted for  [test_id:4105] virt-handlers client side" classname="KubeVirt Tests Suite" time="12.006077263" />
      <testcase name="[sig-compute] Infrastructure [rfe_id:4102][crit:medium][vendor:cnv-qe@redhat.com][level:component]certificates should be rotated when deleted for  [test_id:4106] virt-handlers server side" classname="KubeVirt Tests Suite" time="9.92042023" />
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin should apply the interface configuration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin TCP without port specification connectivity [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin TCP without port specification connectivity [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin TCP with port specification connectivity [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin TCP with port specification connectivity [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin TCP with low port specification connectivity [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin TCP with low port specification connectivity [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin UDP connectivity [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin UDP connectivity [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin egress connectivity should be able to reach the outside world [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin egress connectivity should be able to reach the outside world" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin migration connectivity should be preserved [IPv4]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  VirtualMachineInstance with passt network binding plugin migration connectivity should be preserved [IPv6]" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Slirp VMI with SLIRP interface, custom mac and port is configured correctly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration triggered by evacuation during evacuation should add eviction-in-progress annotation to source virt-launcher pod" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration triggered by evacuation during evacuation when evacuating fails should not remove eviction-in-progress annotation from source virt-launcher pod" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration triggered by evacuation during evacuation when evacuating fails retrying immediately should be blocked by the migration backoff" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration triggered by evacuation during evacuation when evacuating fails after a successful migration backoff should be cleared" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration triggered by evacuation during evacuation VirtualMachineInstanceEvictionRequested condition should set VirtualMachineInstanceEvictionRequested condition when VMI marked for eviction" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration triggered by evacuation during evacuation VirtualMachineInstanceEvictionRequested condition when eviction fails should keep VirtualMachineInstanceEvictionRequested condition when migration fails" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]SecurityFeatures Check virt-launcher securityContext With selinuxLauncherType as container_t [test_id:2953][test_id:2895]Ensure virt-launcher pod securityContext type is correctly set and not privileged" classname="KubeVirt Tests Suite" time="87.591991263" />
      <testcase name="[sig-compute]SecurityFeatures Check virt-launcher securityContext With selinuxLauncherType as container_t [test_id:4297]Make sure qemu processes are MCS constrained" classname="KubeVirt Tests Suite" time="88.341355357">
          <failure type="Panic">tests/security_features_test.go:95
Test Panicked
GOROOT/src/runtime/panic.go:115

Panic: runtime error: index out of range [2] with length 1

Full stack:
tests/go_default_test_test.init.func14.2.2.3()
	tests/security_features_test.go:118 +0x679</failure>
          <system-out>Forwarding from 127.0.0.1:9244 -&gt; 8443
Forwarding from [::1]:9244 -&gt; 8443
Handling connection for 9244
Forwarding from 127.0.0.1:4595 -&gt; 8443
Forwarding from [::1]:4595 -&gt; 8443
Handling connection for 4595
Forwarding from 127.0.0.1:4486 -&gt; 8443
Forwarding from [::1]:4486 -&gt; 8443
Handling connection for 4486
Forwarding from 127.0.0.1:7172 -&gt; 8443
Forwarding from [::1]:7172 -&gt; 8443
Handling connection for 7172
On failure, artifacts will be collected in /home/ubuntu/git/ARO/kubevirt/_out/artifacts/k8s-reporter/12_*
Global test cleanup started.
Forwarding from 127.0.0.1:7757 -&gt; 8443
Forwarding from [::1]:7757 -&gt; 8443
Handling connection for 7757
Forwarding from 127.0.0.1:6171 -&gt; 8443
Forwarding from [::1]:6171 -&gt; 8443
Handling connection for 6171
Forwarding from 127.0.0.1:7081 -&gt; 8443
Forwarding from [::1]:7081 -&gt; 8443
Handling connection for 7081
Forwarding from 127.0.0.1:8534 -&gt; 8443
Forwarding from [::1]:8534 -&gt; 8443
Handling connection for 8534
Global test cleanup ended.
</system-out>
      </testcase>
      <testcase name="[sig-compute]SecurityFeatures Check virt-launcher securityContext With selinuxLauncherType defined as spc_t [test_id:3787]Should honor custom SELinux type for virt-launcher" classname="KubeVirt Tests Suite" time="94.257569119" />
      <testcase name="[sig-compute]SecurityFeatures Check virt-launcher capabilities [test_id:4300]has precisely the documented extra capabilities relative to a regular user pod" classname="KubeVirt Tests Suite" time="22.231578242" />
      <testcase name="[sig-compute]SecurityFeatures The VMI SELinux context status Should get set and stay the the same after a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Primary Pod Network Status VMI connected to the pod network using bridge binding when Guest Agent exists should report PodIP/s on interface status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Primary Pod Network Status VMI connected to the pod network using masquerade binding when Guest Agent exists [test_id:4153]should report PodIP/s as its own on interface status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Primary Pod Network Status VMI connected to the pod network using masquerade binding when no Guest Agent exists should report PodIP as its own on interface status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Windows VirtualMachineInstance with winrm connection [ref_id:139]VMI is created [test_id:240]should have correct UUID" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Windows VirtualMachineInstance with winrm connection [ref_id:139]VMI is created [test_id:3159]should have default masquerade IP" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Windows VirtualMachineInstance with winrm connection [ref_id:139]VMI is created [test_id:3160]should have the domain set properly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Windows VirtualMachineInstance with winrm connection VMI with subdomain is created should have the domain set properly with subdomain" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Windows VirtualMachineInstance with winrm connection with bridge binding should be recognized by other pods in cluster" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure CRDs [test_id:5177]Should have structural schema" classname="KubeVirt Tests Suite" time="7.899914428" />
      <testcase name="[virtctl] [sig-storage]ImageUpload [test_id:4621]Upload an imag start a VMI should succeed DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload [test_id:4621]Upload an imag start a VMI should succeed PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload [test_id:11655]Create upload volume with force-bind flag should succeed DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload [test_id:11655]Create upload volume with force-bind flag should succeed PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload Create upload volume using volume-mode flag should succeed [test_id:10671]block volumeMode" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload Create upload volume using volume-mode flag should succeed [test_id:10672]filesystem volumeMode" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload [test_id:11656]Upload fails when DV is in WFFC/PendingPopulation phase but uploads after consumer is created" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload Create upload archive volume [test_id:11657]Should succeed DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload Create upload archive volume [test_id:11657]Should succeed PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload Create upload archive volume [test_id:11658]fails when provisioning fails DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]ImageUpload Create upload archive volume [test_id:11658]fails when provisioning fails PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Metrics Prometheus metrics should contain virt components metrics" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Metrics Prometheus metrics should contain VNIC metrics" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Metrics Prometheus metrics should contain disk metrics" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Metrics Prometheus metrics should contain label metrics" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Metrics Workqueue metrics should not contain controller-runtime workqueue metrics for virt workloads" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Metrics Workqueue metrics kubevirt workqueue metrics should include controllers names" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Live Migration All containers should complete in source virt-launcher pod after migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface SSH traffic With VMI having explicit ports specified should ssh to VMI with Istio proxy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface SSH traffic With VMI having no explicit ports specified should ssh to VMI with Istio proxy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With VMI having explicit ports specified request to VMI should reach HTTP server on service declared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With VMI having explicit ports specified request to VMI should reach HTTP server on service undeclared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With VMI having no explicit ports specified request to VMI should reach HTTP server on service declared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With VMI having no explicit ports specified request to VMI should reach HTTP server on service undeclared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With VMI having no explicit ports specified Should not be able to reach service running on Istio restricted port" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having explicit ports specified client outside mesh should NOT reach VMI HTTP server on service declared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having explicit ports specified client outside mesh should NOT reach VMI HTTP server on service undeclared port on VMI with explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having no explicit ports specified client outside mesh should NOT reach VMI HTTP server on service declared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Inbound traffic With PeerAuthentication enforcing mTLS With VMI having no explicit ports specified client outside mesh should NOT reach VMI HTTP server on service undeclared port on VMI with no explicit ports" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Outbound traffic VMI with explicit ports Should be able to reach http server outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Outbound traffic VMI with no explicit ports Should be able to reach http server outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Outbound traffic With Sidecar allowing only registered external services VMI with explicit ports Should not be able to reach http service outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network]  Istio with masquerade binding Virtual Machine with istio supported interface Outbound traffic With Sidecar allowing only registered external services VMI with no explicit ports Should not be able to reach http service outside of mesh" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine [test_id:3007][QUARANTINE] Should force restart a VM with terminationGracePeriodSeconds&gt;0" classname="KubeVirt Tests Suite" time="92.062413501" />
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine should force stop a VM with terminationGracePeriodSeconds&gt;0 with Fedora based VMI" classname="KubeVirt Tests Suite" time="25.286585369" />
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine should force stop a VM with terminationGracePeriodSeconds&gt;0 with unresponsive empty-disk VMI" classname="KubeVirt Tests Suite" time="22.130157223" />
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine with paused vmi [test_id:4598][test_id:3060]should signal paused/unpaused state with condition" classname="KubeVirt Tests Suite" time="28.459100877" />
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine with paused vmi [test_id:3085]should be stopped successfully" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine with paused vmi [test_id:3229]should gracefully handle being started again" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine with paused vmi [test_id:3226]should be restarted successfully into unpaused state" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine should not change anything if dry-run option is passed [test_id:7530]when starting a VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine should not change anything if dry-run option is passed when stopping a VM [test_id:7529]with no other flags" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine should not change anything if dry-run option is passed when stopping a VM [test_id:7604]with grace period" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1177][crit:medium] VirtualMachine should not change anything if dry-run option is passed [test_id:7528]when restarting a VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance with VNC connection [test_id:1611]should allow accessing the VNC device multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]should upgrade websocket connection which look like coming from a browser [test_id:1612]for vnc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]should upgrade websocket connection which look like coming from a browser [test_id:1613]for serial console" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance [test_id:1614]should upgrade websocket connections without a subprotocol given" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance Dual connection. Validate default behavior and with 'preserve-session' option Second session without preserve" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance Dual connection. Validate default behavior and with 'preserve-session' option Second session with preserve" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance Dual connection. Validate default behavior and with 'preserve-session' option First with preserve, Second session without preserve" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component]A new VirtualMachineInstance Dual connection. Validate default behavior and with 'preserve-session' option First with preserve, Second session with preserve" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Offline VM Should add volumes on an offline VM with DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Offline VM Should add volumes on an offline VM with PersistentVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Offline VM with a block volume Should be able to boot from block volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Offline VM with a block volume Should start with a hotplug block DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Offline VM with a block volume Should start with a hotplug block PersistentVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Offline VM with a block volume Should preserve access to block devices if virt-handler crashes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug WFFC storage Should be able to boot from WFFC local storage" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug WFFC storage Should be able to add and use WFFC local storage" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI should add/remove volume with DataVolume immediate attach, VMI directly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI should add/remove volume with PersistentVolume immediate attach, VMI directly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI should not add/remove volume with dry run with DataVolume immediate attach, VMI directly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI should not add/remove volume with dry run with PersistentVolume immediate attach, VMI directly" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI Should be able to add and remove and re-add multiple volumes with VMIs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with legacy hotplug should add/remove volume with DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with legacy hotplug should add/remove volume with PersistentVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with legacy hotplug should add/remove volume with DataVolume wait for VM to finish starting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with legacy hotplug should add/remove volume with PersistentVolume wait for VM to finish starting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with legacy hotplug should add/remove volume with Block DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with declarative hotplug should add/remove volume with DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with declarative hotplug should add/remove volume with PersistentVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with declarative hotplug should add/remove volume with DataVolume wait for VM to finish starting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with declarative hotplug should add/remove volume with PersistentVolume wait for VM to finish starting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM with declarative hotplug should add/remove volume with Block DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with PersistentVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with DataVolume wait for VM to finish starting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with PersistentVolume wait for VM to finish starting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with Block DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with DataVolume immediate attach (virtio)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should add/remove volume with PersistentVolume immediate attach (virtio)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should not add/remove volume with dry run with DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should not add/remove volume with dry run with PersistentVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should not add/remove volume with dry run with Block DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM Should be able to add and remove multiple volumes with VMs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM Should be able to add and remove multiple volumes with VMs and block" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM Should be able to add and remove and re-add multiple volumes with VMs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM Should be able to add and remove and re-add multiple volumes  with VMs and block" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should allow to hotplug 75 volumes simultaneously" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM [QUARANTINE] should permanently add hotplug volume when added to VM, but still unpluggable after restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should reject hotplugging a volume with the same name as an existing volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should reject hotplugging the same volume with an existing volume name" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should reject removing a volume which wasn't hotplugged" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should reject removing a volume which doesn't exist" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] Online VM should allow hotplugging both a filesystem and block volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI migration should allow live migration with attached hotplug volumes containerDisk VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] VMI migration should allow live migration with attached hotplug volumes persistent disk VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] disk mutating sidecar should be able to add and remove volumes with DataVolume and running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug [storage-req] disk mutating sidecar should be able to add and remove volumes  with Block DataVolume immediate attach" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug delete attachment pod several times should remain active when deleting the hotplug pod and turning it unschedulable via a ResourceQuota" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug delete attachment pod several times should remain active when repeatedly deleting the hotplug pod and letting it reschedule" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug with limit range in namespace hotplug volume should have mem ratio same as VMI with limit range applied [test_id:10002]1 to 1 cpu and mem ratio" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug with limit range in namespace hotplug volume should have mem ratio same as VMI with limit range applied [test_id:10003]1 to 1 mem ratio, 4 to 1 cpu ratio" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug with limit range in namespace hotplug volume should have mem ratio same as VMI with limit range applied [test_id:10004]2 to 1 mem ratio, 4 to 1 cpu ratio" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug with limit range in namespace hotplug volume should have mem ratio same as VMI with limit range applied [test_id:10005]2.25 to 1 mem ratio, 5.75 to 1 cpu ratio" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug hostpath should attach a hostpath based volume to running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug iothreads should allow adding and removing hotplugged volumes without dedicated IO and shared policy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug iothreads should allow adding and removing hotplugged volumes with dedicated IO and auto policy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug hostpath-separate-device should attach a hostpath based volume to running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Hotplug LUN disk on an offline VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Hotplug Hotplug LUN disk on an online VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MultiQueue MultiQueue Behavior should be able to successfully boot fedora to the login prompt with multi-queue without being blocked by selinux [test_id:4599] with default virtio interface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]MultiQueue MultiQueue Behavior should be able to successfully boot fedora to the login prompt with multi-queue without being blocked by selinux with e1000 interface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of [test_id:10818]TPM across migration and restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of [test_id:10819]TPM across restart and migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of [test_id:10820]EFI across migration and restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of [test_id:10821]TPM+EFI across migration and restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of TPM across migration and restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of TPM across restart and migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of EFI across migration and restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should persist VM state of TPM+EFI across migration and restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM state with persistent TPM VM option enabled should remove persistent storage PVC if VMI is not owned by a VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] CBT VM matches cbt label selector, then unmatches" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] CBT Patch to match cbt label selector patch vm" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] CBT Patch to match cbt label selector patch vm namespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] CBT CBT migration with vmStateStorageClass configuration should persist CBT data across live migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] CBT should persist CBT data across restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] vitiofs config volumes With a single ConfigMap volume Should be the mounted virtiofs layout the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] vitiofs config volumes With a single Secret volume Should be the mounted virtiofs layout the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] vitiofs config volumes With a ServiceAccount defined Should be the namespace and token the same for a pod and vmi with virtiofs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] vitiofs config volumes With a DownwardAPI defined Should be the namespace and token the same for a pod and vmi with virtiofs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller basic labeling skip node reconciliation when node has skip annotation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller basic labeling [test_id:6246] label nodes with cpu model, cpu features and host cpu model" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller basic labeling [test_id:6247] should set default obsolete cpu models filter when obsolete-cpus-models is not set in kubevirt config" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller basic labeling [test_id:6995]should expose tsc frequency and tsc scalability" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller advanced labeling [test_id:6249] should update node with new cpu model label set" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller advanced labeling [test_id:6250] should update node with new cpu model vendor label" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller advanced labeling [test_id:6252] should remove all cpu model labels (all cpu model are in obsolete list)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node-labeller node with obsolete host-model cpuModel should not schedule vmi with host-model cpuModel to node with obsolete host-model cpuModel" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][sig-compute]VMIheadless [rfe_id:609]Creating a VirtualMachineInstance with headless [test_id:709][posneg:positive]should connect to console" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[Sysprep][sig-compute]Syspreped VirtualMachineInstance [ref_id:5105]should create the Admin user as specified in the Autounattend.xml [test_id:5843]Should run echo command on machine using the credentials specified in the Autounattend.xml file" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring][rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus scraped metrics [test_id:4135]should find VMI namespace on namespace label of the metric" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure cluster profiler for pprof data aggregation when ClusterProfiler configuration is disabled it should prevent subresource access" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure cluster profiler for pprof data aggregation when ClusterProfiler configuration is enabled it should allow subresource access" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-performance] Control Plane Performance Density Testing using kwok kwok density tests create a batch of fake VMIs should successfully create all fake VMIs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-performance] Control Plane Performance Density Testing using kwok kwok density tests create a batch of fake VMs should successfully create all fake VMs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces container disk should live migrate a container disk vm, several times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces container disk should live migrate a container disk vm, with an additional PVC mounted, should stay mounted after migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces container disk should live migrate a container disk vm, with an additional hotpluggedPVC mounted, should stay mounted after migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces container disk with RWOFs backend storage class should decentralized migrate a VMI with persistent TPM+EFI enabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces container disk should be able to cancel a migration by deleting the migration resource delete source migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces container disk should be able to cancel a migration by deleting the migration resource delete target migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration across namespaces datavolume disk should live migrate regular disk several times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] virt-handler node restrictions via validatingAdmissionPolicy reject not allowed patches to node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] virt-handler node restrictions via validatingAdmissionPolicy allow kubevirt related patches to node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute][USB] host USB Passthrough with usb storage with emulated USB devices Should successfully passthrough 1 emulated USB device" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute][USB] host USB Passthrough with usb storage with emulated USB devices Should successfully passthrough 2 emulated USB devices" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] K8s IO events [test_id:6225]Should catch the IO error event" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with RAW kubevirt content type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with RAW gzipped kubevirt content type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with archive content type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with archive tarred gzipped content type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with RAW kubevirt content type block" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with RAW kubevirt content type PROXY" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with RAW gzipped kubevirt content type PROXY" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with archive content type PROXY" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with archive tarred gzipped content type PROXY" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should make a PVC export available with RAW kubevirt content type block PROXY" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should export a VM and verify swtpm directories in the gz archive" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should recreate the exporter pod and secret if the pod fails" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should recreate the exporter pod if the pod is deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should recreate the service if the service is deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should handle no pvc existing when export created, then creating and populating the pvc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should be possible to observe exportserver pod exiting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should handle populating an export without a previously defined tokenSecretRef" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should honor TTL by cleaning up the the VMExport altogether" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Ingress should populate external links and cert and contain ingress host" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Route should populate external links and cert and contain route host" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should create export from VMSnapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should create export from VMSnapshot with multiple volumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should mark the status phase skipped on VMSnapshot without volumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should report export pending if VM is running, and start the VM export if the VM is not running, then stop again once VM started" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export with limit range  should report export pending if PVC is in use because of VMI using it, and start the VM export if the PVC is not in use, then stop again once pvc in use again" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should generate updated DataVolumeTemplates on http endpoint when exporting" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should generate updated DataVolumeTemplates on http endpoint when exporting snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export Should generate DVs and expanded VM definition on http endpoint with multiple volumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export should mark the status phase skipped on VM without volumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Export  with potential KubeVirt CR update should recreate exportserver pod when KubeVirt cert params updated" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [crit:high][vendor:cnv-qe@redhat.com][level:component] [crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler is responsive VMIs shouldn't fail after the kubelet restarts [sig-network]with bridge networking" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [crit:high][vendor:cnv-qe@redhat.com][level:component] [crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler is responsive VMIs shouldn't fail after the kubelet restarts [sig-compute]with default networking" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [crit:high][vendor:cnv-qe@redhat.com][level:component] [crit:high][vendor:cnv-qe@redhat.com][level:component]Creating a VirtualMachineInstance when virt-handler is responsive VMIs with Bridge Networking should work with Duplicate Address Detection (DAD)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] [rfe_id:1195][crit:medium][vendor:cnv-qe@redhat.com][level:component] the openapi spec for the subresources [test_id:3177]should be aggregated into the apiserver openapi spec" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] InstancetypeReferencePolicy should result in running VirtualMachine when set to reference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] InstancetypeReferencePolicy should result in running VirtualMachine when set to expand" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute] InstancetypeReferencePolicy should result in running VirtualMachine when set to expandAll" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics VirtOperatorDown should be triggered when virt-operator is down" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics NoReadyVirtOperator should be triggered when virt-operator is down" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics LowVirtOperatorCount should be triggered when virt-operator count is low" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics VirtControllerDown should be triggered when virt-controller is down" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics NoReadyVirtController should be triggered when virt-controller is down" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics LowVirtControllersCount should be triggered when virt-controller count is low" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics VirtApiDown should be triggered when virt-api is down" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Up metrics LowVirtAPICount should be triggered when virt-api count is low" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Low ready alerts LowReadyVirtControllersCount should be triggered when virt-controller pods exist but are not ready" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Errors metrics VirtApiRESTErrorsBurst should be triggered when requests to virt-api are failing" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Errors metrics VirtOperatorRESTErrorsBurst should be triggered when requests to virt-operator are failing" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Errors metrics VirtControllerRESTErrorsBurst should be triggered when requests to virt-controller are failing" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]Component Monitoring Errors metrics VirtHandlerRESTErrorsBurst should be triggered when requests to virt-handler are failing" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotunplug a running VM hot-unplug network interface succeed In place" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotunplug a running VM hot-unplug network interface succeed Migration based" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] Live Migration with addedNodeSelector Should successfully migrate a VM to a labelled node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Readiness Probe should succeed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Readiness Probe Should fail with working Exec probe and invalid command" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Readiness Probe Should fail with working Exec probe and infinitely running command" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Readiness probe with guest agent ping when the guest agent is enabled, after being disabled [test_id:6741] the VMI enters `Ready` state once again" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Liveness probe Should not fail the VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Liveness probe Should fail the VMI with working Exec probe and invalid command" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] GuestAgent Liveness probe with guest agent ping [test_id:9299] VM stops when guest agent is disabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-operator]virt-handler canary upgrade should successfully upgrade virt-handler" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given cpu/memory in requests/limits should allow int type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given cpu/memory in requests/limits should allow float type" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:3161]should carry vm.template.spec.annotations to VMI and ignore vm ones" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should sync the generation annotation on the vmi during restarts" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should not update the vmi generation annotation when the template changes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1521]should remove VirtualMachineInstance once the VM is marked for deletion with ContainerDisk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1521]should remove VirtualMachineInstance once the VM is marked for deletion [storage-req]with Filesystem Disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1521]should remove VirtualMachineInstance once the VM is marked for deletion [storage-req]with Block Disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1522]should remove owner references on the VirtualMachineInstance if it is orphan deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1523]should recreate VirtualMachineInstance if it gets deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1524]should recreate VirtualMachineInstance if the VirtualMachineInstance's pod gets deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1525]should stop VirtualMachineInstance if running set to false with ContainerDisk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1525]should stop VirtualMachineInstance if running set to false [storage-req]with Filesystem Disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1525]should stop VirtualMachineInstance if running set to false [storage-req]with Block Disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1526]should start and stop VirtualMachineInstance multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1527]should not update the VirtualMachineInstance spec if Running" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1528]should survive guest shutdown, multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should always have updated vm revision when starting vm" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:4645]should set the Ready condition on VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should report an error status [test_id:6867] when VM scheduling error occurs with unsatisfiable resource requirements" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should report an error status [test_id:6868] when VM scheduling error occurs with unsatisfiable scheduling constraints" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should report an error status [test_id:7596] when a VM with a missing PVC is started" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should report an error status [test_id:7597] when a VM with a missing DV is started" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:6869][QUARANTINE]should report an error status when image pull error occurs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:7679]should report an error status when data volume error occurs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should stop a running VM [test_id:3163]with RunStrategyAlways" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should stop a running VM [test_id:2186]with RunStrategyRerunOnFailure" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should stop a running VM [test_id:2189]with RunStrategyManual" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should restart a running VM [test_id:3164]with RunStrategyAlways" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should restart a running VM [test_id:2187]with RunStrategyRerunOnFailure" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should restart a running VM [test_id:2035]with RunStrategyManual" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1529]should start a stopped VM only once [test_id:2036]with RunStrategyManual" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:1529]should start a stopped VM only once [test_id:2037]with RunStrategyHalted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should not remove a succeeded VMI with RunStrategyOnce" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given should not remove a succeeded VMI [test_id:2190] with RunStrategyManual" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given [test_id:6311]should start in paused state using RunStrategyManual" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyAlways [test_id:3165]should restart a succeeded VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyAlways [test_id:4119]should migrate a running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyAlways [test_id:7743]should not migrate a running vm if dry-run option is passed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyRerunOnFailure [test_id:2188] should remove a succeeded VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyRerunOnFailure should restart a failed VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyOnce Should leave a failed VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyOnce with a failing VMI and the kubevirt.io/keep-launcher-alive-after-failure annotation [test_id:7164]VMI launcher pod should fail" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine A valid VirtualMachine given Using RunStrategyOnce with a failing VMI and the kubevirt.io/keep-launcher-alive-after-failure annotation [test_id:6993]VMI launcher pod compute container should keep running" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine [release-blocker][test_id:299][test_id:264]should create and delete a VM using all supported API versions with v1 api" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine [release-blocker][test_id:299][test_id:264]should create and delete a VM using all supported API versions with v1alpha3 api" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine crash loop backoff should backoff attempting to create a new VMI when 'runStrategy: Always' during crash loop." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine crash loop backoff should be able to stop a VM during crashloop backoff when when 'runStrategy: Always' is set" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine VirtualMachineControllerFinalizer should be added when the vm is created and removed when the vm is being deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine VirtualMachineControllerFinalizer should be removed when the vm has child resources, such as instance type ControllerRevisions, that have been deleted before the vm - issue #9438" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:1177][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VirtualMachine  when node becomes unhealthy  the VMs running in that node should be respawned" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM Rollout Strategy When using the Stage rollout strategy [test_id:11207]should set RestartRequired when changing any spec field" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with cni ptp plugin interface [test_id:1752]should create a virtual machine with one interface with network definition from different namespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with cni ptp plugin interface [test_id:1753]should create a virtual machine with two interfaces" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with multus network as default network [test_id:1751]should create a virtual machine with one interface with multus default network definition" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with Linux bridge plugin interface should be able to ping between two vms [test_id:1577]with secondary network only" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with Linux bridge plugin interface should be able to ping between two vms [test_id:1578]with default network and secondary network" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with Linux bridge plugin interface should be able to ping between two vms with default network and secondary network with IPAM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. VirtualMachineInstance with Linux bridge CNI plugin interface and custom MAC address. [test_id:676]should configure valid custom MAC address on Linux bridge CNI interface." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. Single VirtualMachineInstance with Linux bridge CNI plugin interface [test_id:1756]should report all interfaces in Status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. Single VirtualMachineInstance with Linux bridge CNI plugin interface should have the correct MTU on the secondary interface with no dhcp server" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:694][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance using different types of interfaces. Security Should allow outbound communication from VM under test - only if original MAC address is unchanged" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Multus [rfe_id:1758][crit:medium][vendor:cnv-qe@redhat.com][level:component]VirtualMachineInstance definition with qemu guest agent [test_id:1757] should report guest interfaces in VMI status" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Port-forward VMI With masquerade binding when performing port-forward from a local port to a VMI's declared port should reach the vmi IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Port-forward VMI With masquerade binding when performing port-forward from a local port to a VMI's declared port should reach the vmi IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Port-forward VMI With masquerade binding when performing port-forward from a local port to a VMI with no declared ports should reach the vmi IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Port-forward VMI With masquerade binding when performing port-forward from a local port to a VMI with no declared ports should reach the vmi IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Port-forward VMI With masquerade binding when performing port-forward from a local port to a VMI's non-declared port should not reach the vmi IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] Port-forward VMI With masquerade binding when performing port-forward from a local port to a VMI's non-declared port should not reach the vmi IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Start a VirtualMachineInstance when the controller pod is not running and an election happens [test_id:4642]should elect a new controller pod" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]virt-handler  multiple HTTP calls should re-use connections and not grow the number of open connections" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations simple default clone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations simple clone with snapshot source, create clone before snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations clone with only some of labels/annotations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations clone with only some of template.labels/template.annotations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations clone with changed MAC address" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations regarding domain Firmware clone with changed SMBios serial" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-compute]simple VM and cloning operations regarding domain Firmware should strip firmware UUID" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-storage]with more complicated VM and snapshot storage class with a simple clone, create clone before VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-storage]with more complicated VM and snapshot storage class with instancetype and preferences should create new ControllerRevisions for cloned VM with a running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-storage]with more complicated VM and snapshot storage class with instancetype and preferences should create new ControllerRevisions for cloned VM with a stopped VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-storage]with more complicated VM and snapshot storage class double cloning: clone target as a clone source" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="VirtualMachineClone Tests VM clone [sig-storage]with more complicated VM and snapshot storage class with WaitForFirstConsumer binding mode should not delete the vmsnapshot and vmrestore until all the pvc(s) are bound" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Instance Type and Preference Hotplug should plug extra resources from new instance type with maxGuest and maxSockets defined" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Instance Type and Preference Hotplug should plug extra resources from new instance type without maxGuest and maxSockets defined" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Instance Type and Preference Hotplug should reject live update when preference requirements are no longer met - bug #14595 by VirtualMachine resource requests" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Instance Type and Preference Hotplug should reject live update when preference requirements are no longer met - bug #14595 by instance type resource requests" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Reset subresource Reset a VirtualMachineInstance should succeed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure changes to the kubernetes client on the controller rate limiter should lead to delayed VMI starts" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure changes to the kubernetes client on the virt handler rate limiter should lead to delayed VMI running states" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints [test_id:4136] should find one leading virt-controller and two ready" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints [test_id:4137]should find one leading virt-operator and two ready" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints [test_id:4138]should be exposed and registered on the metrics endpoint" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints [test_id:4139]should return Prometheus metrics" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should throttle the Prometheus metrics access [test_id:4140] by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should throttle the Prometheus metrics access [test_id:6226] by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the metrics for a running VM [test_id:4141] by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the metrics for a running VM [test_id:6227] by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should expose kubevirt_node_deprecated_machine_types metric" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] storage flush requests metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6228] storage flush requests metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] time spent on cache flushing metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6229] time spent on cache flushing metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] I/O read operations metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6230] I/O read operations metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] I/O write operations metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6231] I/O write operations metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] storage read operation time metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6232] storage read operation time metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] storage read traffic in bytes metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6233] storage read traffic in bytes metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] storage write operation time metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6234] storage write operation time metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:4142] storage write traffic in bytes metric by using IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include the storage metrics for a running VM [test_id:6235] storage write traffic in bytes metric by using IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:4143] network metrics by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:6236] network metrics by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:4144] memory metrics by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:6237] memory metrics by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:4553] vcpu wait by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:6238] vcpu wait by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:4554] vcpu seconds by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:6239] vcpu seconds by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:4556] vmi unused memory by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include metrics for a running VM [test_id:6240] vmi unused memory by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints [QUARANTINE]should include VMI infos for a running VM [test_id:4145] by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints [QUARANTINE]should include VMI infos for a running VM [test_id:6241] by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include VMI phase metrics for all running VMs [test_id:4146] by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include VMI phase metrics for all running VMs [test_id:6242] by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include VMI eviction blocker status for all running VMs [test_id:4148] by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include VMI eviction blocker status for all running VMs [test_id:6243] by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include kubernetes labels to VMI metrics [test_id:4147] by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include kubernetes labels to VMI metrics [test_id:6244] by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include swap metrics [test_id:4555] by IPv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure [rfe_id:3187][crit:medium][vendor:cnv-qe@redhat.com][level:component]Prometheus Endpoints should include swap metrics [test_id:6245] by IPv6" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with a host-model cpu [test_id:6981]should migrate only to nodes supporting right cpu model" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with a host-model cpu Should trigger event if vmi with host-model start on source node with uniq host-model [test_id:7505]when no node is suited for host model" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration with a host-model cpu Should trigger event if the nodes doesn't contain MigrationSelectorLabel for the vmi host-model type no node contain suited SupportedHostModelMigrationCPU label" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Testing host-model cpuModel edge cases in the cluster if the cluster is host-model migratable Should be able to migrate back to the initial node from target node with host-model even if target is newer than source" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:393][crit:high][vendor:cnv-qe@redhat.com][level:system][sig-compute] VM Live Migration Testing host-model cpuModel edge cases in the cluster if the cluster is host-model migratable vmi with host-model should be able to migrate to node that support the initial node's host-model even if this model isn't the target's host-model" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:526]given a vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:527]given a vm" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin given a vmpool" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:528]given a vmi preset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:529][crit:low]given a vmi replica set" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:3230]given a vmi migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:5243]given a vmsnapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:5244]given a vmsnapshotcontent" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:5245]given a vmsrestore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:TODO]given a virtualmachineinstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:TODO]given a virtualmachinepreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:TODO]given a virtualmachineclusterinstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on resources are correct for view, edit, and admin [test_id:TODO]given a virtualmachineclusterpreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default [test_id:3232]on vm start" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default [test_id:3233]on vm stop" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default [test_id:3234]on vm restart" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vm expand-spec" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vm portforward" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vm migrate" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi guestosinfo" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi userlist" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi filesystemlist" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi addvolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi removevolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi freeze" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi unfreeze" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi reset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi softreboot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi portforward" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi vsock" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on expand-vm-spec" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi sev/fetchcertchain" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi sev/querylaunchmeasurement" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi sev/setupsession" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi sev/injectlaunchsecret" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi usbredir" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi vnc" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:500][crit:high][vendor:cnv-qe@redhat.com][level:component][sig-compute]User Access With default kubevirt service accounts should verify permissions on subresources are correct for view, edit, admin, migrate and default on vmi vnc/screenshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM Hotplug PCI Port Allocation should allocate the appropriate number of free ports with 1Gi memory and 0 additional devs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM Hotplug PCI Port Allocation should allocate the appropriate number of free ports with 2.1Gi memory and 0 additional devs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM Hotplug PCI Port Allocation should allocate the appropriate number of free ports with 2.1Gi memory and 6 additional devs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] VirtualMachineInstance with macvtap network binding plugin two VMs with macvtap interface should be able to communicate over macvtap network" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] VirtualMachineInstance with macvtap network binding plugin VMI migration should be successful when the VMI MAC address is defined in its spec" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] VirtualMachineInstance with macvtap network binding plugin VMI migration with live traffic should keep connectivity after a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance with error disk should pause VMI on IO error" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance with error disk should report IO errors in the guest with errorPolicy set to report" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]with Alpine PVC should be successfully started [test_id:3130]with Disk PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]with Alpine PVC should be successfully started [test_id:3131]with CDRom PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]with Alpine PVC should be successfully started unless hostpath disk image file not owned by qemu" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]with Alpine PVC should be successfully started and stopped multiple times [test_id:3132]with Disk PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]with Alpine PVC should be successfully started and stopped multiple times [test_id:3133]with CDRom PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]With an emptyDisk defined [test_id:3134]should create a writeable emptyDisk with the right capacity" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]With an emptyDisk defined and a specified serial number [test_id:3135]should create a writeable emptyDisk with the specified serial number" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]With ephemeral alpine PVC should be successfully [test_id:3136]started with Ephemeral PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]With ephemeral alpine PVC [test_id:3137]should not persist data" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:3106][crit:medium][vendor:cnv-qe@redhat.com][level:component]With VirtualMachineInstance with two PVCs [test_id:3138]should start vmi multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance With feature gates disabled for [test_id:4620]HostDisk, it should fail to start a VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With a HostDisk defined With 'DiskExistsOrCreate' type Should create a disk image and start [test_id:851]with virtio driver" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With a HostDisk defined With 'DiskExistsOrCreate' type Should create a disk image and start [test_id:3057]with sata driver" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With a HostDisk defined With 'DiskExistsOrCreate' type [test_id:3107]should start with multiple hostdisks in the same directory" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With a HostDisk defined With 'DiskExists' type [test_id:2306]Should use existing disk image and start" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With a HostDisk defined With 'DiskExists' type [test_id:847]Should fail with a capacity option" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With a HostDisk defined With unknown hostDisk type [test_id:852]Should fail to start VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With multiple empty PVCs [test_id:868] Should initialize an empty PVC by creating a disk.img" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With smaller than requested PVCs [test_id:3108]Should not initialize an empty PVC with a disk.img when disk is too small even with toleration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2298][crit:medium][vendor:cnv-qe@redhat.com][level:component] With HostDisk and PVC initialization With smaller than requested PVCs [test_id:3109]Should initialize an empty PVC with a disk.img when disk is too small but within toleration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2288][crit:high][vendor:cnv-qe@redhat.com][level:component][storage-req] With Cirros BlockMode PVC [test_id:1015]should be successfully started" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [storage-req][rfe_id:2288][crit:high][vendor:cnv-qe@redhat.com][level:component]With Alpine block volume PVC [test_id:3139]should be successfully started" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [rfe_id:2288][crit:high][vendor:cnv-qe@redhat.com][level:component] With not existing PVC [test_id:1040] should get unschedulable condition" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance With both SCSI and SATA devices should successfully start with distinct device names" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance With both SCSI and SATA devices With a USB device [test_id:9797]should successfully start and have the USB storage device attached" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance [storage-req] With a volumeMode block backed ephemeral disk should generate the pod with the volumeDevice" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance disk shareable tunable should successfully start 2 VMs with a shareable disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance write and read data from a shared disk should successfully write and read data" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance with lun disk should run the VMI using PVC source" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance with lun disk should run the VMI using DataVolume source" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Storage Starting a VirtualMachineInstance with lun disk should run the VMI created with a DataVolume source and use the LUN disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachineInstances [test_id:7627]create a VirtualMachineInstance" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachineInstances [test_id:7628]delete a VirtualMachineInstance" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachineInstances [test_id:7629]update a VirtualMachineInstance" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachineInstances [test_id:7630]patch a VirtualMachineInstance" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachines [test_id:7631]create a VirtualMachine" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachines [test_id:7632]delete a VirtualMachine" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachines [test_id:7633]update a VirtualMachine" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VirtualMachines [test_id:7634]patch a VirtualMachine" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests Migrations [test_id:7635]create a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests Migrations [test_id:7636]delete a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests Migrations [test_id:7637]update a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests Migrations [test_id:7638]patch a migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI Presets [test_id:7639]create a VMI preset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI Presets [test_id:7640]delete a VMI preset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI Presets [test_id:7641]update a VMI preset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI Presets [test_id:7642]patch a VMI preset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI ReplicaSets [test_id:7643]create a VMI replicaset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI ReplicaSets [test_id:7644]delete a VMI replicaset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI ReplicaSets [test_id:7645]update a VMI replicaset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VMI ReplicaSets [test_id:7646]patch a VMI replicaset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests KubeVirt CR [test_id:7648]delete a KubeVirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests KubeVirt CR [test_id:7649]update a KubeVirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests KubeVirt CR [test_id:7650]patch a KubeVirt CR" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Snapshots [test_id:7651]create a VM Snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Snapshots [test_id:7652]delete a VM Snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Snapshots [test_id:7653]update a VM Snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Snapshots [test_id:7654]patch a VM Snapshot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Restores [test_id:7655]create a VM Restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Restores [test_id:7656]delete a VM Restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Restores [test_id:7657]update a VM Restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Dry-Run requests VM Restores [test_id:7658]patch a VM Restore" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy  destination PVC expansion should migrate the source volume from a source DV to a destination PVC to a filesystem volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy  destination PVC expansion should migrate the source volume from a source DV to a destination PVC to a block volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should migrate the source volume from a source DV to a destination DV with pre-copy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should migrate the source volume from a source DV to a destination DV with post-copy" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should trigger the migration once the destination DV exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should trigger the migration once the destination PVC exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should migrate the source volume from a source and destination block RWX DVs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should migrate the source volume from a block source and filesystem destination DVs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should migrate a PVC with a VM using a containerdisk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should cancel the migration by the reverting to the source volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should fail to migrate when the destination image is smaller" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should set the restart condition since the second volume is RWO and not part of the migration" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should refuse to restart the VM and set the ManualRecoveryRequired at VM shutdown" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should cancel the migration and clear the volume migration state" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Update volumes with the migration updateVolumesStrategy should be able to recover from an interrupted volume migration when the copy of the destination volumes was successful" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to add and remove a volume with the volume migration feature gate enabled with a persistent volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to add and remove a volume with the volume migration feature gate enabled with an ephemeral volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to volume migrate a VM with a containerdisk and a hotplugged volume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to volume migrate a VM with a datavolume and an hotplugged datavolume migrating from filesystem to filesystem" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to volume migrate a VM with a datavolume and an hotplugged datavolume migrating from filesystem to block" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to volume migrate a VM with a datavolume and an hotplugged datavolume migrating from block to filesystem" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Volumes update with migration Hotplug volumes should be able to volume migrate a VM with a datavolume and an hotplugged datavolume migrating from block to block" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] network binding plugin with CNI and Sidecar can be used by a VMI as its primary network" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] network binding plugin with domain attachment tap type can run a virtual machine with one macvtap interface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] network binding plugin with domain attachment managedTap type can run a virtual machine with one primary managed-tap interface" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] network binding plugin with domain attachment managedTap type can establish communication between two VMs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a ConfigMap defined With a single volume [test_id:782]Should be the fs layout the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a ConfigMap defined With multiple volumes [test_id:783]Should start VMI with multiple ConfigMaps" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a Secret defined With a single volume [test_id:779]Should be the fs layout the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a Secret defined With multiple volumes [test_id:780]Should start VMI with multiple Secrets" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a ServiceAccount defined [test_id:998]Should be the namespace and token the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a Secret and a ConfigMap defined With a single volume [test_id:786]Should be that cfgMap and secret fs layout same for the pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With SSH Keys as a Secret defined With a single volume [test_id:778]Should be the fs layout the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:899][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]Config With a DownwardAPI defined [test_id:790]Should be the namespace and token the same for a pod and vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [storage-req]PVC expansion PVC expansion is detected by VM and can be fully used with Block PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [storage-req]PVC expansion PVC expansion is detected by VM and can be fully used with Filesystem PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [storage-req]PVC expansion Check disk expansion accounts for actual usable size" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachineInstance with a DataVolume as a volume source Alpine import [test_id:3189]should be successfully started and stopped multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachineInstance with a DataVolume as a volume source Alpine import [test_id:6686]should successfully start multiple concurrent VMIs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachineInstance with a DataVolume as a volume source Alpine import [test_id:5252]should be successfully started when using a PVC volume owned by a DataVolume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachineInstance with a DataVolume as a volume source Alpine import should accurately aggregate DataVolume conditions from many DVs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachineInstance with a DataVolume as a volume source with a PVC from a Datavolume [test_id:4643]should NOT be rejected when VM template lists a DataVolume, but VM lists PVC VolumeSource" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachine with an invalid DataVolume using DataVolume with invalid URL should be possible to stop VM if datavolume is crashing" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachine with an invalid DataVolume using DataVolume with invalid URL [test_id:3190]should correctly handle invalid DataVolumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachine with an invalid DataVolume using DataVolume with invalid URL [test_id:3190]should correctly handle eventually consistent DataVolumes" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachine with a DataVolume using http import [test_id:3191]should be successfully started and stopped multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachine with a DataVolume using http import [test_id:837]deleting VM with background propagation policy should automatically delete DataVolumes and VMI owned by VM." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] Starting a VirtualMachine with a DataVolume using http import [test_id:3192]should remove owner references on DataVolume if VM is orphan deleted." classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone should resolve DataVolume sourceRef with PVC source" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone should resolve DataVolume sourceRef with Snapshot source" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone should report DataVolume without source PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request [test_id:3193]with explicit role" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request [test_id:3194]with implicit role" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request [test_id:5253]with explicit role (all namespaces)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request [test_id:5254]with explicit role (one namespace)" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request with explicit role snapshot clone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request with implicit insufficient role snapshot clone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request with implicit sufficient role snapshot clone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request with explicit role (all namespaces) snapshot clone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone [storage-req] deny then allow clone request with explicit role (one namespace) snapshot clone" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration [rfe_id:3188][crit:high][vendor:cnv-qe@redhat.com][level:system] DataVolume clone permission checking using Alpine import/clone should skip authorization when DataVolume already exists" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration Fedora VMI tests [rfe_id:5070][crit:medium][vendor:cnv-qe@redhat.com][level:component]fstrim from the VM influences disk.img [test_id:5894]by default, fstrim will make the image smaller" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration Fedora VMI tests [rfe_id:5070][crit:medium][vendor:cnv-qe@redhat.com][level:component]fstrim from the VM influences disk.img [test_id:5898]with preallocation true, fstrim has no effect" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration Fedora VMI tests [rfe_id:5070][crit:medium][vendor:cnv-qe@redhat.com][level:component]fstrim from the VM influences disk.img [test_id:5897]with preallocation false, fstrim will make the image smaller" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration Fedora VMI tests [rfe_id:5070][crit:medium][vendor:cnv-qe@redhat.com][level:component]fstrim from the VM influences disk.img [test_id:5899]with thick provision true, fstrim has no effect" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] DataVolume Integration Fedora VMI tests [rfe_id:5070][crit:medium][vendor:cnv-qe@redhat.com][level:component]fstrim from the VM influences disk.img [test_id:5896]with thick provision false, fstrim will make the image smaller" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Guestfs [rfe_id:6364]Run libguestfs on PVCs without root on a FS PVC [test_id:11669]Should successfully run libguestfs-test-tool" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Guestfs [rfe_id:6364]Run libguestfs on PVCs without root on a FS PVC [posneg:positive]Should successfully run guestfs command on a filesystem-based PVC [test_id:6480]without extra arguments" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Guestfs [rfe_id:6364]Run libguestfs on PVCs without root on a FS PVC [posneg:positive]Should successfully run guestfs command on a filesystem-based PVC [test_id:11670]setting the uid" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Guestfs [rfe_id:6364]Run libguestfs on PVCs without root on a FS PVC [posneg:negative][test_id:11671]Should fail to run the guestfs command on a PVC in use" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Guestfs [rfe_id:6364]Run libguestfs on PVCs without root [posneg:positive][test_id:6479]Should successfully run guestfs command on a block-based PVC" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-storage]Guestfs [rfe_id:6364]Should successfully run guestfs command on a filesystem-based PVC with root" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="Ensure stable functionality by repeately starting vmis many times without issues" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-compute]SSH and SCP [test_id:11661]should succeed to execute a command on the VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-compute]SSH and SCP [test_id:11659]should copy a local file back and forth" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-compute]SSH and SCP [test_id:11660]should copy a local directory back and forth" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][test_id:4272]should connect to vnc with --proxy-only flag" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][test_id:5274]should connect to vnc with --proxy-only flag to the specified port" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[virtctl] [sig-compute]VNC [rfe_id:127][crit:medium][vendor:cnv-qe@redhat.com][level:component][test_id:11667]should allow creating a VNC screenshot in PNG format" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM can be hotplugged a network interface In place" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM can be hotplugged a network interface Migration based" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM can migrate a VMI with hotplugged interfaces In place" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM can migrate a VMI with hotplugged interfaces Migration based" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM has connectivity over the secondary network In place" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM has connectivity over the secondary network Migration based" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM is able to hotplug multiple network interfaces In place" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] bridge nic-hotplug a running VM is able to hotplug multiple network interfaces Migration based" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool pool should scale to three, to two and then to zero replicas" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool pool should scale to five, to six and then to zero replicas" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should be rejected on POST if spec is invalid" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should reject POST if vmi spec is invalid" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should remove VMs once they are marked for deletion" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should handle pool with dataVolumeTemplates" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should replace deleted VM and get replacement" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should roll out VM template changes without impacting VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should roll out VMI template changes and proactively roll out new VMIs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should remove owner references on the VirtualMachine if it is orphan deleted" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should not scale when paused and scale when resume" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should use DescendingOrder scale-in strategy when specified" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should respect name generation settings do not append index by default" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should respect name generation settings do not append index if set to false" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should respect name generation settings append index if set to true" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VirtualMachinePool should respect maxUnavailable strategy during updates" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]Watchdog A VirtualMachineInstance with a watchdog device [test_id:4641]should be shut down when the watchdog expires" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]vTPM [rfe_id:5168][crit:high][vendor:cnv-qe@redhat.com][level:component] with TPM VMI option enabled [test_id:8607] should expose a functional emulated TPM which persists across migrations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Guest Access Credentials should have ssh-key under authorized keys added [test_id:6220] using qemu guest agent" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Guest Access Credentials should have ssh-key under authorized keys added [test_id:6224] using configdrive" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Guest Access Credentials should have ssh-key under authorized keys added using nocloud" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Guest Access Credentials with qemu guest agent [test_id:6221]should propagate user password" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Guest Access Credentials with qemu guest agent should update to unsupported agent [test_id:6222]for public ssh keys" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Guest Access Credentials with qemu guest agent should update to unsupported agent [test_id:6223] for user password" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and connectivity between VMI/s is blocked by Default-deny networkpolicy [test_id:1511] should fail to reach serverVMI from clientVMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and connectivity between VMI/s is blocked by Default-deny networkpolicy [test_id:1512] should fail to reach clientVMI from serverVMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and connectivity between VMI/s is blocked by Default-deny networkpolicy [test_id:369] should deny http traffic for ports 80/81 from clientVMI to serverVMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and vms limited by allow same namespace networkpolicy when client vmi is on default namespace [test_id:1513] should succeed pinging between two VMI/s in the same namespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and vms limited by allow same namespace networkpolicy when client vmi is on alternative namespace [test_id:1514] should fail pinging between two VMI/s each on different namespaces" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and ingress traffic to VMI identified via label at networkprofile's labelSelector is blocked when client vmi is on alternative namespace [test_id:1515] should fail to reach serverVMI from clientVMIAlternativeNamespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and ingress traffic to VMI identified via label at networkprofile's labelSelector is blocked when client vmi is on default namespace [test_id:1515] should fail to reach serverVMI from clientVMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and ingress traffic to VMI identified via label at networkprofile's labelSelector is blocked when client vmi is on default namespace when another client vmi is on an alternative namespace [test_id:1517] should success to reach clientVMI from clientVMIAlternativeNamespace" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and TCP connectivity on ports 80 and 81 between VMI/s is allowed by networkpolicy [test_id:2774] should allow http traffic for ports 80 and 81 from clientVMI to serverVMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [rfe_id:150][crit:high][vendor:cnv-qe@redhat.com][level:component]Networkpolicy when three alpine VMs with default networking are started and serverVMI start an HTTP server on port 80 and 81 and TCP connectivity on ports 80 between VMI/s is allowed by networkpolicy [test_id:2775] should allow http traffic at port 80 and deny at port 81 from clientVMI to serverVMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with existing VM [test_id:TODO] should return unchanged VirtualMachine, if instancetype is not used" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with existing VM [test_id:TODO] should return VirtualMachine with instancetype expanded with VirtualMachineInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with existing VM [test_id:TODO] should return VirtualMachine with instancetype expanded with VirtualMachineClusterInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should return unchanged VirtualMachine, if instancetype is not used" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should return VirtualMachine with instancetype expanded with VirtualMachineInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should return VirtualMachine with instancetype expanded with VirtualMachineClusterInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should fail, if referenced instancetype does not exist with VirtualMachineInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should fail, if referenced instancetype does not exist with VirtualMachineClusterInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should fail, if instancetype expansion hits a conflict with VirtualMachineInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should fail, if instancetype expansion hits a conflict with VirtualMachineClusterInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should fail, if VM and endpoint namespace are different with VirtualMachineInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource instancetype with passed VM in request [test_id:TODO] should fail, if VM and endpoint namespace are different with VirtualMachineClusterInstancetype" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with existing VM [test_id:TODO] should return unchanged VirtualMachine, if preference is not used" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with existing VM [test_id:TODO] should return VirtualMachine with preference expanded with VirtualMachinePreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with existing VM [test_id:TODO] should return VirtualMachine with preference expanded with VirtualMachineClusterPreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with passed VM in request [test_id:TODO] should return unchanged VirtualMachine, if preference is not used" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with passed VM in request [test_id:TODO] should return VirtualMachine with preference expanded with VirtualMachinePreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with passed VM in request [test_id:TODO] should return VirtualMachine with preference expanded with VirtualMachineClusterPreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with passed VM in request [test_id:TODO] should fail, if referenced preference does not exist with VirtualMachinePreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] ExpandSpec subresource preference with passed VM in request [test_id:TODO] should fail, if referenced preference does not exist with VirtualMachineClusterPreference" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute-realtime]Realtime should start the realtime VM when no mask is specified" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute-realtime]Realtime should start the realtime VM when realtime mask is specified" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]HostDevices with ephemeral disk with emulated PCI devices Should successfully passthrough an emulated PCI device" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]HostDevices with ephemeral disk with emulated PCI devices Should successfully passthrough 2 emulated PCI devices" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Declarative Hotplug Inject/Eject CD-ROM Should inject, swap, and eject a CD-ROM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-storage] Declarative Hotplug Hotplug disks Should add and remove a hotplug disk" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]VM Tolerations Updating VMs tolerations should successfully live update tolerations" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute] Infrastructure Node Restriction Should disallow to modify VMs on different node" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] interface state up/down status and guest should show correct iface state" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] interface state up/down status and guest should show iface is down when vm with ifaces down is migrated" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring Cluster VM metrics kubevirt_number_of_vms should reflect the number of VMs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VMI metrics should have kubevirt_vmi_phase_transition_time_seconds buckets correctly configured" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VMI metrics should have kubevirt_rest_client_requests_total for the 'virtualmachineinstances' resource" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM status metrics Should be available for a running VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM status metrics Should be available for a paused VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM status metrics Should not be available for a stopped VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM migration metrics Should correctly update metrics on successful VMIM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM migration metrics Should correctly update metrics on failing VMIM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM snapshot metrics [test_id:8639]Number of disks restored and total restored bytes metric values should be correct" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM snapshot metrics Snapshot succeeded timestamp metric values should be correct" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM metrics that are based on the guest agent [QUARANTINE][test_id:11267]should have kubevirt_vmi_info correctly configured with guest OS labels" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring Metrics that are based on VMI connections should have kubevirt_vmi_last_api_connection_timestamp_seconds correctly configured" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM alerts [test_id:9260] should fire OrphanedVirtualMachineInstances alert" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM alerts should fire VMCannotBeEvicted alert" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM dirty rate metrics should ensure a running VM has dirty rate metrics" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-monitoring]VM Monitoring VM dirty rate metrics [QUARANTINE] should ensure a stress VM has high dirty rate than a stale VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk [rfe_id:273][crit:medium][vendor:cnv-qe@redhat.com][level:component]Starting and stopping the same VirtualMachine with ephemeral registry disk [test_id:1463] should success multiple times" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk [rfe_id:273][crit:medium][vendor:cnv-qe@redhat.com][level:component]Starting a VirtualMachineInstance should obey the disk verification limits in the KubeVirt CR [test_id:7182]disk verification should fail when the memory limit is too low" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk [rfe_id:273][crit:medium][vendor:cnv-qe@redhat.com][level:component]Starting from custom image location with disk at /custom-disk/downloaded [test_id:1466]should boot normally" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk [rfe_id:273][crit:medium][vendor:cnv-qe@redhat.com][level:component]Starting with virtio-win with virtio-win as secondary disk [test_id:1467]should boot and have the virtio as sata CDROM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk [rfe_id:4052][crit:high][vendor:cnv-qe@redhat.com][level:component]VMI disk permissions with ephemeral registry disk [test_id:4299]should not have world write permissions" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk Bogus container disk path that points to outside of the volume should be rejected on VMI creation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk Simulate an upgrade from a version where ImageVolume was disabled to a version where it is enabled Migration from a source launcher with the bind mount workaround to a target launcher without the bind mount workaround should succeed when  using simple Cirros vmi" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk Simulate an upgrade from a version where ImageVolume was disabled to a version where it is enabled Migration from a source launcher with the bind mount workaround to a target launcher without the bind mount workaround should succeed when  using  Cirros vmi with custom location" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:588][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]ContainerDisk Simulate an upgrade from a version where ImageVolume was disabled to a version where it is enabled Migration from a source launcher with the bind mount workaround to a target launcher without the bind mount workaround should succeed when  using  Cirros vmi with kernel boot" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-performance] CPU latency tests for measuring realtime VMs performance running cyclictest and collecting results directly from VM" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [ref_id:1182]Probes for readiness should succeed with working TCP probe and tcp server on ipv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [ref_id:1182]Probes for readiness should fail when there is no TCP server listening inside the guest" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [ref_id:1182]Probes for liveness should not fail the VMI with working TCP probe and tcp server on ipv4" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-network] [ref_id:1182]Probes for liveness should fail when there is no TCP server listening inside the guest" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[ref_id:2717][sig-compute]KubeVirt control plane resilience pod eviction evicting pods of control plane [test_id:2830]last eviction should fail for multi-replica virt-controller pods" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[ref_id:2717][sig-compute]KubeVirt control plane resilience pod eviction evicting pods of control plane [test_id:2799]last eviction should fail for multi-replica virt-api pods" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[ref_id:2717][sig-compute]KubeVirt control plane resilience pod eviction evicting pods of control plane eviction of single-replica virt-controller pod should succeed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[ref_id:2717][sig-compute]KubeVirt control plane resilience pod eviction evicting pods of control plane eviction of single-replica virt-api pod should succeed" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[ref_id:2717][sig-compute]KubeVirt control plane resilience control plane components check when control plane pods are running [test_id:2806]virt-controller and virt-api pods have a pod disruption budget" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[ref_id:2717][sig-compute]KubeVirt control plane resilience control plane components check when Control plane pods temporarily lose connection to Kubernetes API should fail health checks when connectivity is lost, and recover when connectivity is regained" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset CRD Validation [test_id:1595]Should reject POST if schema is invalid" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset CRD Validation [test_id:1596]should reject POST if validation webhoook deems the spec is invalid" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1597]Should be accepted on POST" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1598]Should reject a second submission of a VMIPreset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1599]Should return 404 if VMIPreset does not exist" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1600]Should reject presets that conflict with VirtualMachineInstance settings" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1601]Should accept presets that don't conflict with VirtualMachineInstance settings" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1602]Should ignore VMIs that don't match" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Matching [test_id:1603]Should not be applied to existing VMIs" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Exclusions [test_id:1604]Should not apply presets to VirtualMachineInstance's with the exclusion marking" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Conflict [test_id:1605]should denied to start the VMI" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Override [test_id:644][rfe_id:609] should override presets" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Preset Lifecycle [test_id:617][rfe_id:609] should create and delete preset" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset Match Expressions [test_id:726] Should match multiple VMs via MatchExpression" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[rfe_id:609][crit:medium][vendor:cnv-qe@redhat.com][level:component][sig-compute]VMIPreset [rfe_id:613]MatchLabels [test_id:672] Should match multiple VMs via MatchLabel" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]AMD Secure Encrypted Virtualization (SEV) device management should reset SEV allocatable devices when the feature gate is disabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]AMD Secure Encrypted Virtualization (SEV) lifecycle should start a SEV or SEV-ES VM It should launch with base SEV features enabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]AMD Secure Encrypted Virtualization (SEV) lifecycle should start a SEV or SEV-ES VM It should launch with SEV-ES features enabled" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
      <testcase name="[sig-compute]AMD Secure Encrypted Virtualization (SEV) lifecycle [QUARANTINE] should run guest attestation" classname="KubeVirt Tests Suite" time="0">
          <skipped />
      </testcase>
  </testsuite>